<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Frame-Accurate Video Player</title>
    <style>
        * { box-sizing: border-box; }
        body {
            font-family: system-ui, -apple-system, sans-serif;
            margin: 0;
            padding: 20px;
            line-height: 1.6;
            background: #1a1a1a;
            color: #e0e0e0;
        }
        h1 { margin-bottom: 0.5rem; color: #fff; }
        .description { color: #aaa; margin-top: 0; }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .controls {
            background: #2a2a2a;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        button {
            background: #667eea;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 6px;
            font-size: 16px;
            cursor: pointer;
            margin: 5px;
        }
        button:hover { background: #5568d3; }
        button:disabled {
            background: #444;
            cursor: not-allowed;
        }
        .canvas-container {
            position: relative;
            background: #000;
            border-radius: 8px;
            overflow: hidden;
            margin: 20px 0;
            cursor: grab;
            height: 70vh;
        }
        .canvas-container:active { cursor: grabbing; }
        canvas {
            display: block;
            width: 100%;
            height: 100%;
            image-rendering: crisp-edges;
        }
        .seekbar-container {
            background: #2a2a2a;
            padding: 15px 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .seekbar {
            width: 100%;
            height: 8px;
            background: #444;
            border-radius: 4px;
            position: relative;
            cursor: pointer;
            margin: 10px 0;
        }
        .seekbar-progress {
            height: 100%;
            background: #667eea;
            border-radius: 4px;
            width: 0%;
            pointer-events: none;
        }
        .seekbar-thumb {
            position: absolute;
            width: 16px;
            height: 16px;
            background: white;
            border-radius: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
            left: 0%;
            pointer-events: none;
            box-shadow: 0 2px 4px rgba(0,0,0,0.3);
        }
        .overlay-controls {
            display: flex;
            gap: 20px;
            padding: 10px 20px;
            background: #2a2a2a;
            border-radius: 8px;
            margin: 10px 0;
        }
        .overlay-controls h3 {
            margin: 0 0 10px 0;
            font-size: 14px;
            color: #ccc;
        }
        .overlay-controls label {
            display: flex;
            align-items: center;
            gap: 6px;
            cursor: pointer;
            font-size: 14px;
            color: #ccc;
            margin: 5px 0;
        }
        .overlay-controls input[type="checkbox"] {
            cursor: pointer;
        }
        .info-row {
            display: flex;
            gap: 15px;
            margin: 20px 0;
        }
        .metrics {
            flex: 2;
            background: #2a2a2a;
            padding: 15px 20px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            color: #aaa;
        }
        .metrics h3 {
            margin: 0 0 10px 0;
            font-size: 14px;
            font-family: system-ui, -apple-system, sans-serif;
            color: #ccc;
        }
        .info-row .overlay-controls {
            flex: 1;
            background: #2a2a2a;
            padding: 15px 20px;
            border-radius: 8px;
        }
        .metrics-row {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .metric {
            margin: 5px 0;
        }
        .metric-label {
            color: #667eea;
            font-weight: bold;
        }
        .settings {
            background: #2a2a2a;
            padding: 15px 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .settings label {
            display: inline-block;
            margin-right: 10px;
            color: #aaa;
        }
        .settings input[type="number"] {
            background: #1a1a1a;
            border: 1px solid #444;
            color: #e0e0e0;
            padding: 6px 10px;
            border-radius: 4px;
            width: 80px;
            font-size: 14px;
        }
        .hotkeys {
            background: #2a2a2a;
            padding: 15px 20px;
            border-radius: 8px;
            margin: 20px 0;
            font-size: 14px;
        }
        .hotkeys h3 {
            margin-top: 0;
            color: #fff;
        }
        .hotkeys-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 8px 20px;
        }
        .hotkey {
            display: flex;
            gap: 10px;
        }
        .hotkey-key {
            color: #667eea;
            font-family: 'Courier New', monospace;
            min-width: 100px;
        }
        .hotkey-desc {
            color: #aaa;
        }
        .url-input-container {
            background: #2a2a2a;
            padding: 15px 20px;
            border-radius: 8px;
            margin: 10px 0;
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            align-items: center;
        }
        .url-input-container input[type="text"] {
            flex: 1;
            background: #1a1a1a;
            border: 1px solid #444;
            color: #e0e0e0;
            padding: 10px 12px;
            border-radius: 6px;
            font-size: 14px;
        }
        .url-input-container input[type="text"]:focus {
            outline: none;
            border-color: #667eea;
        }
        .url-input-container button {
            padding: 10px 16px;
            margin: 0;
        }
        .url-hint {
            width: 100%;
            color: #888;
            font-size: 12px;
            margin-top: 4px;
        }
        .error-msg {
            background: #4a2020;
            border: 1px solid #ff6b6b;
            color: #ff6b6b;
            padding: 15px 20px;
            border-radius: 8px;
            margin: 20px 0;
            display: none;
        }
        .cache-viz-container {
            background: #2a2a2a;
            padding: 15px 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .cache-viz-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
            flex-wrap: wrap;
            gap: 10px;
        }
        .cache-viz-header h3 {
            margin: 0;
            color: #fff;
            font-size: 14px;
        }
        .cache-viz-settings {
            display: flex;
            gap: 15px;
            align-items: center;
        }
        .cache-viz-settings label {
            color: #aaa;
            font-size: 12px;
        }
        .cache-viz-settings input[type="number"] {
            background: #1a1a1a;
            border: 1px solid #444;
            color: #e0e0e0;
            padding: 4px 8px;
            border-radius: 4px;
            width: 70px;
            font-size: 12px;
        }
        .cache-viz-legend {
            display: flex;
            gap: 15px;
            font-size: 11px;
            color: #aaa;
        }
        .cache-viz-legend-item {
            display: flex;
            align-items: center;
            gap: 5px;
        }
        .cache-viz-legend-color {
            width: 12px;
            height: 12px;
            border-radius: 2px;
        }
        .cache-viz-canvas {
            width: 100%;
            height: 24px;
            border-radius: 4px;
            cursor: crosshair;
        }
        .diagnostic-console {
            background: #1a1a1a;
            border: 1px solid #333;
            border-radius: 8px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 11px;
        }
        .diagnostic-console-header {
            background: #2a2a2a;
            padding: 8px 15px;
            border-radius: 8px 8px 0 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .diagnostic-console-header h3 {
            margin: 0;
            color: #fff;
            font-size: 12px;
        }
        .diagnostic-console-header button {
            background: #444;
            padding: 4px 10px;
            font-size: 11px;
            margin: 0;
        }
        .diagnostic-console-body {
            height: 120px;
            overflow-y: auto;
            padding: 10px 15px;
        }
        .log-entry {
            margin: 2px 0;
            display: flex;
            gap: 10px;
        }
        .log-time {
            color: #666;
            flex-shrink: 0;
        }
        .log-msg { color: #aaa; }
        .log-msg.info { color: #667eea; }
        .log-msg.success { color: #4ade80; }
        .log-msg.warn { color: #fbbf24; }
        .log-msg.error { color: #ff6b6b; }
        @media (max-width: 600px) {
            body { padding: 10px; }
            .controls, .settings, .metrics { padding: 10px 15px; }
            button { padding: 10px 16px; font-size: 14px; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Frame-Accurate Video Player</h1>
        <p class="description">Load local videos with frame-accurate seeking, zoom/pan, and playback controls. Uses WebCodecs API for fast decoding.</p>

        <div class="controls">
            <input type="file" id="fileInput" accept="video/mp4,video/quicktime,video/webm,.mp4,.mov,.m4v,.webm" style="display: none;">
            <button id="loadBtn">Load Video File</button>
            <button id="loadUrlBtn">Load from URL</button>
            <button id="playBtn" disabled>Play</button>
            <button id="resetZoomBtn" disabled>Reset Zoom</button>
        </div>
        <div class="url-input-container" id="urlInputContainer" style="display: none;">
            <input type="text" id="urlInput" placeholder="Enter video URL (must support CORS)">
            <button id="urlLoadBtn">Load</button>
            <button id="urlCancelBtn">Cancel</button>
            <small class="url-hint">URL must support CORS. Range requests enable streaming without downloading the full file.</small>
        </div>

        <div class="error-msg" id="errorMsg"></div>

        <div class="canvas-container" id="canvasContainer" style="display: none;">
            <canvas id="canvas"></canvas>
        </div>

        <div class="seekbar-container" id="seekbarContainer" style="display: none;">
            <div class="seekbar" id="seekbar">
                <div class="seekbar-progress" id="seekbarProgress"></div>
                <div class="seekbar-thumb" id="seekbarThumb"></div>
            </div>
        </div>

        <div class="cache-viz-container" id="cacheVizContainer" style="display: none;">
            <div class="cache-viz-header">
                <h3>Frame Cache</h3>
                <div class="cache-viz-settings">
                    <label>Cache Size: <input type="number" id="bufferSize" value="60" min="10" max="500"></label>
                    <label>Lookahead: <input type="number" id="lookaheadSize" value="30" min="1" max="100"></label>
                </div>
                <div class="cache-viz-legend">
                    <div class="cache-viz-legend-item"><div class="cache-viz-legend-color" style="background: #4ade80;"></div> Cached</div>
                    <div class="cache-viz-legend-item"><div class="cache-viz-legend-color" style="background: #fbbf24;"></div> Keyframe</div>
                    <div class="cache-viz-legend-item"><div class="cache-viz-legend-color" style="background: #667eea;"></div> Current</div>
                </div>
            </div>
            <canvas class="cache-viz-canvas" id="cacheVizCanvas"></canvas>
        </div>

        <div class="info-row" id="infoRow" style="display: none;">
            <div class="metrics" id="metrics">
                <h3>Video Info</h3>
                <div class="metrics-row">
                    <div class="metric"><span class="metric-label">File:</span> <span id="metricFile">-</span></div>
                    <div class="metric"><span class="metric-label">Codec:</span> <span id="metricCodec">-</span></div>
                    <div class="metric"><span class="metric-label">Resolution:</span> <span id="metricRes">-</span></div>
                </div>
                <div class="metrics-row">
                    <div class="metric"><span class="metric-label">Frame:</span> <span id="metricFrame">-</span>/<span id="metricTotal">-</span></div>
                    <div class="metric"><span class="metric-label">FPS:</span> <span id="metricFps">-</span></div>
                    <div class="metric"><span class="metric-label">Seek:</span> <span id="metricSeek">-</span></div>
                    <div class="metric"><span class="metric-label">Cached:</span> <span id="metricCached">-</span></div>
                    <div class="metric"><span class="metric-label">Keyframes:</span> <span id="metricKeyframes">-</span></div>
                </div>
            </div>
            <div class="overlay-controls" id="overlayControls">
                <h3>Overlays</h3>
                <label><input type="checkbox" id="showFrameIndex" checked> Frame Index</label>
                <label><input type="checkbox" id="showTimingStats" checked> Timing Stats</label>
            </div>
        </div>

        <div class="diagnostic-console" id="diagnosticConsole">
            <div class="diagnostic-console-header">
                <h3>Diagnostic Log</h3>
                <button id="copyLogBtn">Copy</button>
            </div>
            <div class="diagnostic-console-body" id="logBody"></div>
        </div>

        <div class="hotkeys">
            <h3>Keyboard Shortcuts</h3>
            <div class="hotkeys-grid">
                <div class="hotkey"><span class="hotkey-key">← / →</span><span class="hotkey-desc">±1 frame</span></div>
                <div class="hotkey"><span class="hotkey-key">↑ / ↓</span><span class="hotkey-desc">±10 frames</span></div>
                <div class="hotkey"><span class="hotkey-key">Ctrl+← / →</span><span class="hotkey-desc">±30 frames</span></div>
                <div class="hotkey"><span class="hotkey-key">Ctrl+↑ / ↓</span><span class="hotkey-desc">±100 frames</span></div>
                <div class="hotkey"><span class="hotkey-key">Space</span><span class="hotkey-desc">Play/Pause</span></div>
                <div class="hotkey"><span class="hotkey-key">Mouse Wheel</span><span class="hotkey-desc">Zoom</span></div>
                <div class="hotkey"><span class="hotkey-key">Click + Drag</span><span class="hotkey-desc">Pan</span></div>
            </div>
        </div>
    </div>

    <!-- mp4box.js for demuxing MP4 files -->
    <script src="https://cdn.jsdelivr.net/npm/mp4box@0.5.2/dist/mp4box.all.min.js"></script>

    <script>
        // ============================================
        // Diagnostic Logging System
        // ============================================
        const logBody = document.getElementById('logBody');
        const MAX_LOG_ENTRIES = 100;

        function log(msg, level = 'info') {
            const time = new Date().toLocaleTimeString('en-US', { hour12: false, hour: '2-digit', minute: '2-digit', second: '2-digit', fractionalSecondDigits: 3 });
            const entry = document.createElement('div');
            entry.className = 'log-entry';
            entry.innerHTML = `<span class="log-time">${time}</span><span class="log-msg ${level}">${msg}</span>`;
            logBody.appendChild(entry);

            // Limit entries
            while (logBody.children.length > MAX_LOG_ENTRIES) {
                logBody.removeChild(logBody.firstChild);
            }

            // Auto-scroll
            logBody.scrollTop = logBody.scrollHeight;
        }

        document.getElementById('copyLogBtn').addEventListener('click', () => {
            const lines = Array.from(logBody.querySelectorAll('.log-entry')).map(entry => {
                const time = entry.querySelector('.log-time').textContent;
                const msg = entry.querySelector('.log-msg').textContent;
                return `${time} ${msg}`;
            });
            const text = lines.join('\n');
            navigator.clipboard.writeText(text).then(() => {
                log('Log copied to clipboard', 'success');
            }).catch(() => {
                // Fallback
                const ta = document.createElement('textarea');
                ta.value = text;
                document.body.appendChild(ta);
                ta.select();
                document.execCommand('copy');
                document.body.removeChild(ta);
                log('Log copied to clipboard', 'success');
            });
        });

        log('Video player initialized', 'info');

        // ============================================
        // On-Demand Video Decoder with Sliding Cache
        // Uses File System Access API for chunked reading
        // ============================================
        class OnDemandVideoDecoder {
            constructor(options = {}) {
                this.cacheSize = options.cacheSize || 60;
                this.lookahead = options.lookahead || 30;
                this.cache = new Map();
                this.samples = [];
                this.keyframeIndices = [];
                this.decoder = null;
                this.config = null;
                this.videoTrack = null;
                this.mp4boxFile = null;
                this.fileHandle = null;  // File System Access API handle
                this.file = null;        // Standard File object fallback
                this.url = null;         // URL for remote video
                this.fileSize = 0;
                this.CHUNK_SIZE = 1024 * 1024; // 1MB chunks
                this.supportsRangeRequests = false;
                this.isDecoding = false;  // Lock to prevent concurrent decodes
                this.pendingFrame = null; // Queue the latest requested frame
                this.prefetchRequested = false; // Flag to trigger background prefetch
                this.lastAccessedFrame = -1; // Track access pattern for prefetching
                this.accessDirection = 1; // 1 = forward, -1 = backward
            }

            // Initialize with File System Access API handle, File object, or URL string
            async init(source) {
                if (typeof source === 'string') {
                    // URL - check for range request support
                    this.url = source;
                    log('Checking URL for range request support...', 'info');
                    const headResponse = await fetch(source, { method: 'HEAD' });
                    if (!headResponse.ok) {
                        throw new Error(`Failed to fetch URL: ${headResponse.status} ${headResponse.statusText}`);
                    }
                    this.fileSize = parseInt(headResponse.headers.get('Content-Length')) || 0;
                    this.supportsRangeRequests = headResponse.headers.get('Accept-Ranges') === 'bytes';

                    if (!this.supportsRangeRequests || !this.fileSize) {
                        // Fall back to fetching entire file
                        log('URL does not support range requests, fetching entire file...', 'warn');
                        const response = await fetch(source);
                        const blob = await response.blob();
                        this.file = blob;
                        this.fileSize = blob.size;
                        this.url = null;
                        log(`Downloaded ${(this.fileSize / 1024 / 1024).toFixed(1)} MB`, 'info');
                    } else {
                        log(`URL supports streaming (${(this.fileSize / 1024 / 1024).toFixed(1)} MB, range requests enabled)`, 'success');
                    }
                } else if (source.getFile) {
                    // File System Access API handle
                    this.fileHandle = source;
                    this.file = await source.getFile();
                    this.fileSize = this.file.size;
                } else {
                    // Standard File object
                    this.file = source;
                    this.fileSize = this.file.size;
                }

                // Demux the video using chunked reading
                this.mp4boxFile = MP4Box.createFile();

                const ready = new Promise((resolve, reject) => {
                    this.mp4boxFile.onError = reject;
                    this.mp4boxFile.onReady = resolve;
                });

                // Read file progressively until mp4box has enough info
                let offset = 0;
                let resolved = false;

                ready.then(() => { resolved = true; });

                while (offset < this.fileSize && !resolved) {
                    const buffer = await this.readChunk(offset, this.CHUNK_SIZE);
                    buffer.fileStart = offset;

                    const nextOffset = this.mp4boxFile.appendBuffer(buffer);

                    if (nextOffset === undefined) {
                        // mp4box needs more data, continue reading sequentially
                        offset += buffer.byteLength;
                    } else {
                        // mp4box is requesting a specific offset
                        offset = nextOffset;
                    }

                    // Give the promise a chance to resolve
                    await new Promise(r => setTimeout(r, 0));
                }

                const info = await ready;

                if (info.videoTracks.length === 0) {
                    throw new Error('No video tracks found in file');
                }

                this.videoTrack = info.videoTracks[0];

                // Get codec description
                const trak = this.mp4boxFile.getTrackById(this.videoTrack.id);
                const description = this.getCodecDescription(trak);

                const codec = this.videoTrack.codec.startsWith('vp08') ? 'vp8' : this.videoTrack.codec;
                this.config = {
                    codec: codec,
                    codedWidth: this.videoTrack.video.width,
                    codedHeight: this.videoTrack.video.height,
                };
                if (description) {
                    this.config.description = description;
                }

                // Check codec support
                const support = await VideoDecoder.isConfigSupported(this.config);
                if (!support.supported) {
                    throw new Error(`Codec ${codec} is not supported by this browser`);
                }

                // mp4box has parsed the moov atom which contains sample metadata (offsets, sizes).
                // We don't need to load mdat here - we'll read sample data on-demand when decoding.

                // Extract all samples (metadata only - not the full video data)
                this.extractSamples();

                // Calculate FPS
                const duration = this.videoTrack.duration / this.videoTrack.timescale;
                this.fps = this.samples.length / duration;

                return {
                    codec: codec,
                    width: this.videoTrack.video.width,
                    height: this.videoTrack.video.height,
                    totalFrames: this.samples.length,
                    keyframes: this.keyframeIndices.length,
                    duration: duration,
                    fps: this.fps,
                };
            }

            // Read a chunk of the file at a specific offset
            async readChunk(offset, size) {
                const end = Math.min(offset + size, this.fileSize);

                if (this.url && this.supportsRangeRequests) {
                    // Use HTTP range request for URL
                    const response = await fetch(this.url, {
                        headers: { 'Range': `bytes=${offset}-${end - 1}` }
                    });
                    const arrayBuffer = await response.arrayBuffer();
                    // Return ArrayBuffer directly (not Uint8Array) so fileStart can be set
                    return arrayBuffer;
                } else {
                    // Use File/Blob slice for local files
                    const blob = this.file.slice(offset, end);
                    const arrayBuffer = await blob.arrayBuffer();
                    return arrayBuffer;
                }
            }

            getCodecDescription(trak) {
                for (const entry of trak.mdia.minf.stbl.stsd.entries) {
                    const box = entry.avcC || entry.hvcC || entry.vpcC || entry.av1C;
                    if (box) {
                        const stream = new DataStream(undefined, 0, DataStream.BIG_ENDIAN);
                        box.write(stream);
                        return new Uint8Array(stream.buffer, 8);
                    }
                }
                return null;
            }

            extractSamples() {
                // Use getTrackSamplesInfo to get sample metadata (offsets, sizes)
                // without needing mdat loaded - this works from moov alone
                const samplesInfo = this.mp4boxFile.getTrackSamplesInfo(this.videoTrack.id);

                if (!samplesInfo || samplesInfo.length === 0) {
                    throw new Error('No samples found in video track');
                }

                const timescale = this.videoTrack.timescale;

                // Extract all samples with decode order index for file reading
                const rawSamples = samplesInfo.map((sample, decodeIndex) => ({
                    offset: sample.offset,
                    size: sample.size,
                    timestamp: sample.cts * 1e6 / timescale,
                    duration: sample.duration * 1e6 / timescale,
                    isKeyframe: sample.is_sync,
                    cts: sample.cts,
                    decodeIndex, // Original index for reading from file in decode order
                }));

                // Sort by CTS to get presentation order
                // This is critical for videos with B-frames where decode order != presentation order
                rawSamples.sort((a, b) => a.cts - b.cts);

                // Now this.samples[N] = presentation frame N
                this.samples = rawSamples;

                // Build keyframe indices in presentation order
                for (let i = 0; i < this.samples.length; i++) {
                    if (this.samples[i].isKeyframe) {
                        this.keyframeIndices.push(i);
                    }
                }

                log(`Extracted ${this.samples.length} sample metadata entries (sorted by presentation order)`, 'info');
            }

            findKeyframeBefore(frameIndex) {
                let left = 0, right = this.keyframeIndices.length - 1;
                let result = 0;

                while (left <= right) {
                    const mid = Math.floor((left + right) / 2);
                    if (this.keyframeIndices[mid] <= frameIndex) {
                        result = this.keyframeIndices[mid];
                        left = mid + 1;
                    } else {
                        right = mid - 1;
                    }
                }

                return result;
            }

            findKeyframeAfter(frameIndex) {
                for (const kf of this.keyframeIndices) {
                    if (kf > frameIndex) return kf;
                }
                return this.samples.length;
            }

            async getFrame(frameIndex) {
                if (frameIndex < 0 || frameIndex >= this.samples.length) {
                    return null;
                }

                // Track access direction for prefetching
                if (this.lastAccessedFrame >= 0) {
                    const delta = frameIndex - this.lastAccessedFrame;
                    if (delta > 0) this.accessDirection = 1;
                    else if (delta < 0) this.accessDirection = -1;
                }
                this.lastAccessedFrame = frameIndex;

                // Check cache first
                if (this.cache.has(frameIndex)) {
                    const bitmap = this.cache.get(frameIndex);
                    this.cache.delete(frameIndex);
                    this.cache.set(frameIndex, bitmap);

                    // Trigger background prefetch if we're getting close to cache edge
                    this.maybeStartPrefetch(frameIndex);

                    return { bitmap, fromCache: true };
                }

                // If currently decoding, queue this frame and wait
                if (this.isDecoding) {
                    this.pendingFrame = frameIndex;
                    // Wait for current decode to finish, then try again
                    await new Promise(resolve => {
                        const checkDone = () => {
                            if (!this.isDecoding) {
                                resolve();
                            } else {
                                setTimeout(checkDone, 10);
                            }
                        };
                        checkDone();
                    });
                    // Check cache again - might have been decoded
                    if (this.cache.has(frameIndex)) {
                        const bitmap = this.cache.get(frameIndex);
                        this.cache.delete(frameIndex);
                        this.cache.set(frameIndex, bitmap);
                        return { bitmap, fromCache: true };
                    }
                    // If there's a newer pending frame, skip this one
                    if (this.pendingFrame !== null && this.pendingFrame !== frameIndex) {
                        return null;
                    }
                }

                // Find keyframe and decode range with lookahead
                const keyframe = this.findKeyframeBefore(frameIndex);
                const endFrame = Math.min(frameIndex + this.lookahead, this.samples.length - 1);
                const nextKeyframe = this.findKeyframeAfter(frameIndex);
                const actualEnd = nextKeyframe > frameIndex ? Math.min(endFrame, nextKeyframe - 1) : endFrame;

                await this.decodeRange(keyframe, actualEnd, frameIndex);

                const bitmap = this.cache.get(frameIndex);
                return bitmap ? { bitmap, fromCache: false } : null;
            }

            // Check if we should start prefetching ahead
            maybeStartPrefetch(currentFrame) {
                if (this.isDecoding || this.prefetchRequested) return;

                // Find the edge of cached frames in the access direction
                let cachedAhead = 0;
                if (this.accessDirection > 0) {
                    // Moving forward - count cached frames ahead
                    for (let i = currentFrame + 1; i < this.samples.length && this.cache.has(i); i++) {
                        cachedAhead++;
                    }
                } else {
                    // Moving backward - count cached frames behind
                    for (let i = currentFrame - 1; i >= 0 && this.cache.has(i); i--) {
                        cachedAhead++;
                    }
                }

                // If we have less than lookahead frames cached ahead, start prefetching
                if (cachedAhead < this.lookahead) {
                    this.prefetchRequested = true;
                    // Use setTimeout to not block the current frame return
                    setTimeout(() => this.prefetch(currentFrame), 0);
                }
            }

            // Prefetch frames in the current access direction
            async prefetch(fromFrame) {
                if (this.isDecoding) {
                    this.prefetchRequested = false;
                    return;
                }

                const direction = this.accessDirection;
                let targetFrame;

                if (direction > 0) {
                    // Find first uncached frame ahead
                    targetFrame = fromFrame + 1;
                    while (targetFrame < this.samples.length && this.cache.has(targetFrame)) {
                        targetFrame++;
                    }
                    if (targetFrame >= this.samples.length) {
                        this.prefetchRequested = false;
                        return;
                    }
                } else {
                    // Find first uncached frame behind
                    targetFrame = fromFrame - 1;
                    while (targetFrame >= 0 && this.cache.has(targetFrame)) {
                        targetFrame--;
                    }
                    if (targetFrame < 0) {
                        this.prefetchRequested = false;
                        return;
                    }
                }

                // Decode a range around the target
                const keyframe = this.findKeyframeBefore(targetFrame);
                const endFrame = Math.min(targetFrame + this.lookahead, this.samples.length - 1);
                const nextKeyframe = this.findKeyframeAfter(targetFrame);
                const actualEnd = nextKeyframe > targetFrame ? Math.min(endFrame, nextKeyframe - 1) : endFrame;

                await this.decodeRange(keyframe, actualEnd, targetFrame);
                this.prefetchRequested = false;
            }

            async decodeRange(startFrame, endFrame, targetFrame) {
                this.isDecoding = true;
                this.pendingFrame = null;

                try {
                    await this._decodeRangeInternal(startFrame, endFrame, targetFrame);
                } finally {
                    this.isDecoding = false;
                }
            }

            async _decodeRangeInternal(startFrame, endFrame, targetFrame) {
                const halfCache = Math.floor(this.cacheSize / 2);
                const cacheWindowStart = Math.max(startFrame, targetFrame - halfCache);
                const cacheWindowEnd = Math.min(endFrame, targetFrame + halfCache);

                if (this.decoder) {
                    try {
                        this.decoder.close();
                    } catch (e) {
                        // Ignore close errors
                    }
                }

                // Get samples for the presentation range and find the decode index range
                // VideoDecoder requires ALL frames in decode order for proper inter-frame prediction
                let minDecodeIndex = Infinity;
                let maxDecodeIndex = -Infinity;
                for (let i = startFrame; i <= endFrame; i++) {
                    const di = this.samples[i].decodeIndex;
                    minDecodeIndex = Math.min(minDecodeIndex, di);
                    maxDecodeIndex = Math.max(maxDecodeIndex, di);
                }

                // Collect ALL samples with decode indices in this range
                // This ensures we don't skip reference frames that B-frames depend on
                const samplesToFeed = [];
                for (let i = 0; i < this.samples.length; i++) {
                    const sample = this.samples[i];
                    if (sample.decodeIndex >= minDecodeIndex && sample.decodeIndex <= maxDecodeIndex) {
                        samplesToFeed.push({ presentationIndex: i, sample });
                    }
                }
                samplesToFeed.sort((a, b) => a.sample.decodeIndex - b.sample.decodeIndex);

                // Expected frames is now the full decode range (may be more than presentation range)
                const expectedFrames = samplesToFeed.length;
                let decodedCount = 0;

                // Read sample data in decode order for efficient batching
                const sampleDataMap = await this.readSampleDataByDecodeOrder(samplesToFeed);

                // Build timestamp-to-presentation-index map for ALL frames we're decoding
                // VideoDecoder outputs frames in presentation order (by timestamp)
                const timestampToIndex = new Map();
                for (const { presentationIndex, sample } of samplesToFeed) {
                    const ts = Math.round(sample.timestamp);
                    timestampToIndex.set(ts, presentationIndex);
                }

                return new Promise((resolve, reject) => {
                    this.decoder = new VideoDecoder({
                        output: (frame) => {
                            // Map frame timestamp to presentation index
                            const frameTs = Math.round(frame.timestamp);
                            let frameIndex = timestampToIndex.get(frameTs);

                            // Fallback: find closest timestamp if exact match fails
                            if (frameIndex === undefined) {
                                let closestDiff = Infinity;
                                for (const [ts, idx] of timestampToIndex.entries()) {
                                    const diff = Math.abs(ts - frameTs);
                                    if (diff < closestDiff) {
                                        closestDiff = diff;
                                        frameIndex = idx;
                                    }
                                }
                            }

                            if (frameIndex !== undefined && frameIndex >= cacheWindowStart && frameIndex <= cacheWindowEnd) {
                                createImageBitmap(frame).then(bitmap => {
                                    this.addToCache(frameIndex, bitmap);
                                    frame.close();
                                    decodedCount++;
                                    if (decodedCount >= expectedFrames) {
                                        resolve();
                                    }
                                }).catch(() => {
                                    frame.close();
                                    decodedCount++;
                                    if (decodedCount >= expectedFrames) {
                                        resolve();
                                    }
                                });
                            } else {
                                frame.close();
                                decodedCount++;
                                if (decodedCount >= expectedFrames) {
                                    resolve();
                                }
                            }
                        },
                        error: (e) => {
                            // Ignore AbortError from decoder close
                            if (e.name === 'AbortError') {
                                resolve();
                            } else {
                                reject(e);
                            }
                        }
                    });

                    this.decoder.configure(this.config);

                    // Feed samples to decoder in decode order (DTS order)
                    for (const { presentationIndex, sample } of samplesToFeed) {
                        const sampleData = sampleDataMap.get(presentationIndex);
                        const chunk = new EncodedVideoChunk({
                            type: sample.isKeyframe ? 'key' : 'delta',
                            timestamp: sample.timestamp,
                            duration: sample.duration,
                            data: sampleData,
                        });
                        this.decoder.decode(chunk);
                    }

                    this.decoder.flush();
                });
            }

            // Read sample data for samples sorted by decode order, with batching
            async readSampleDataByDecodeOrder(samplesToFeed) {
                const results = new Map();

                // samplesToFeed is already sorted by decodeIndex
                // Group samples that are contiguous in the file for batch reading
                let i = 0;
                while (i < samplesToFeed.length) {
                    const first = samplesToFeed[i];
                    let regionEnd = i;
                    let regionBytes = first.sample.size;

                    // Extend region while samples are contiguous in file
                    while (regionEnd < samplesToFeed.length - 1) {
                        const current = samplesToFeed[regionEnd];
                        const next = samplesToFeed[regionEnd + 1];

                        // Check if next sample immediately follows current in file
                        if (next.sample.offset === current.sample.offset + current.sample.size) {
                            regionEnd++;
                            regionBytes += next.sample.size;
                        } else {
                            break;
                        }
                    }

                    // Read the entire contiguous region
                    const buffer = await this.readChunk(first.sample.offset, regionBytes);
                    const bufferView = new Uint8Array(buffer);

                    // Extract individual samples and map by presentation index
                    let bufferOffset = 0;
                    for (let j = i; j <= regionEnd; j++) {
                        const { presentationIndex, sample } = samplesToFeed[j];
                        results.set(presentationIndex, bufferView.slice(bufferOffset, bufferOffset + sample.size));
                        bufferOffset += sample.size;
                    }

                    i = regionEnd + 1;
                }

                return results;
            }

            addToCache(frameIndex, bitmap) {
                if (this.cache.size >= this.cacheSize) {
                    const firstKey = this.cache.keys().next().value;
                    const oldBitmap = this.cache.get(firstKey);
                    oldBitmap.close();
                    this.cache.delete(firstKey);
                }
                this.cache.set(frameIndex, bitmap);
            }

            getCacheStatus() {
                return {
                    size: this.cache.size,
                    maxSize: this.cacheSize,
                };
            }

            getFrameTimestamp(frameIndex) {
                if (frameIndex >= 0 && frameIndex < this.samples.length) {
                    return this.samples[frameIndex].timestamp / 1e6;
                }
                return 0;
            }

            close() {
                if (this.decoder) {
                    this.decoder.close();
                }
                for (const bitmap of this.cache.values()) {
                    bitmap.close();
                }
                this.cache.clear();
            }
        }

        // ============================================
        // Video Player UI
        // ============================================

        let videoDecoder = null;
        let currentFrame = 0;
        let totalFrames = 0;
        let fps = 0;
        let fileName = '';
        let isPlaying = false;
        let playInterval = null;
        let videoInfo = null;

        // Canvas and zoom/pan state
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        let scale = 1;
        let offsetX = 0;
        let offsetY = 0;
        let isDragging = false;
        let dragStartX = 0;
        let dragStartY = 0;
        let currentBitmap = null;

        // Constrain offset to keep at least 10% of image visible on each axis
        function constrainOffset() {
            if (!currentBitmap) return;

            const container = canvasContainer;
            const containerWidth = container.clientWidth;
            const containerHeight = container.clientHeight;

            // Calculate the scaled video dimensions (same logic as renderFrame)
            const videoAspect = currentBitmap.width / currentBitmap.height;
            const containerAspect = containerWidth / containerHeight;
            let baseScale, drawX, drawY;
            if (videoAspect > containerAspect) {
                baseScale = containerWidth / currentBitmap.width;
                drawX = 0;
                drawY = (containerHeight - currentBitmap.height * baseScale) / 2;
            } else {
                baseScale = containerHeight / currentBitmap.height;
                drawX = (containerWidth - currentBitmap.width * baseScale) / 2;
                drawY = 0;
            }

            const scaledWidth = currentBitmap.width * baseScale * scale;
            const scaledHeight = currentBitmap.height * baseScale * scale;

            // Require at least 25% visible on each axis
            const minVisible = 0.25;
            const minVisibleX = scaledWidth * minVisible;
            const minVisibleY = scaledHeight * minVisible;

            // Calculate bounds accounting for the centering offset (drawX, drawY)
            // The image is drawn at (offsetX + drawX, offsetY + drawY)
            // Right edge of image must be at least minVisibleX from left of container
            const minOffsetX = minVisibleX - scaledWidth - drawX;
            // Left edge of image must be at least minVisibleX from right of container
            const maxOffsetX = containerWidth - minVisibleX - drawX;

            // Bottom edge of image must be at least minVisibleY from top of container
            const minOffsetY = minVisibleY - scaledHeight - drawY;
            // Top edge of image must be at least minVisibleY from bottom of container
            const maxOffsetY = containerHeight - minVisibleY - drawY;

            offsetX = Math.max(minOffsetX, Math.min(maxOffsetX, offsetX));
            offsetY = Math.max(minOffsetY, Math.min(maxOffsetY, offsetY));
        }

        // Performance metrics
        let lastSeekTime = 0;
        let lastFromCache = false;

        // Overlay system - array of callbacks for drawing on top of video frames
        const overlays = [];

        // Frame index overlay - shows current frame / total frames
        function frameIndexOverlay({ ctx, canvas, frameIndex, totalFrames }) {
            const text = `${frameIndex} / ${totalFrames}`;
            const padding = 8;
            const fontSize = 14;

            ctx.font = `bold ${fontSize}px monospace`;
            const metrics = ctx.measureText(text);
            const boxWidth = metrics.width + padding * 2;
            const boxHeight = fontSize + padding * 2;

            ctx.fillStyle = 'rgba(0, 0, 0, 0.6)';
            ctx.fillRect(10, 10, boxWidth, boxHeight);

            ctx.fillStyle = '#ffffff';
            ctx.fillText(text, 10 + padding, 10 + padding + fontSize - 2);
        }

        // Timing stats overlay - shows seek time and cache status
        function timingStatsOverlay({ ctx, canvas, seekTime, fromCache }) {
            const cacheStatus = fromCache ? 'cache' : 'decode';
            const text = `${seekTime.toFixed(1)}ms (${cacheStatus})`;
            const padding = 8;
            const fontSize = 14;
            const yOffset = 40;

            ctx.font = `${fontSize}px monospace`;
            const metrics = ctx.measureText(text);
            const boxWidth = metrics.width + padding * 2;
            const boxHeight = fontSize + padding * 2;

            ctx.fillStyle = 'rgba(0, 0, 0, 0.6)';
            ctx.fillRect(10, yOffset, boxWidth, boxHeight);

            ctx.fillStyle = fromCache ? '#4ade80' : '#fbbf24';
            ctx.fillText(text, 10 + padding, yOffset + padding + fontSize - 2);
        }

        // Zoom level overlay - shows zoom factor when not at 1.0x
        function zoomLevelOverlay({ ctx, canvas, zoomScale }) {
            if (zoomScale === undefined || Math.abs(zoomScale - 1.0) < 0.01) return; // Don't show at 1.0x

            const text = `${zoomScale.toFixed(1)}x`;
            const padding = 8;
            const fontSize = 14;
            const yOffset = 70; // Below timing stats overlay

            ctx.font = `bold ${fontSize}px monospace`;
            const metrics = ctx.measureText(text);
            const boxWidth = metrics.width + padding * 2;
            const boxHeight = fontSize + padding * 2;

            ctx.fillStyle = 'rgba(0, 0, 0, 0.6)';
            ctx.fillRect(10, yOffset, boxWidth, boxHeight);

            ctx.fillStyle = '#ffffff';
            ctx.fillText(text, 10 + padding, yOffset + padding + fontSize - 2);
        }

        // Render all active overlays
        function renderOverlays(info) {
            for (const overlay of overlays) {
                ctx.save();
                overlay(info);
                ctx.restore();
            }
        }

        // Helper to render frame with overlays
        function renderFrameWithOverlays() {
            if (!currentBitmap || !videoDecoder) return;
            renderFrame(currentBitmap);
            renderOverlays({
                ctx,
                canvas,
                frameIndex: currentFrame,
                totalFrames,
                seekTime: lastSeekTime,
                fromCache: lastFromCache,
                fps,
                bitmap: currentBitmap,
                timestamp: videoDecoder.getFrameTimestamp(currentFrame),
                zoomScale: scale,
            });
        }

        // Update active overlays based on checkbox state
        function updateOverlays() {
            overlays.length = 0;
            if (document.getElementById('showFrameIndex').checked) {
                overlays.push(frameIndexOverlay);
            }
            if (document.getElementById('showTimingStats').checked) {
                overlays.push(timingStatsOverlay);
            }
            // Zoom overlay is always active (self-manages visibility based on zoom level)
            overlays.push(zoomLevelOverlay);
            // Re-render current frame with updated overlays
            renderFrameWithOverlays();
        }

        // UI Elements
        const loadBtn = document.getElementById('loadBtn');
        const fileInput = document.getElementById('fileInput');
        const playBtn = document.getElementById('playBtn');
        const resetZoomBtn = document.getElementById('resetZoomBtn');
        const canvasContainer = document.getElementById('canvasContainer');
        const seekbar = document.getElementById('seekbar');
        const seekbarProgress = document.getElementById('seekbarProgress');
        const seekbarThumb = document.getElementById('seekbarThumb');
        const seekbarContainer = document.getElementById('seekbarContainer');
        const metricsDiv = document.getElementById('metrics');
        const bufferSizeInput = document.getElementById('bufferSize');
        const lookaheadInput = document.getElementById('lookaheadSize');
        const errorMsg = document.getElementById('errorMsg');
        const cacheVizContainer = document.getElementById('cacheVizContainer');
        const cacheVizCanvas = document.getElementById('cacheVizCanvas');
        const cacheVizCtx = cacheVizCanvas.getContext('2d');

        // Check WebCodecs support
        if (!('VideoDecoder' in window)) {
            showError('WebCodecs API is not supported in this browser. Please use Chrome, Edge, or Firefox.');
            loadBtn.disabled = true;
        }

        function showError(msg) {
            errorMsg.textContent = msg;
            errorMsg.style.display = 'block';
        }

        function hideError() {
            errorMsg.style.display = 'none';
        }

        // ============================================
        // Cache Visualization (canvas-based for 100k+ frames)
        // ============================================
        function renderCacheVisualization() {
            if (!videoDecoder || totalFrames === 0) return;

            const rect = cacheVizCanvas.getBoundingClientRect();
            const dpr = window.devicePixelRatio || 1;
            const width = rect.width * dpr;
            const height = rect.height * dpr;

            // Set canvas size for high DPI
            if (cacheVizCanvas.width !== width || cacheVizCanvas.height !== height) {
                cacheVizCanvas.width = width;
                cacheVizCanvas.height = height;
            }

            cacheVizCtx.fillStyle = '#333';
            cacheVizCtx.fillRect(0, 0, width, height);

            // For very large videos, each pixel represents multiple frames
            const framesPerPixel = Math.max(1, totalFrames / width);
            const pixelsPerFrame = width / totalFrames;

            // Get cached frame indices
            const cachedFrames = new Set(videoDecoder.cache.keys());
            const keyframes = new Set(videoDecoder.keyframeIndices);

            if (framesPerPixel <= 1) {
                // Fewer frames than pixels - draw individual marks
                const frameWidth = Math.max(1, pixelsPerFrame);

                // Draw keyframes first (background layer)
                cacheVizCtx.fillStyle = '#fbbf24';
                for (const kf of keyframes) {
                    const x = (kf / totalFrames) * width;
                    cacheVizCtx.fillRect(x, 0, Math.max(1, frameWidth), height);
                }

                // Draw cached frames
                cacheVizCtx.fillStyle = '#4ade80';
                for (const frame of cachedFrames) {
                    const x = (frame / totalFrames) * width;
                    cacheVizCtx.fillRect(x, 0, Math.max(1, frameWidth), height);
                }
            } else {
                // More frames than pixels - aggregate
                for (let px = 0; px < width; px++) {
                    const frameStart = Math.floor(px * framesPerPixel);
                    const frameEnd = Math.floor((px + 1) * framesPerPixel);

                    let hasCached = false;
                    let hasKeyframe = false;

                    for (let f = frameStart; f < frameEnd; f++) {
                        if (cachedFrames.has(f)) hasCached = true;
                        if (keyframes.has(f)) hasKeyframe = true;
                    }

                    if (hasCached) {
                        cacheVizCtx.fillStyle = '#4ade80';
                        cacheVizCtx.fillRect(px, 0, 1, height);
                    } else if (hasKeyframe) {
                        cacheVizCtx.fillStyle = '#fbbf24';
                        cacheVizCtx.fillRect(px, 0, 1, height);
                    }
                }
            }

            // Draw current frame marker (always on top)
            const currentX = (currentFrame / totalFrames) * width;
            cacheVizCtx.fillStyle = '#667eea';
            cacheVizCtx.fillRect(currentX - 1, 0, 3, height);
        }

        // Click on cache viz to seek
        cacheVizCanvas.addEventListener('click', (e) => {
            if (!videoDecoder || totalFrames === 0) return;
            const rect = cacheVizCanvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const frame = Math.floor((x / rect.width) * totalFrames);
            log(`Seek to frame ${frame} via cache visualization`, 'info');
            seekToFrame(frame);
        });

        // Load video from file handle, File object, or URL string
        async function loadVideo(source) {
            hideError();

            try {
                // Get file name
                if (typeof source === 'string') {
                    // URL - extract filename from path
                    fileName = source.split('/').pop().split('?')[0] || 'remote video';
                } else if (source.name) {
                    fileName = source.name;
                } else if (source.getFile) {
                    const f = await source.getFile();
                    fileName = f.name;
                }

                log(`Loading video: ${fileName}`, 'info');

                // Clean up previous decoder
                if (videoDecoder) {
                    videoDecoder.close();
                }

                // Create new decoder
                const cacheSize = parseInt(bufferSizeInput.value) || 60;
                const lookahead = parseInt(lookaheadInput.value) || 10;
                videoDecoder = new OnDemandVideoDecoder({ cacheSize, lookahead });

                log(`Decoder configured: cacheSize=${cacheSize}, lookahead=${lookahead}`, 'info');

                // Initialize with file handle or file object (chunked reading, no full copy)
                const startTime = performance.now();
                videoInfo = await videoDecoder.init(source);
                const initTime = performance.now() - startTime;

                totalFrames = videoInfo.totalFrames;
                fps = videoInfo.fps;

                log(`Video loaded in ${initTime.toFixed(0)}ms`, 'success');
                log(`Codec: ${videoInfo.codec}, Resolution: ${videoInfo.width}x${videoInfo.height}`, 'info');
                log(`Frames: ${totalFrames}, FPS: ${fps.toFixed(2)}, Keyframes: ${videoInfo.keyframes}`, 'info');

                // Show UI
                canvasContainer.style.display = 'block';
                seekbarContainer.style.display = 'block';
                cacheVizContainer.style.display = 'block';
                document.getElementById('infoRow').style.display = 'flex';
                playBtn.disabled = false;
                resetZoomBtn.disabled = false;

                // Initialize overlays (checked by default)
                updateOverlays();

                // Reset state
                currentFrame = 0;
                scale = 1;
                offsetX = 0;
                offsetY = 0;

                updateMetrics();
                renderCacheVisualization();

                // Load first frame
                await seekToFrame(0);

            } catch (err) {
                console.error('Error loading video:', err);
                log(`Error loading video: ${err.message}`, 'error');
                showError('Error loading video: ' + err.message);
            }
        }

        // Use File System Access API if available, otherwise fall back to file input
        loadBtn.addEventListener('click', async () => {
            if ('showOpenFilePicker' in window) {
                console.log('[video-player] Using File System Access API (no file copy)');
                try {
                    const [handle] = await window.showOpenFilePicker({
                        types: [{
                            description: 'Video files',
                            accept: {
                                'video/mp4': ['.mp4', '.m4v'],
                                'video/quicktime': ['.mov'],
                                'video/webm': ['.webm'],
                            }
                        }],
                        multiple: false
                    });
                    await loadVideo(handle);
                } catch (err) {
                    // User cancelled or API error - fall back to file input
                    if (err.name !== 'AbortError') {
                        console.log('File System Access API failed, using fallback:', err);
                        fileInput.click();
                    }
                }
            } else {
                // Browser doesn't support File System Access API
                console.log('[video-player] File System Access API not available, using file input fallback');
                fileInput.click();
            }
        });

        // Fallback file input handler
        fileInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;
            console.log('[video-player] Loading via file input fallback');
            await loadVideo(file);
        });

        // URL loading UI
        const loadUrlBtn = document.getElementById('loadUrlBtn');
        const urlInputContainer = document.getElementById('urlInputContainer');
        const urlInput = document.getElementById('urlInput');
        const urlLoadBtn = document.getElementById('urlLoadBtn');
        const urlCancelBtn = document.getElementById('urlCancelBtn');

        // Pre-populate URL with demo video using current host
        urlInput.value = `${window.location.origin}/video-player/mice.mp4`;

        // Check for URL parameter and auto-load if present
        const urlParams = new URLSearchParams(window.location.search);
        const videoUrl = urlParams.get('url');
        if (videoUrl) {
            log(`Auto-loading from URL parameter: ${videoUrl}`, 'info');
            loadVideo(videoUrl).catch(err => {
                log(`Failed to load URL: ${err.message}`, 'error');
                showError('Failed to load URL: ' + err.message);
            });
        }

        loadUrlBtn.addEventListener('click', () => {
            urlInputContainer.style.display = 'flex';
            urlInput.focus();
        });

        urlCancelBtn.addEventListener('click', () => {
            urlInputContainer.style.display = 'none';
            urlInput.value = '';
        });

        urlLoadBtn.addEventListener('click', async () => {
            const url = urlInput.value.trim();
            if (!url) return;

            urlInputContainer.style.display = 'none';
            log(`Loading from URL: ${url}`, 'info');

            try {
                await loadVideo(url);
                // Update address bar with URL parameter for easy sharing
                const newUrl = new URL(window.location.href);
                newUrl.searchParams.set('url', url);
                history.replaceState(null, '', newUrl);
            } catch (err) {
                log(`Failed to load URL: ${err.message}`, 'error');
                showError('Failed to load URL: ' + err.message);
            }
        });

        // Allow Enter key to submit URL
        urlInput.addEventListener('keydown', (e) => {
            if (e.key === 'Enter') {
                urlLoadBtn.click();
            } else if (e.key === 'Escape') {
                urlCancelBtn.click();
            }
        });

        // Seek to specific frame (with wraparound)
        async function seekToFrame(frameIndex) {
            if (!videoDecoder) return;

            // Modulo wraparound for looping
            if (totalFrames > 0) {
                frameIndex = ((frameIndex % totalFrames) + totalFrames) % totalFrames;
            }

            const startTime = performance.now();
            const result = await videoDecoder.getFrame(frameIndex);
            lastSeekTime = performance.now() - startTime;

            // result can be null if a newer frame request superseded this one
            if (result && result.bitmap) {
                currentFrame = frameIndex;
                currentBitmap = result.bitmap;
                lastFromCache = result.fromCache;
                renderFrame(currentBitmap);

                // Render overlays on top of frame
                renderOverlays({
                    ctx,
                    canvas,
                    frameIndex,
                    totalFrames,
                    seekTime: lastSeekTime,
                    fromCache: result.fromCache,
                    fps,
                    bitmap: result.bitmap,
                    timestamp: videoDecoder.getFrameTimestamp(frameIndex),
                });

                updateMetrics();
                updateSeekbar();
                renderCacheVisualization();

                // Log seek performance (but not too verbose during playback)
                if (!isPlaying) {
                    const cacheStatus = videoDecoder.getCacheStatus();
                    log(`Frame ${frameIndex}: ${result.fromCache ? 'cache hit' : 'decoded'} in ${lastSeekTime.toFixed(0)}ms (${cacheStatus.size}/${cacheStatus.maxSize} cached)`, result.fromCache ? 'success' : 'info');
                }
            }
        }

        // Render frame to canvas
        function renderFrame(bitmap) {
            if (!bitmap) return;

            // Size canvas to fill container at device pixel ratio
            const container = canvasContainer;
            const dpr = window.devicePixelRatio || 1;
            const containerWidth = container.clientWidth;
            const containerHeight = container.clientHeight;

            if (canvas.width !== containerWidth * dpr || canvas.height !== containerHeight * dpr) {
                canvas.width = containerWidth * dpr;
                canvas.height = containerHeight * dpr;
            }

            // Calculate scale to fit video in container (maintaining aspect ratio)
            const videoAspect = bitmap.width / bitmap.height;
            const containerAspect = containerWidth / containerHeight;
            let baseScale, drawX, drawY;

            if (videoAspect > containerAspect) {
                // Video is wider - fit to width
                baseScale = containerWidth / bitmap.width;
                drawX = 0;
                drawY = (containerHeight - bitmap.height * baseScale) / 2;
            } else {
                // Video is taller - fit to height
                baseScale = containerHeight / bitmap.height;
                drawX = (containerWidth - bitmap.width * baseScale) / 2;
                drawY = 0;
            }

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.save();
            ctx.scale(dpr, dpr); // Scale for high DPI

            // Use nearest neighbor interpolation when zoomed in enough to see pixels
            const effectiveScale = baseScale * scale;
            ctx.imageSmoothingEnabled = effectiveScale < 2;

            ctx.translate(offsetX, offsetY);
            ctx.translate(drawX, drawY);
            ctx.scale(effectiveScale, effectiveScale);
            ctx.drawImage(bitmap, 0, 0);
            ctx.restore();
        }

        // Update metrics display
        function updateMetrics() {
            document.getElementById('metricFile').textContent = fileName;
            document.getElementById('metricCodec').textContent = videoInfo ? videoInfo.codec : '-';
            document.getElementById('metricRes').textContent = videoInfo ? `${videoInfo.width}x${videoInfo.height}` : '-';
            document.getElementById('metricFrame').textContent = currentFrame;
            document.getElementById('metricTotal').textContent = totalFrames;
            document.getElementById('metricFps').textContent = fps.toFixed(2);
            document.getElementById('metricSeek').textContent = lastSeekTime.toFixed(0) + 'ms';

            const cacheStatus = videoDecoder ? videoDecoder.getCacheStatus() : { size: 0, maxSize: 0 };
            document.getElementById('metricCached').textContent = `${cacheStatus.size}/${cacheStatus.maxSize}`;
            document.getElementById('metricKeyframes').textContent = videoInfo ? videoInfo.keyframes : '-';
        }

        // Update seekbar position
        function updateSeekbar() {
            const progress = totalFrames > 0 ? (currentFrame / totalFrames) * 100 : 0;
            seekbarProgress.style.width = progress + '%';
            seekbarThumb.style.left = progress + '%';
        }

        // Keyboard shortcuts
        document.addEventListener('keydown', (e) => {
            if (!videoDecoder) return;

            let delta = 0;

            if (e.key === 'ArrowLeft') {
                delta = e.ctrlKey ? -30 : -1;
                e.preventDefault();
            } else if (e.key === 'ArrowRight') {
                delta = e.ctrlKey ? 30 : 1;
                e.preventDefault();
            } else if (e.key === 'ArrowUp') {
                // Zoom in (centered on canvas)
                const zoomFactor = e.ctrlKey ? 1.5 : 1.1;
                const newScale = Math.min(50, scale * zoomFactor);
                const rect = canvasContainer.getBoundingClientRect();
                const centerX = rect.width / 2;
                const centerY = rect.height / 2;
                offsetX = centerX - (centerX - offsetX) * (newScale / scale);
                offsetY = centerY - (centerY - offsetY) * (newScale / scale);
                scale = newScale;
                constrainOffset();
                renderFrameWithOverlays();
                e.preventDefault();
            } else if (e.key === 'ArrowDown') {
                // Zoom out (centered on canvas)
                const zoomFactor = e.ctrlKey ? 0.67 : 0.9;
                const newScale = Math.max(0.1, scale * zoomFactor);
                const rect = canvasContainer.getBoundingClientRect();
                const centerX = rect.width / 2;
                const centerY = rect.height / 2;
                offsetX = centerX - (centerX - offsetX) * (newScale / scale);
                offsetY = centerY - (centerY - offsetY) * (newScale / scale);
                scale = newScale;
                constrainOffset();
                renderFrameWithOverlays();
                e.preventDefault();
            } else if (e.key === ' ') {
                togglePlayback();
                e.preventDefault();
            }

            if (delta !== 0) {
                seekToFrame(currentFrame + delta);
            }
        });

        // Seekbar scrubbing
        let isScrubbing = false;

        function handleSeekbarInteraction(e) {
            const rect = seekbar.getBoundingClientRect();
            const x = Math.max(0, Math.min(e.clientX - rect.left, rect.width));
            const percent = x / rect.width;
            const frame = Math.floor(percent * totalFrames);
            seekToFrame(frame);
        }

        seekbar.addEventListener('mousedown', (e) => {
            e.preventDefault();
            isScrubbing = true;
            document.body.style.userSelect = 'none'; // Prevent text selection while dragging
            handleSeekbarInteraction(e);
        });

        document.addEventListener('mousemove', (e) => {
            if (isScrubbing) {
                handleSeekbarInteraction(e);
            }
        });

        // Zoom with mouse wheel (zoom towards cursor)
        canvasContainer.addEventListener('wheel', (e) => {
            e.preventDefault();

            // Get cursor position relative to container
            const rect = canvasContainer.getBoundingClientRect();
            const mouseX = e.clientX - rect.left;
            const mouseY = e.clientY - rect.top;

            // Normalize deltaY for different input devices
            // Mouse wheels: ~100-120 per tick, fewer events
            // Trackpads: smaller values but many more events, plus momentum
            let delta = e.deltaY;
            if (e.deltaMode === 1) delta *= 40; // line mode (rare, but normalize)

            // Clamp to prevent huge jumps from trackpad momentum
            delta = Math.max(-100, Math.min(100, delta));

            // Use exponential scaling: ~10% zoom per 100px of scroll
            const zoomFactor = Math.exp(-delta * 0.001);
            const newScale = Math.max(0.1, Math.min(50, scale * zoomFactor));

            // Adjust offset to zoom towards cursor position
            // The point under cursor should stay fixed after zoom
            offsetX = mouseX - (mouseX - offsetX) * (newScale / scale);
            offsetY = mouseY - (mouseY - offsetY) * (newScale / scale);

            scale = newScale;
            constrainOffset();
            renderFrameWithOverlays();
        });

        // Pan with mouse drag
        canvasContainer.addEventListener('mousedown', (e) => {
            isDragging = true;
            dragStartX = e.clientX - offsetX;
            dragStartY = e.clientY - offsetY;
        });

        document.addEventListener('mousemove', (e) => {
            if (isDragging) {
                offsetX = e.clientX - dragStartX;
                offsetY = e.clientY - dragStartY;
                constrainOffset();
                renderFrameWithOverlays();
            }
        });

        document.addEventListener('mouseup', () => {
            if (isScrubbing) {
                document.body.style.userSelect = ''; // Restore text selection
            }
            isDragging = false;
            isScrubbing = false;
        });

        // Pinch-to-zoom for touch devices
        let initialPinchDistance = null;
        let initialPinchScale = null;
        let pinchCenterX = null;
        let pinchCenterY = null;

        function getTouchDistance(touches) {
            const dx = touches[0].clientX - touches[1].clientX;
            const dy = touches[0].clientY - touches[1].clientY;
            return Math.sqrt(dx * dx + dy * dy);
        }

        function getTouchCenter(touches, rect) {
            return {
                x: (touches[0].clientX + touches[1].clientX) / 2 - rect.left,
                y: (touches[0].clientY + touches[1].clientY) / 2 - rect.top
            };
        }

        canvasContainer.addEventListener('touchstart', (e) => {
            if (e.touches.length === 2) {
                e.preventDefault();
                initialPinchDistance = getTouchDistance(e.touches);
                initialPinchScale = scale;
                const rect = canvasContainer.getBoundingClientRect();
                const center = getTouchCenter(e.touches, rect);
                pinchCenterX = center.x;
                pinchCenterY = center.y;
            }
        }, { passive: false });

        canvasContainer.addEventListener('touchmove', (e) => {
            if (e.touches.length === 2 && initialPinchDistance !== null) {
                e.preventDefault();
                const currentDistance = getTouchDistance(e.touches);
                const pinchRatio = currentDistance / initialPinchDistance;
                const newScale = Math.max(0.1, Math.min(50, initialPinchScale * pinchRatio));

                // Zoom towards pinch center
                offsetX = pinchCenterX - (pinchCenterX - offsetX) * (newScale / scale);
                offsetY = pinchCenterY - (pinchCenterY - offsetY) * (newScale / scale);

                scale = newScale;
                constrainOffset();
                renderFrameWithOverlays();
            }
        }, { passive: false });

        canvasContainer.addEventListener('touchend', (e) => {
            if (e.touches.length < 2) {
                initialPinchDistance = null;
                initialPinchScale = null;
                pinchCenterX = null;
                pinchCenterY = null;
            }
        });

        // Single-finger pan for touch devices
        let touchStartX = null;
        let touchStartY = null;
        let touchStartOffsetX = null;
        let touchStartOffsetY = null;

        canvasContainer.addEventListener('touchstart', (e) => {
            if (e.touches.length === 1) {
                touchStartX = e.touches[0].clientX;
                touchStartY = e.touches[0].clientY;
                touchStartOffsetX = offsetX;
                touchStartOffsetY = offsetY;
            }
        });

        canvasContainer.addEventListener('touchmove', (e) => {
            if (e.touches.length === 1 && touchStartX !== null) {
                e.preventDefault();
                offsetX = touchStartOffsetX + (e.touches[0].clientX - touchStartX);
                offsetY = touchStartOffsetY + (e.touches[0].clientY - touchStartY);
                constrainOffset();
                renderFrameWithOverlays();
            }
        }, { passive: false });

        canvasContainer.addEventListener('touchend', (e) => {
            if (e.touches.length === 0) {
                touchStartX = null;
                touchStartY = null;
                touchStartOffsetX = null;
                touchStartOffsetY = null;
            }
        });

        // Reset zoom
        resetZoomBtn.addEventListener('click', () => {
            scale = 1;
            offsetX = 0;
            offsetY = 0;
            renderFrameWithOverlays();
        });

        // Playback
        function togglePlayback() {
            if (isPlaying) {
                stopPlayback();
            } else {
                startPlayback();
            }
        }

        function startPlayback() {
            if (!videoDecoder) return;

            isPlaying = true;
            playBtn.textContent = 'Pause';
            log(`Playback started at frame ${currentFrame}`, 'info');

            const interval = 1000 / fps;

            playInterval = setInterval(async () => {
                // Loop continuously - seekToFrame handles wraparound
                await seekToFrame(currentFrame + 1);
            }, interval);
        }

        function stopPlayback() {
            const wasPlaying = isPlaying;
            isPlaying = false;
            playBtn.textContent = 'Play';
            if (playInterval) {
                clearInterval(playInterval);
                playInterval = null;
            }
            if (wasPlaying) {
                log(`Playback stopped at frame ${currentFrame}`, 'info');
            }
        }

        playBtn.addEventListener('click', togglePlayback);

        // Update cache size
        bufferSizeInput.addEventListener('change', () => {
            const newSize = parseInt(bufferSizeInput.value);
            if (newSize >= 10 && newSize <= 500 && videoDecoder) {
                videoDecoder.cacheSize = newSize;
                log(`Cache size updated to ${newSize}`, 'info');
                updateMetrics();
                renderCacheVisualization();
            }
        });

        // Update lookahead size
        lookaheadInput.addEventListener('change', () => {
            const newSize = parseInt(lookaheadInput.value);
            if (newSize >= 1 && newSize <= 100 && videoDecoder) {
                videoDecoder.lookahead = newSize;
                log(`Lookahead updated to ${newSize}`, 'info');
            }
        });

        // Overlay toggle handlers
        document.getElementById('showFrameIndex').addEventListener('change', updateOverlays);
        document.getElementById('showTimingStats').addEventListener('change', updateOverlays);

        // Re-render cache viz on window resize
        window.addEventListener('resize', () => {
            if (videoDecoder && totalFrames > 0) {
                renderCacheVisualization();
            }
        });
    </script>
</body>
</html>
