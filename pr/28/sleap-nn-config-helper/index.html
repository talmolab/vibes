<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLEAP-NN Config Helper</title>
    <script src="https://cdn.jsdelivr.net/npm/js-yaml@4.1.0/dist/js-yaml.min.js"></script>
    <style>
        * { box-sizing: border-box; }

        :root {
            --bg: #1a1a2e;
            --surface: #252542;
            --surface-hover: #2d2d4a;
            --border: #3a3a5c;
            --text: #e8e8f0;
            --text-dim: #8888aa;
            --accent: #6c63ff;
            --accent-dim: #5551cc;
            --success: #4ade80;
            --warning: #fbbf24;
            --error: #f87171;
        }

        body {
            font-family: system-ui, -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            margin: 0;
            padding: 20px;
            min-height: 100vh;
        }

        .container { max-width: 1400px; margin: 0 auto; }

        header { margin-bottom: 24px; }
        h1 { margin: 0 0 8px 0; font-size: 1.8rem; }
        .subtitle { color: var(--text-dim); margin: 0; }

        /* Layout */
        .main-layout {
            display: grid;
            grid-template-columns: 350px 1fr;
            gap: 24px;
        }

        @media (max-width: 900px) {
            .main-layout { grid-template-columns: 1fr; }
        }

        /* Sidebar */
        .sidebar {
            display: flex;
            flex-direction: column;
            gap: 16px;
        }

        /* Tabs */
        .tabs {
            display: flex;
            gap: 4px;
            border-bottom: 2px solid var(--border);
            margin-bottom: 20px;
        }

        .tab {
            padding: 10px 16px;
            background: transparent;
            border: none;
            color: var(--text-dim);
            font-size: 0.9rem;
            cursor: pointer;
            border-radius: 8px 8px 0 0;
            transition: all 0.2s;
        }
        .tab:hover { background: var(--surface); color: var(--text); }
        .tab.active { background: var(--surface); color: var(--accent); font-weight: 600; }

        /* Internal/Sub tabs for Top-Down pipeline */
        .sub-tabs {
            display: flex;
            gap: 8px;
            margin-bottom: 16px;
        }
        .sub-tab {
            padding: 8px 16px;
            background: var(--card);
            border: 1px solid var(--border);
            color: var(--text-dim);
            font-size: 0.85rem;
            cursor: pointer;
            border-radius: 6px;
            transition: all 0.2s;
        }
        .sub-tab:hover { background: var(--border); }
        .sub-tab.active {
            background: var(--accent);
            color: white;
            border-color: var(--accent);
        }
        .sub-panel { display: none; }
        .sub-panel.active { display: block; }

        /* Model selector tabs on accent background */
        #training-model-selector .sub-tab,
        #config-topdown > .card .sub-tab {
            background: rgba(255,255,255,0.2);
            border-color: rgba(255,255,255,0.3);
            color: rgba(255,255,255,0.9);
        }
        #training-model-selector .sub-tab:hover,
        #config-topdown > .card .sub-tab:hover {
            background: rgba(255,255,255,0.3);
        }
        #training-model-selector .sub-tab.active,
        #config-topdown > .card .sub-tab.active {
            background: white;
            color: var(--accent);
            border-color: white;
        }

        .tab-panel { display: none; }
        .tab-panel.active { display: block; }

        /* Cards */
        .card {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 16px;
        }

        .card h2 { margin: 0 0 14px 0; font-size: 1rem; }
        .card h3 { margin: 14px 0 10px 0; font-size: 0.9rem; color: var(--text-dim); }

        /* File inputs */
        .file-group { margin-bottom: 12px; }
        .file-group label { display: block; margin-bottom: 6px; color: var(--text-dim); font-size: 0.8rem; }
        .file-group input[type="file"] { display: none; }

        .file-btn {
            display: inline-block;
            padding: 8px 16px;
            background: var(--accent);
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.85rem;
        }
        .file-btn:hover { background: var(--accent-dim); }
        .file-btn.secondary { background: var(--border); }

        .file-status { margin-top: 6px; font-size: 0.75rem; color: var(--text-dim); }
        .file-status.loaded { color: var(--success); }

        /* Frame Viewer */
        .viewer-container {
            background: var(--bg);
            border-radius: 8px;
            padding: 8px;
            position: relative;
        }

        .viewer-canvas {
            width: 100%;
            height: auto;
            display: block;
            border-radius: 4px;
        }

        .frame-controls {
            display: flex;
            align-items: center;
            gap: 8px;
            margin-top: 8px;
        }

        .frame-slider {
            flex: 1;
            height: 4px;
            background: var(--border);
            border-radius: 2px;
            -webkit-appearance: none;
        }

        .frame-slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 14px;
            height: 14px;
            background: var(--accent);
            border-radius: 50%;
            cursor: pointer;
        }

        .frame-info { font-size: 0.75rem; color: var(--text-dim); min-width: 80px; text-align: right; }

        /* Stats */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 8px;
        }

        .stat-card {
            background: var(--bg);
            border-radius: 6px;
            padding: 10px;
        }

        .stat-label { color: var(--text-dim); font-size: 0.7rem; margin-bottom: 2px; }
        .stat-value { font-size: 1.1rem; font-weight: 600; }
        .stat-detail { color: var(--text-dim); font-size: 0.65rem; margin-top: 2px; }

        /* Recommendation */
        .recommendation-box {
            background: linear-gradient(135deg, rgba(108, 99, 255, 0.1), rgba(74, 222, 128, 0.05));
            border: 1px solid var(--accent);
            border-radius: 8px;
            padding: 14px;
        }

        .recommendation-box h3 { margin: 0 0 10px 0; font-size: 0.9rem; color: var(--accent); }

        .pipeline-badge {
            display: inline-block;
            background: var(--accent);
            color: white;
            padding: 6px 14px;
            border-radius: 20px;
            font-weight: 600;
            font-size: 0.9rem;
        }

        .rec-details { margin-top: 10px; font-size: 0.8rem; color: var(--text-dim); }
        .rec-details li { margin-bottom: 4px; }

        /* Form controls */
        .form-group { margin-bottom: 14px; }
        .form-group label { display: block; margin-bottom: 5px; font-size: 0.8rem; color: var(--text-dim); }

        .form-row { display: flex; gap: 12px; flex-wrap: wrap; }
        .form-row .form-group { flex: 1; min-width: 120px; }

        select, input[type="number"], input[type="text"] {
            width: 100%;
            padding: 8px 10px;
            background: var(--bg);
            border: 1px solid var(--border);
            border-radius: 6px;
            color: var(--text);
            font-size: 0.85rem;
        }

        select:focus, input:focus { outline: none; border-color: var(--accent); }

        /* Radio options */
        .radio-group { display: flex; flex-direction: column; gap: 8px; }

        .radio-option {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 10px 12px;
            background: var(--bg);
            border: 1px solid var(--border);
            border-radius: 8px;
            cursor: pointer;
            transition: border-color 0.2s;
        }

        .radio-option:hover { border-color: var(--accent-dim); }
        .radio-option.selected { border-color: var(--accent); background: rgba(108, 99, 255, 0.1); }
        .radio-option input[type="radio"] { accent-color: var(--accent); }
        .radio-option strong { font-size: 0.9rem; }
        .radio-option .desc { font-size: 0.75rem; color: var(--text-dim); }

        /* Sliders */
        .slider-group { margin-bottom: 14px; }
        .slider-header { display: flex; justify-content: space-between; margin-bottom: 6px; }
        .slider-label { font-size: 0.8rem; color: var(--text-dim); }
        .slider-value { font-size: 0.85rem; font-weight: 600; color: var(--accent); }

        input[type="range"] {
            width: 100%;
            height: 5px;
            background: var(--border);
            border-radius: 3px;
            -webkit-appearance: none;
        }

        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 16px;
            height: 16px;
            background: var(--accent);
            border-radius: 50%;
            cursor: pointer;
        }

        /* Visualization canvas */
        .viz-canvas {
            background: var(--bg);
            border-radius: 8px;
            display: block;
        }

        .viz-legend {
            font-size: 0.7rem;
            color: var(--text-dim);
            text-align: center;
            margin-top: 4px;
        }

        /* Status boxes */
        .status-box {
            padding: 10px;
            border-radius: 6px;
            font-size: 0.8rem;
            background: var(--bg);
            border-left: 3px solid var(--text-dim);
        }

        /* Tooltips */
        .tooltip-icon {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 14px;
            height: 14px;
            border-radius: 50%;
            background: var(--border);
            color: var(--text-dim);
            font-size: 10px;
            font-weight: 600;
            cursor: help;
            margin-left: 4px;
            position: relative;
            vertical-align: middle;
        }
        .tooltip-icon:hover {
            background: var(--accent);
            color: white;
        }
        .tooltip-icon .tooltip-text {
            visibility: hidden;
            opacity: 0;
            position: absolute;
            bottom: calc(100% + 8px);
            left: 50%;
            transform: translateX(-50%);
            background: #1a1a2e;
            color: var(--text);
            padding: 8px 12px;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 400;
            width: 220px;
            text-align: left;
            line-height: 1.4;
            z-index: 100;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
            border: 1px solid var(--border);
            transition: opacity 0.2s, visibility 0.2s;
        }
        .tooltip-icon .tooltip-text::after {
            content: '';
            position: absolute;
            top: 100%;
            left: 50%;
            transform: translateX(-50%);
            border: 6px solid transparent;
            border-top-color: var(--border);
        }
        .tooltip-icon:hover .tooltip-text {
            visibility: visible;
            opacity: 1;
        }
        /* Tooltip on right for labels near left edge */
        .tooltip-icon.tooltip-right .tooltip-text {
            left: 0;
            transform: translateX(0);
        }
        .tooltip-icon.tooltip-right .tooltip-text::after {
            left: 10px;
            transform: none;
        }

        /* Memory */
        .gpu-cards { display: flex; gap: 8px; flex-wrap: wrap; }

        .gpu-card {
            padding: 10px;
            background: var(--bg);
            border-radius: 6px;
            text-align: center;
            min-width: 70px;
            flex: 1;
        }

        .gpu-card .name { font-size: 0.7rem; color: var(--text-dim); }
        .gpu-card .mem { font-size: 0.9rem; font-weight: 600; }
        .gpu-card .status { font-size: 0.7rem; margin-top: 4px; }

        /* Node tags */
        .node-list { display: flex; flex-wrap: wrap; gap: 4px; }
        .node-tag { background: var(--border); padding: 3px 6px; border-radius: 4px; font-size: 0.7rem; }

        /* Loading */
        .loading { display: none; align-items: center; gap: 10px; padding: 12px; background: var(--surface); border-radius: 8px; margin-bottom: 16px; }
        .loading.visible { display: flex; }
        .spinner { width: 18px; height: 18px; border: 2px solid var(--border); border-top-color: var(--accent); border-radius: 50%; animation: spin 1s linear infinite; }
        @keyframes spin { to { transform: rotate(360deg); } }

        /* Log */
        .log-section { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 12px; margin-top: 20px; }
        .log-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 8px; }
        .log-header h3 { margin: 0; font-size: 0.8rem; color: var(--text-dim); }
        .log-toggle { background: none; border: none; color: var(--text-dim); cursor: pointer; font-size: 0.75rem; }
        .log-content { font-family: monospace; font-size: 0.7rem; max-height: 120px; overflow-y: auto; background: var(--bg); border-radius: 4px; padding: 8px; }
        .log-content.collapsed { display: none; }
        .log-entry { margin-bottom: 2px; }
        .log-entry.success { color: var(--success); }
        .log-entry.warn { color: var(--warning); }
        .log-entry.error { color: var(--error); }
        .log-entry.info { color: var(--text-dim); }

        /* YAML output */
        .yaml-output {
            background: var(--bg);
            border-radius: 8px;
            padding: 14px;
            font-family: monospace;
            font-size: 0.75rem;
            max-height: 400px;
            overflow-y: auto;
            white-space: pre-wrap;
        }

        .export-buttons { display: flex; gap: 10px; margin-top: 12px; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>SLEAP-NN Config Helper</h1>
            <p class="subtitle">Load your data, choose a model, and export training configuration</p>
        </header>

        <div class="loading" id="loading">
            <div class="spinner"></div>
            <span id="loading-text">Loading...</span>
        </div>

        <div class="main-layout">
            <!-- ==================== SIDEBAR ==================== -->
            <div class="sidebar">
                <!-- File Loading -->
                <div class="card">
                    <h2>Load Data</h2>
                    <div class="file-group">
                        <label>SLP Labels File <span class="tooltip-icon">?<span class="tooltip-text">SLEAP labels file (.slp) containing your skeleton, labeled frames, and video paths.</span></span></label>
                        <label class="file-btn" for="slp-input">Choose SLP</label>
                        <input type="file" id="slp-input" accept=".slp">
                        <div class="file-status" id="slp-status">No file loaded</div>
                    </div>
                    <div class="file-group">
                        <label>Video File <span class="tooltip-icon">?<span class="tooltip-text">Optional video to preview preprocessing and augmentations. Useful for visualizations.</span></span></label>
                        <label class="file-btn secondary" for="video-input">Choose Video</label>
                        <input type="file" id="video-input" accept=".mp4,.avi,.mov">
                        <div class="file-status" id="video-status">No video loaded</div>
                    </div>
                    <div class="file-group">
                        <label>Existing Config <span class="tooltip-icon">?<span class="tooltip-text">Load an existing sleap-nn YAML config to edit. All settings will be populated from the file.</span></span></label>
                        <label class="file-btn secondary" for="yaml-input">Load YAML</label>
                        <input type="file" id="yaml-input" accept=".yaml,.yml">
                        <div class="file-status" id="yaml-status">No config loaded</div>
                    </div>
                </div>

                <!-- Frame Viewer -->
                <div class="card" id="viewer-card" style="display: none;">
                    <h2>Frame Viewer</h2>
                    <div class="viewer-container">
                        <canvas id="viewer-canvas" class="viewer-canvas" width="320" height="240"></canvas>
                        <div class="frame-controls">
                            <input type="range" id="frame-slider" class="frame-slider" min="0" max="100" value="0">
                            <span class="frame-info" id="frame-info">0 / 0</span>
                        </div>
                    </div>
                </div>

                <!-- Data Stats -->
                <div class="card" id="stats-card" style="display: none;">
                    <h2>Data Analysis</h2>
                    <div class="stats-grid">
                        <div class="stat-card">
                            <div class="stat-label">Frames</div>
                            <div class="stat-value" id="stat-frames">-</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-label">Keypoints</div>
                            <div class="stat-value" id="stat-keypoints">-</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-label">Instances/Frame</div>
                            <div class="stat-value" id="stat-instances">-</div>
                            <div class="stat-detail" id="stat-instances-detail"></div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-label">Max Instance Size</div>
                            <div class="stat-value" id="stat-size">-</div>
                            <div class="stat-detail" id="stat-size-detail"></div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-label">Tracks</div>
                            <div class="stat-value" id="stat-tracks">-</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-label">Overlap</div>
                            <div class="stat-value" id="stat-overlap">-</div>
                        </div>
                    </div>
                    <h3>Skeleton Nodes</h3>
                    <div class="node-list" id="node-list"></div>
                    <h3>Skeleton Edges</h3>
                    <div class="node-list" id="edge-list"></div>
                </div>
            </div>

            <!-- ==================== MAIN CONTENT ==================== -->
            <div class="main-content">
                <div class="tabs">
                    <button class="tab active" data-tab="model">Model</button>
                    <button class="tab" data-tab="training">Training</button>
                    <button class="tab" data-tab="export">Export</button>
                </div>

                <!-- ==================== MODEL TAB ==================== -->
                <div class="tab-panel active" id="panel-model">
                    <!-- Recommendation (shown after SLP load) -->
                    <div class="card" id="rec-card" style="display: none;">
                        <div class="recommendation-box">
                            <h3>Recommended Pipeline</h3>
                            <span class="pipeline-badge" id="rec-pipeline">-</span>
                            <ul class="rec-details" id="rec-details"></ul>
                        </div>
                    </div>
                    <div class="card">
                        <h2>Pipeline Type</h2>
                        <div class="radio-group" id="pipeline-options">
                            <label class="radio-option" id="pipeline-single-instance-label">
                                <input type="radio" name="pipeline" value="single_instance" id="pipeline-single-instance">
                                <div>
                                    <strong>Single Instance</strong>
                                    <div class="desc">Best for videos with exactly one animal per frame</div>
                                    <div class="desc" id="single-instance-disabled-msg" style="display: none; color: var(--warning); margin-top: 4px; font-weight: 500;"></div>
                                </div>
                            </label>
                            <label class="radio-option selected">
                                <input type="radio" name="pipeline" value="topdown" checked>
                                <div>
                                    <strong>Top-Down</strong>
                                    <div class="desc">Best for multiple well-separated animals that are small relative to the frame; finds each animal first, then estimates pose</div>
                                </div>
                            </label>
                            <label class="radio-option">
                                <input type="radio" name="pipeline" value="bottomup">
                                <div>
                                    <strong>Bottom-Up</strong>
                                    <div class="desc">Best for crowded/overlapping animals; detects all parts, then groups into instances</div>
                                </div>
                            </label>
                        </div>
                        <!-- Multi-Class Option (enabled when tracks detected) -->
                        <div id="multi-class-option" style="margin-top: 12px; padding: 12px; background: var(--bg); border-radius: 8px; border: 1px solid var(--border);">
                            <label style="display: flex; align-items: flex-start; gap: 10px; cursor: pointer;">
                                <input type="checkbox" id="config-multi-class" style="width: auto; margin-top: 3px;" disabled>
                                <div>
                                    <strong>Enable Multi-Class (Identity Tracking)</strong>
                                    <div class="desc" style="font-size: 0.85rem; color: var(--text-dim); margin-top: 4px;">
                                        Adds identity classification heads to assign IDs (labels) to each instance.
                                        <span id="multi-class-tracks-info" style="color: var(--warning);">Requires identity tracks in your SLP file.</span>
                                    </div>
                                </div>
                            </label>
                        </div>
                    </div>

                    <!-- ===== SINGLE INSTANCE / BOTTOM-UP CONFIG ===== -->
                    <div id="config-shared" style="display: none;">
                        <div class="card">
                            <h2>Backbone</h2>
                            <div class="form-row">
                                <div class="form-group">
                                    <label>Architecture <span class="tooltip-icon">?<span class="tooltip-text">UNet: lightweight, good default. ConvNeXt/SwinT: modern architectures with pretrained weights, better for complex scenes.</span></span></label>
                                    <select id="config-backbone">
                                        <option value="unet">UNet</option>
                                        <option value="convnext">ConvNeXt</option>
                                        <option value="swint">SwinT</option>
                                    </select>
                                </div>
                                <div class="form-group" id="shared-max-stride-group">
                                    <label>Max Stride <span class="tooltip-icon">?<span class="tooltip-text">Maximum stride which determines the number of encoder blocks (log₂(max_stride)). Higher values = larger receptive field but lower resolution features. Use 16 for small animals, 32-64 for larger ones.</span></span></label>
                                    <select id="config-max-stride">
                                        <option value="8">8</option>
                                        <option value="16" selected>16</option>
                                        <option value="32">32</option>
                                        <option value="64">64</option>
                                    </select>
                                </div>
                                <div class="form-group" id="shared-model-type-group" style="display: none;">
                                    <label>Model Size <span class="tooltip-icon">?<span class="tooltip-text">Model capacity. Tiny is fastest, Large has most parameters. Start with Tiny/Small.</span></span></label>
                                    <select id="config-model-type">
                                        <option value="tiny" selected>Tiny</option>
                                        <option value="small">Small</option>
                                        <option value="base">Base</option>
                                        <option value="large">Large</option>
                                    </select>
                                    <label style="display: flex; align-items: center; gap: 6px; margin-top: 8px; font-size: 0.8rem; cursor: pointer;">
                                        <input type="checkbox" id="config-pretrained" style="width: auto;">
                                        Use pretrained weights (ImageNet)
                                    </label>
                                </div>
                            </div>
                            <div class="form-row" id="shared-unet-params">
                                <div class="form-group">
                                    <label>Input Channels <span class="tooltip-icon">?<span class="tooltip-text">Auto-detected from video. Use grayscale (1) unless color is essential for distinguishing body parts.</span></span></label>
                                    <select id="config-in-channels">
                                        <option value="1" selected>1 (Grayscale)</option>
                                        <option value="3">3 (RGB)</option>
                                    </select>
                                </div>
                                <div class="form-group">
                                    <label>Filters <span class="tooltip-icon">?<span class="tooltip-text">Base number of filters in the first encoder block. Channels per block = filters × rate^block. More filters = more capacity but slower training and more memory. Default: 16-32.</span></span></label>
                                    <input type="number" id="config-filters" value="32" min="8" max="64">
                                </div>
                                <div class="form-group">
                                    <label>Filters Rate <span class="tooltip-icon">?<span class="tooltip-text">Factor to multiply filters per encoder block (filters × rate^block). With rate=1.5 and filters=32: 32→48→72→108. Default: 1.5 for UNet, 2.0 for ConvNeXt/SwinT.</span></span></label>
                                    <input type="number" id="config-filters-rate" value="1.5" min="1.0" max="3.0" step="0.5">
                                </div>
                            </div>
                        </div>

                        <div class="card">
                            <h2>Head Config</h2>
                            <!-- Single Instance Head -->
                            <div id="head-single-instance" class="head-config" style="display: none;">
                                <div class="form-row">
                                    <div class="form-group">
                                        <label>Sigma <span class="tooltip-icon">?<span class="tooltip-text">Spread of the Gaussian distribution of confidence maps (pixels at model input resolution). Each keypoint has its own channel, so overlap is not a concern. Smaller values are more precise but harder to learn. Default: 2.5</span></span></label>
                                        <input type="number" id="config-si-sigma" value="2.5" min="1.0" max="15.0" step="0.5">
                                    </div>
                                    <div class="form-group">
                                        <label>Output Stride <span class="tooltip-icon">?<span class="tooltip-text">Stride of output confidence maps relative to input. Stride of 2 = 0.5× resolution. Higher values speed up training and reduce memory, but decrease spatial precision. Must be ≤ max_stride.</span></span></label>
                                        <select id="config-si-stride">
                                            <option value="1" selected>1</option>
                                            <option value="2">2</option>
                                            <option value="4">4</option>
                                            <option value="8">8</option>
                                            <option value="16">16</option>
                                            <option value="32">32</option>
                                            <option value="64">64</option>
                                        </select>
                                    </div>
                                </div>
                                <div id="si-sigma-info" style="font-size: 0.75rem; color: var(--text-dim); margin-top: 4px;">
                                    <span id="si-sigma-suggest">Default: 2.5 (each keypoint has its own channel)</span>
                                </div>
                            </div>

                            <!-- Bottom-Up Head -->
                            <div id="head-bottomup" class="head-config" style="display: none;">
                                <h3 style="margin-top: 0; color: var(--accent);">Confidence Maps</h3>
                                <div class="form-row">
                                    <div class="form-group">
                                        <label>Sigma <span class="tooltip-icon">?<span class="tooltip-text">Spread of the Gaussian distribution of confidence maps (pixels at model input resolution). Each keypoint has its own channel, so overlap is not a concern. Smaller values are more precise but harder to learn. Default: 2.5</span></span></label>
                                        <input type="number" id="config-bu-sigma" value="2.5" min="1.0" max="15.0" step="0.5">
                                    </div>
                                    <div class="form-group">
                                        <label>Output Stride <span class="tooltip-icon">?<span class="tooltip-text">Stride of output confidence maps relative to input. Stride of 2 = 0.5× resolution. Higher values speed up training and reduce memory, but decrease spatial precision.</span></span></label>
                                        <select id="config-bu-stride">
                                            <option value="1" selected>1</option>
                                            <option value="2">2</option>
                                            <option value="4">4</option>
                                            <option value="8">8</option>
                                            <option value="16">16</option>
                                            <option value="32">32</option>
                                            <option value="64">64</option>
                                        </select>
                                    </div>
                                    <div class="form-group">
                                        <label>Loss Weight <span class="tooltip-icon">?<span class="tooltip-text">Scalar to weigh this head's loss during training. Increase to focus optimization on this output in multi-head models. Default: 1.0</span></span></label>
                                        <input type="number" id="config-bu-confmap-weight" value="1.0" min="0.1" max="10.0" step="0.1">
                                    </div>
                                </div>
                                <h3 style="color: var(--accent);">Part Affinity Fields (PAFs)</h3>
                                <div class="form-row">
                                    <div class="form-group">
                                        <label>PAF Sigma <span class="tooltip-icon">?<span class="tooltip-text">Spread of PAF vector fields connecting keypoints. Higher sigma (15+) is typical for PAFs since they benefit from broader spatial spread. Default: 15.0</span></span></label>
                                        <input type="number" id="config-paf-sigma" value="15.0" min="5.0" max="50.0" step="1.0">
                                    </div>
                                    <div class="form-group">
                                        <label>PAF Stride <span class="tooltip-icon">?<span class="tooltip-text">Stride of output PAF maps relative to input. Usually matches confidence map output stride. Default: 1</span></span></label>
                                        <select id="config-paf-stride">
                                            <option value="1" selected>1</option>
                                            <option value="2">2</option>
                                            <option value="4">4</option>
                                            <option value="8">8</option>
                                            <option value="16">16</option>
                                            <option value="32">32</option>
                                            <option value="64">64</option>
                                        </select>
                                    </div>
                                    <div class="form-group">
                                        <label>PAF Weight <span class="tooltip-icon">?<span class="tooltip-text">Scalar to weigh PAF head loss during training. Increase to focus on grouping if detection is good but grouping is poor. Default: 1.0</span></span></label>
                                        <input type="number" id="config-paf-weight" value="1.0" min="0.1" max="10.0" step="0.1">
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- ===== TOP-DOWN MODEL SELECTOR ===== -->
                    <div id="config-topdown">
                        <div class="card" style="background: var(--accent); padding: 16px;">
                            <div style="display: flex; align-items: center; gap: 16px; flex-wrap: wrap;">
                                <div>
                                    <h2 style="color: white; margin: 0;">Top-Down Models</h2>
                                    <p style="color: rgba(255,255,255,0.8); margin: 4px 0 0 0; font-size: 0.85rem;">
                                        Select which model to configure:
                                    </p>
                                </div>
                                <div class="sub-tabs" style="margin: 0;">
                                    <button class="sub-tab active" data-subtab="centroid">Centroid Model</button>
                                    <button class="sub-tab" data-subtab="centered-instance">Centered Instance Model</button>
                                </div>
                            </div>
                        </div>

                        <!-- Top-Down Info -->
                        <div class="card" id="topdown-info" style="border-color: var(--accent);">
                            <p style="font-size: 0.85rem; color: var(--text-dim); margin: 0 0 12px 0;">
                                Top-down requires training <strong>two models</strong>:
                            </p>
                            <div class="stats-grid">
                                <div class="stat-card">
                                    <div class="stat-label">Model 1</div>
                                    <div class="stat-value" style="font-size: 0.9rem;">Centroid</div>
                                    <div class="stat-detail">Detects animal centers</div>
                                </div>
                                <div class="stat-card">
                                    <div class="stat-label">Model 2</div>
                                    <div class="stat-value" style="font-size: 0.9rem;">Centered Instance</div>
                                    <div class="stat-detail">Predicts keypoints on crops</div>
                                </div>
                            </div>
                            <p style="font-size: 0.8rem; color: var(--text-dim); margin: 12px 0 0 0;">
                                Use the tabs above to configure each model. Export will generate both configs.
                            </p>
                        </div>

                        <!-- Centroid Model Config -->
                        <div id="subtab-centroid" class="sub-panel active">
                            <div class="card">
                                <h3 style="margin-top: 0; color: var(--accent);">Backbone</h3>
                                <div class="form-row">
                                    <div class="form-group">
                                        <label>Architecture <span class="tooltip-icon">?<span class="tooltip-text">UNet: lightweight, good default. ConvNeXt/SwinT: modern architectures with pretrained weights.</span></span></label>
                                        <select id="config-centroid-backbone">
                                            <option value="unet">UNet</option>
                                            <option value="convnext">ConvNeXt</option>
                                            <option value="swint">SwinT</option>
                                        </select>
                                    </div>
                                    <div class="form-group" id="centroid-max-stride-group">
                                        <label>Max Stride <span class="tooltip-icon">?<span class="tooltip-text">Controls receptive field. For centroid models, typically 16-32 is sufficient since you're detecting instance centers, not fine details.</span></span></label>
                                        <select id="config-centroid-max-stride">
                                            <option value="8">8</option>
                                            <option value="16" selected>16</option>
                                            <option value="32">32</option>
                                            <option value="64">64</option>
                                        </select>
                                    </div>
                                    <div class="form-group" id="centroid-model-type-group" style="display: none;">
                                        <label>Model Size <span class="tooltip-icon">?<span class="tooltip-text">Model capacity. Tiny is fastest, Large has most parameters. Start with Tiny/Small.</span></span></label>
                                        <select id="config-centroid-model-type">
                                            <option value="tiny" selected>Tiny</option>
                                            <option value="small">Small</option>
                                            <option value="base">Base</option>
                                            <option value="large">Large</option>
                                        </select>
                                        <label style="display: flex; align-items: center; gap: 6px; margin-top: 8px; font-size: 0.8rem; cursor: pointer;">
                                            <input type="checkbox" id="config-centroid-pretrained" style="width: auto;">
                                            Use pretrained weights (ImageNet)
                                        </label>
                                    </div>
                                </div>
                                <div class="form-row" id="centroid-unet-params">
                                    <div class="form-group">
                                        <label>Input Channels <span class="tooltip-icon">?<span class="tooltip-text">Auto-detected from video. Use grayscale (1) unless color is essential.</span></span></label>
                                        <select id="config-centroid-in-channels">
                                            <option value="1" selected>1 (Grayscale)</option>
                                            <option value="3">3 (RGB)</option>
                                        </select>
                                    </div>
                                    <div class="form-group">
                                        <label>Filters <span class="tooltip-icon">?<span class="tooltip-text">Base feature channels. More = more capacity but slower. Default: 16 for centroid.</span></span></label>
                                        <input type="number" id="config-centroid-filters" value="16" min="8" max="64">
                                    </div>
                                    <div class="form-group">
                                        <label>Filters Rate <span class="tooltip-icon">?<span class="tooltip-text">Channel multiplier per block. Default: 1.5 for UNet.</span></span></label>
                                        <input type="number" id="config-centroid-filters-rate" value="1.5" min="1.0" max="3.0" step="0.5">
                                    </div>
                                </div>
                                <h3 style="color: var(--accent);">Head Config</h3>
                                <!-- Anchor Part with Visual Picker -->
                                <div style="display: flex; gap: 16px; align-items: flex-start; margin-bottom: 12px;">
                                    <div style="flex: 1;">
                                        <label style="display: block; margin-bottom: 4px;">Anchor Part <span class="tooltip-icon">?<span class="tooltip-text">Node name to use as anchor point. If None, uses midpoint of bounding box of all visible instance points. Choose a reliably visible node (e.g., thorax, nose). Missing values are noted next to each option.</span></span></label>
                                        <select id="config-centroid-anchor" style="width: 100%;">
                                            <option value="">None (use bounding box center)</option>
                                        </select>
                                        <div style="font-size: 0.75rem; margin-top: 4px;">
                                            <span style="color: var(--text-dim);">Click a node to select anchor.</span>
                                            <span id="centroid-anchor-nan-info" style="margin-left: 8px;"></span>
                                        </div>
                                    </div>
                                    <div style="flex-shrink: 0;">
                                        <canvas id="centroid-anchor-viz" width="100" height="100" style="border: 1px solid var(--border); border-radius: 4px; background: var(--bg); cursor: pointer;" title="Click a node to select anchor"></canvas>
                                    </div>
                                </div>
                                <!-- Sigma & Output Stride with Visualization -->
                                <div style="display: flex; gap: 16px; align-items: flex-start;">
                                    <div style="flex: 1;">
                                        <div class="form-row">
                                            <div class="form-group">
                                                <label>Sigma <span class="tooltip-icon">?<span class="tooltip-text">Spread of the Gaussian for centroid confidence maps (pixels at model input resolution). Can use larger sigma (5-10) for centroids since they're spaced further apart than keypoints. Default: 5.0</span></span></label>
                                                <input type="number" id="config-centroid-sigma" value="5.0" min="1.0" max="20.0" step="0.5">
                                            </div>
                                            <div class="form-group">
                                                <label>Output Stride <span class="tooltip-icon">?<span class="tooltip-text">Stride of centroid maps relative to input. Higher strides (2-4) are acceptable for centroids since precise localization is less critical. Speeds up training and reduces memory.</span></span></label>
                                                <select id="config-centroid-stride">
                                                    <option value="1" selected>1</option>
                                                    <option value="2">2</option>
                                                    <option value="4">4</option>
                                                    <option value="8">8</option>
                                                    <option value="16">16</option>
                                                </select>
                                            </div>
                                        </div>
                                        <div id="centroid-sigma-info" style="font-size: 0.75rem; color: var(--text-dim); margin-top: 8px;">
                                            <div>Gaussian spread: <span id="centroid-sigma-radius">10</span>px (2σ covers 95%)</div>
                                            <div style="margin-top: 2px;">Suggested: <span id="centroid-sigma-suggest">5-10</span> for centroids</div>
                                        </div>
                                    </div>
                                    <div style="flex-shrink: 0;">
                                        <canvas id="centroid-sigma-viz" width="80" height="80" style="border: 1px solid var(--border); border-radius: 4px; background: var(--bg);"></canvas>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <!-- Centered Instance Model Config -->
                        <div id="subtab-centered-instance" class="sub-panel">
                            <div class="card">
                                <h3 style="margin-top: 0; color: var(--accent);">Backbone</h3>
                                <div class="form-row">
                                    <div class="form-group">
                                        <label>Architecture <span class="tooltip-icon">?<span class="tooltip-text">UNet: lightweight, good default. ConvNeXt/SwinT: modern architectures with pretrained weights.</span></span></label>
                                        <select id="config-ci-backbone">
                                            <option value="unet">UNet</option>
                                            <option value="convnext">ConvNeXt</option>
                                            <option value="swint">SwinT</option>
                                        </select>
                                    </div>
                                    <div class="form-group" id="ci-max-stride-group">
                                        <label>Max Stride <span class="tooltip-icon">?<span class="tooltip-text">Controls receptive field for keypoint detection within crops. RF should cover most of the cropped instance.</span></span></label>
                                        <select id="config-ci-max-stride">
                                            <option value="8">8</option>
                                            <option value="16" selected>16</option>
                                            <option value="32">32</option>
                                            <option value="64">64</option>
                                        </select>
                                    </div>
                                    <div class="form-group" id="ci-model-type-group" style="display: none;">
                                        <label>Model Size <span class="tooltip-icon">?<span class="tooltip-text">Model capacity. Tiny is fastest, Large has most parameters. Start with Tiny/Small.</span></span></label>
                                        <select id="config-ci-model-type">
                                            <option value="tiny" selected>Tiny</option>
                                            <option value="small">Small</option>
                                            <option value="base">Base</option>
                                            <option value="large">Large</option>
                                        </select>
                                        <label style="display: flex; align-items: center; gap: 6px; margin-top: 8px; font-size: 0.8rem; cursor: pointer;">
                                            <input type="checkbox" id="config-ci-pretrained" style="width: auto;">
                                            Use pretrained weights (ImageNet)
                                        </label>
                                    </div>
                                </div>
                                <div class="form-row" id="ci-unet-params">
                                    <div class="form-group">
                                        <label>Input Channels <span class="tooltip-icon">?<span class="tooltip-text">Auto-detected from video. Use grayscale (1) unless color is essential.</span></span></label>
                                        <select id="config-ci-in-channels">
                                            <option value="1" selected>1 (Grayscale)</option>
                                            <option value="3">3 (RGB)</option>
                                        </select>
                                    </div>
                                    <div class="form-group">
                                        <label>Filters <span class="tooltip-icon">?<span class="tooltip-text">Base feature channels. More = more capacity but slower. Default: 32.</span></span></label>
                                        <input type="number" id="config-ci-filters" value="32" min="8" max="64">
                                    </div>
                                    <div class="form-group">
                                        <label>Filters Rate <span class="tooltip-icon">?<span class="tooltip-text">Channel multiplier per block. Default: 1.5 for UNet.</span></span></label>
                                        <input type="number" id="config-ci-filters-rate" value="1.5" min="1.0" max="3.0" step="0.5">
                                    </div>
                                </div>
                                <h3 style="color: var(--accent);">Head Config</h3>
                                <!-- Anchor Part with Visual Picker -->
                                <div style="display: flex; gap: 16px; align-items: flex-start; margin-bottom: 12px;">
                                    <div style="flex: 1;">
                                        <label style="display: block; margin-bottom: 4px;">Anchor Part <span class="tooltip-icon">?<span class="tooltip-text">Node name to center instance crops on. Should match centroid model anchor for consistent geometry. If None, uses bounding box midpoint. A reliable anchor improves accuracy by keeping body parts at consistent positions in crops.</span></span></label>
                                        <select id="config-ci-anchor" style="width: 100%;">
                                            <option value="">None (use bounding box center)</option>
                                        </select>
                                        <div style="font-size: 0.75rem; margin-top: 4px;">
                                            <span style="color: var(--text-dim);">Click a node to select anchor.</span>
                                            <span id="ci-anchor-nan-info" style="margin-left: 8px;"></span>
                                        </div>
                                    </div>
                                    <div style="flex-shrink: 0;">
                                        <canvas id="ci-anchor-viz" width="100" height="100" style="border: 1px solid var(--border); border-radius: 4px; background: var(--bg); cursor: pointer;" title="Click a node to select anchor"></canvas>
                                    </div>
                                </div>
                                <!-- Sigma & Output Stride with Visualization -->
                                <div style="display: flex; gap: 16px; align-items: flex-start;">
                                    <div style="flex: 1;">
                                        <div class="form-row">
                                            <div class="form-group">
                                                <label>Sigma <span class="tooltip-icon">?<span class="tooltip-text">Spread of the Gaussian for keypoint confidence maps (pixels at model input resolution). Each keypoint has its own channel, so overlap is not a concern. Default: 2.5</span></span></label>
                                                <input type="number" id="config-ci-sigma" value="2.5" min="1.0" max="15.0" step="0.5">
                                            </div>
                                            <div class="form-group">
                                                <label>Output Stride <span class="tooltip-icon">?<span class="tooltip-text">Stride of keypoint maps relative to crop input. Use stride=1-2 for precise keypoint localization in cropped instances. Higher strides trade precision for speed.</span></span></label>
                                                <select id="config-ci-stride">
                                                    <option value="1" selected>1</option>
                                                    <option value="2">2</option>
                                                    <option value="4">4</option>
                                                    <option value="8">8</option>
                                                    <option value="16">16</option>
                                                </select>
                                            </div>
                                        </div>
                                        <div id="ci-sigma-info" style="font-size: 0.75rem; color: var(--text-dim); margin-top: 8px;">
                                            <div>Gaussian spread: <span id="ci-sigma-radius">10</span>px (2σ covers 95%)</div>
                                            <div style="margin-top: 2px;"><span id="ci-sigma-suggest">Default: 2.5 (each keypoint has its own channel)</span></div>
                                        </div>
                                    </div>
                                    <div style="flex-shrink: 0;">
                                        <canvas id="ci-sigma-viz" width="80" height="80" style="border: 1px solid var(--border); border-radius: 4px; background: var(--bg);"></canvas>
                                    </div>
                                </div>
                                <p style="font-size: 0.8rem; color: var(--text-dim); margin-top: 12px; font-style: italic;">
                                    Data and Training settings are in the Data and Trainer tabs.
                                </p>
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Model architecture</h2>
                        <div class="stats-grid">
                            <div class="stat-card">
                                <div class="stat-label">Parameters</div>
                                <div class="stat-value" id="model-params">~1.2M</div>
                            </div>
                            <div class="stat-card">
                                <div class="stat-label">Head Output</div>
                                <div class="stat-value" id="model-head-output">24 → 13</div>
                                <div class="stat-detail" id="model-head-stride">at stride 1</div>
                            </div>
                        </div>
                        <!-- UNet Architecture Diagram -->
                        <details id="shared-unet-diagram" style="margin-top: 12px;">
                            <summary style="cursor: pointer; font-size: 0.85rem; color: var(--accent);">View UNet Architecture</summary>
                            <div id="shared-unet-arch" style="margin-top: 8px; padding: 12px; background: var(--bg); border-radius: 6px; font-family: monospace; font-size: 0.75rem; overflow-x: auto;"></div>
                        </details>
                    </div>

                    <div class="card">
                        <h2>Receptive Field</h2>
                        <p style="font-size: 0.8rem; color: var(--text-dim); margin: 0 0 12px 0;">
                            Adjust max stride and scale to see how RF changes. The RF should be about the size of the animal.
                        </p>
                        <div style="display: flex; gap: 16px; flex-wrap: wrap; margin-bottom: 16px;">
                            <div class="form-group" style="flex: 1; min-width: 120px;" id="rf-max-stride-group">
                                <label>Max Stride <span class="tooltip-icon">?<span class="tooltip-text">Adjust to see how max stride affects receptive field size in the visualization.</span></span></label>
                                <select id="rf-max-stride">
                                    <option value="8">8</option>
                                    <option value="16" selected>16</option>
                                    <option value="32">32</option>
                                    <option value="64">64</option>
                                </select>
                            </div>
                            <div class="form-group" style="flex: 1; min-width: 120px;">
                                <label>Input Scale <span class="tooltip-icon">?<span class="tooltip-text">Adjust to see how scale affects effective RF in original image coordinates.</span></span></label>
                                <select id="rf-scale-select">
                                    <option value="1.0" selected>1.0</option>
                                    <option value="0.75">0.75</option>
                                    <option value="0.5">0.5</option>
                                    <option value="0.25">0.25</option>
                                </select>
                            </div>
                        </div>
                        <div style="display: flex; gap: 16px; flex-wrap: wrap;">
                            <div style="flex: 1; min-width: 200px;">
                                <div class="stats-grid" style="margin-bottom: 12px;">
                                    <div class="stat-card">
                                        <div class="stat-label">Receptive Field <span class="tooltip-icon">?<span class="tooltip-text">RF size at model resolution (after scaling). This is what the model "sees" in processed pixels. The value in parentheses shows RF mapped to original image coordinates.</span></span></div>
                                        <div class="stat-value" id="rf-value">76 px</div>
                                        <div class="stat-detail" id="rf-base" style="font-size: 0.65rem;">(152 px in original)</div>
                                    </div>
                                    <div class="stat-card" id="rf-instance-card">
                                        <div class="stat-label">Instance Size <span class="tooltip-icon">?<span class="tooltip-text">Max instance bounding box dimension at model resolution (after scaling). Compare to RF to see coverage.</span></span></div>
                                        <div class="stat-value" id="rf-instance-size">- px</div>
                                        <div class="stat-detail" id="rf-instance-scaled" style="font-size: 0.65rem;">(original)</div>
                                    </div>
                                    <div class="stat-card" id="rf-coverage-card">
                                        <div class="stat-label">Coverage</div>
                                        <div class="stat-value" id="rf-ratio">-</div>
                                    </div>
                                </div>
                                <div id="rf-status" class="status-box">RF should cover most keypoints from center</div>
                            </div>
                            <div style="flex: 0 0 180px; text-align: center;">
                                <canvas id="rf-viz-canvas" class="viz-canvas" width="180" height="180"></canvas>
                                <div class="viz-legend">
                                    <span style="color: #ff0000;">■</span> RF
                                    <span style="color: #fbbf24;">□</span> Instance
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Preprocessing (moved from Data tab) -->
                    <div class="card">
                        <h2>Preprocessing</h2>
                        <div style="display: flex; gap: 16px; flex-wrap: wrap;">
                            <div style="flex: 1; min-width: 200px;">
                                <div class="form-row">
                                    <div class="form-group">
                                        <label>Input Scale <span class="tooltip-icon">?<span class="tooltip-text">Factor to resize image dimensions by. Scale=0.5 halves width/height. Lower values speed up training but reduce precision. Effective receptive field increases proportionally. Default: 1.0</span></span></label>
                                        <select id="config-scale">
                                            <option value="1.0">1.0 (original)</option>
                                            <option value="0.75">0.75</option>
                                            <option value="0.5">0.5 (half)</option>
                                            <option value="0.25">0.25</option>
                                        </select>
                                    </div>
                                    <div class="form-group">
                                        <label>Channels <span class="tooltip-icon">?<span class="tooltip-text">Input channel handling. Auto-detect uses source format. Grayscale converts RGB→gray. RGB replicates single-channel→3 channels. Use grayscale unless color is essential.</span></span></label>
                                        <select id="config-channels">
                                            <option value="auto">Auto-detect</option>
                                            <option value="grayscale">Grayscale</option>
                                            <option value="rgb">RGB</option>
                                        </select>
                                    </div>
                                </div>
                                <div class="form-row" style="margin-top: 8px;">
                                    <div class="form-group">
                                        <label>Max Height <span class="tooltip-icon">?<span class="tooltip-text">Maximum height to resize image to before scaling. Leave empty for no limit. Useful for very large images to reduce memory usage. Applied before scale factor.</span></span></label>
                                        <input type="number" id="config-max-height" placeholder="None" min="32" step="16" style="width: 100px;">
                                    </div>
                                    <div class="form-group">
                                        <label>Max Width <span class="tooltip-icon">?<span class="tooltip-text">Maximum width to resize image to before scaling. Leave empty for no limit. Useful for very large images to reduce memory usage. Applied before scale factor.</span></span></label>
                                        <input type="number" id="config-max-width" placeholder="None" min="32" step="16" style="width: 100px;">
                                    </div>
                                </div>
                                <div class="stats-grid" style="margin-top: 12px;">
                                    <div class="stat-card">
                                        <div class="stat-label">Original Size</div>
                                        <div class="stat-value" id="orig-size">-</div>
                                    </div>
                                    <div class="stat-card">
                                        <div class="stat-label">Scaled Size</div>
                                        <div class="stat-value" id="proc-size">-</div>
                                    </div>
                                    <div class="stat-card">
                                        <div class="stat-label">Final Processed Image (After padding) <span class="tooltip-icon" style="font-size: 0.7rem;">?<span class="tooltip-text">Final size after padding to max_stride. Images are padded to be divisible by the backbone's max stride for proper convolution alignment.</span></span></div>
                                        <div class="stat-value" id="padded-size">-</div>
                                    </div>
                                </div>
                            </div>
                            <div style="flex: 0 0 200px; text-align: center;">
                                <canvas id="preproc-canvas" width="200" height="150" style="border: 1px solid var(--border); border-radius: 8px; background: #1a1a2e;"></canvas>
                                <div style="font-size: 0.75rem; color: var(--text-dim); margin-top: 4px;">Load video to preview</div>
                            </div>
                        </div>
                    </div>

                    <div class="card" id="crop-size-card">
                        <h2>Crop Size <span style="font-size: 0.75rem; color: var(--text-dim);">(Top-Down only)</span> <span class="tooltip-icon">?<span class="tooltip-text">Crop size for centered-instance model. If null, auto-computed from largest instance in labels. Should contain full instance with padding. Visualizer shows recommended size from your data.</span></span></h2>
                        <div style="display: flex; gap: 16px; flex-wrap: wrap;">
                            <div style="flex: 1; min-width: 200px;">
                                <div class="slider-group">
                                    <div class="slider-header">
                                        <span class="slider-label">Crop Size</span>
                                        <span class="slider-value" id="crop-size-value">256 px</span>
                                    </div>
                                    <input type="range" id="config-crop-size" min="64" max="512" step="16" value="256">
                                </div>
                                <div id="crop-instance-size" style="font-size: 0.85rem; color: var(--text-dim); margin: 8px 0;">
                                    Max instance: <span id="crop-max-instance">- px</span>
                                </div>
                                <div id="crop-status" class="status-box">Load SLP to see recommendations</div>
                            </div>
                            <div style="flex: 0 0 180px;">
                                <canvas id="viz-canvas" class="viz-canvas" width="180" height="180"></canvas>
                                <div class="viz-legend">
                                    <span style="color: #4ade80;">■</span> Crop
                                    <span style="color: #fbbf24;">■</span> Instance
                                    <span style="color: #fbbf24;">●</span> Keypoints
                                </div>
                            </div>
                        </div>
                    </div>

                </div>

                <!-- ==================== TRAINING TAB ==================== -->
                <div class="tab-panel" id="panel-training">
                    <!-- Top-Down Model Selector (only visible for top-down pipeline) -->
                    <div id="training-model-selector" class="card" style="display: none; background: var(--accent); padding: 12px 16px;">
                        <div style="display: flex; align-items: center; gap: 16px; flex-wrap: wrap;">
                            <span style="color: white; font-weight: 500;">Configuring:</span>
                            <div class="sub-tabs" style="margin: 0;">
                                <button class="sub-tab active" data-model="centroid" onclick="switchTopDownModel('centroid')">Centroid</button>
                                <button class="sub-tab" data-model="centered-instance" onclick="switchTopDownModel('centered-instance')">Centered Instance</button>
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Data Pipeline</h2>
                        <div class="form-row">
                            <div class="form-group">
                                <label>Pipeline Framework <span class="tooltip-icon">?<span class="tooltip-text">Data loading framework. Stream: no caching, requires num_workers=0. Memory cache: fastest, uses RAM, allows workers>0. Disk cache: saves memory but slower I/O.</span></span></label>
                                <select id="config-data-pipeline">
                                    <option value="torch_dataset">Stream (no caching)</option>
                                    <option value="torch_dataset_cache_img_memory" selected>Cache in Memory (recommended)</option>
                                    <option value="torch_dataset_cache_img_disk">Cache to Disk</option>
                                </select>
                                <div style="font-size: 0.7rem; color: var(--text-dim); margin-top: 4px;">
                                    Stream: requires workers=0. Cache: faster training, allows workers&gt;0
                                </div>
                            </div>
                            <div class="form-group">
                                <label>User Instances Only <span class="tooltip-icon">?<span class="tooltip-text">If Yes (default), only human-labeled instances are used for training. If No, predicted instances are also included - useful for semi-supervised learning with model predictions.</span></span></label>
                                <select id="config-user-instances">
                                    <option value="true">Yes (recommended)</option>
                                    <option value="false">No (include predicted)</option>
                                </select>
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Augmentation</h2>
                        <div style="display: flex; gap: 16px; flex-wrap: wrap;">
                            <div style="flex: 1; min-width: 200px;">
                                <h3 style="margin-top: 0;">Geometric</h3>
                                <div class="slider-group">
                                    <div class="slider-header">
                                        <span class="slider-label">Rotation</span>
                                        <span class="slider-value" id="rotation-value">±15°</span>
                                    </div>
                                    <input type="range" id="config-rotation" min="0" max="180" value="15">
                                </div>
                                <div class="slider-group">
                                    <div class="slider-header">
                                        <span class="slider-label">Scale</span>
                                        <span class="slider-value" id="scale-aug-value">0.9 - 1.1</span>
                                    </div>
                                    <input type="range" id="config-scale-aug" min="0" max="50" value="10">
                                </div>

                                <h3>Intensity</h3>
                                <div class="slider-group">
                                    <div class="slider-header">
                                        <span class="slider-label">Brightness</span>
                                        <span class="slider-value" id="brightness-value">0%</span>
                                    </div>
                                    <input type="range" id="config-brightness" min="0" max="50" value="0">
                                </div>
                                <div class="slider-group">
                                    <div class="slider-header">
                                        <span class="slider-label">Contrast</span>
                                        <span class="slider-value" id="contrast-value">0%</span>
                                    </div>
                                    <input type="range" id="config-contrast" min="0" max="50" value="0">
                                </div>
                            </div>
                            <div style="flex: 0 0 320px; text-align: center;">
                                <div style="display: flex; gap: 8px; justify-content: center;">
                                    <div>
                                        <canvas id="aug-original" width="150" height="150" style="border: 1px solid var(--border); border-radius: 8px; background: #1a1a2e;"></canvas>
                                        <div style="font-size: 0.7rem; color: var(--text-dim);">Original</div>
                                    </div>
                                    <div>
                                        <canvas id="aug-preview" width="150" height="150" style="border: 1px solid var(--border); border-radius: 8px; background: #1a1a2e;"></canvas>
                                        <div style="font-size: 0.7rem; color: var(--text-dim);">Augmented</div>
                                    </div>
                                </div>
                                <button id="randomize-aug-btn" style="margin-top: 8px; padding: 6px 12px; font-size: 0.8rem;">Randomize</button>
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Training Parameters</h2>
                        <div class="form-row">
                            <div class="form-group">
                                <label>Batch Size <span class="tooltip-icon">?<span class="tooltip-text">Number of samples per training step. Larger batches = faster training but more GPU memory. Start with 4-8 and increase if memory allows. Default: 4</span></span></label>
                                <input type="number" id="config-batch-size" value="4" min="1" max="64">
                            </div>
                            <div class="form-group">
                                <label>Max Epochs <span class="tooltip-icon">?<span class="tooltip-text">Maximum number of epochs to run. Early stopping will halt training before this if validation loss plateaus. Default: 200</span></span></label>
                                <input type="number" id="config-epochs" value="200" min="10" max="1000">
                            </div>
                            <div class="form-group">
                                <label>Num Workers <span class="tooltip-icon">?<span class="tooltip-text">Number of subprocesses for data loading. Must be 0 for Stream pipeline (no caching). Can use 2-4 for Cache pipelines. Default: 0</span></span></label>
                                <input type="number" id="config-num-workers" value="0" min="0" max="16">
                            </div>
                        </div>
                        <div class="form-row" style="margin-top: 12px;">
                            <label class="checkbox-group" style="cursor: pointer; display: flex; align-items: center; gap: 8px;">
                                <input type="checkbox" id="config-same-data-val">
                                <span>Use same data for train & validation <span class="tooltip-icon">?<span class="tooltip-text">When enabled, uses identical data for training and validation. Useful for intentional overfitting on very small datasets to verify the model can learn. NOT recommended for normal training.</span></span></span>
                            </label>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Optimizer</h2>
                        <div class="form-row">
                            <div class="form-group">
                                <label>Optimizer <span class="tooltip-icon">?<span class="tooltip-text">Optimizer algorithm. Adam is the standard default. AdamW adds decoupled weight decay (L2 regularization) which can improve generalization.</span></span></label>
                                <select id="config-optimizer">
                                    <option value="Adam" selected>Adam</option>
                                    <option value="AdamW">AdamW</option>
                                </select>
                            </div>
                            <div class="form-group">
                                <label>Learning Rate <span class="tooltip-icon">?<span class="tooltip-text">Step size for weight updates. Default 1e-4 (0.0001) works well for most cases. Reduce if training is unstable or loss spikes.</span></span></label>
                                <input type="number" id="config-lr" value="0.0001" min="0.00001" max="0.01" step="0.0001">
                            </div>
                            <div class="form-group">
                                <label>AMSGrad <span class="tooltip-icon">?<span class="tooltip-text">Enable AMSGrad variant of Adam with guaranteed convergence properties. Can help stabilize training in some cases. Default: No</span></span></label>
                                <select id="config-amsgrad">
                                    <option value="false" selected>No</option>
                                    <option value="true">Yes</option>
                                </select>
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>LR Scheduler <span class="tooltip-icon">?<span class="tooltip-text">ReduceLROnPlateau: reduces learning rate when validation loss stops improving. Helps the model fine-tune in later training epochs when progress stalls.</span></span></h2>
                        <div class="form-row">
                            <div class="form-group">
                                <label>Factor <span class="tooltip-icon">?<span class="tooltip-text">Factor to multiply learning rate by when reducing. new_lr = lr × factor. 0.5 means halving. Default: 0.5</span></span></label>
                                <input type="number" id="config-lr-factor" value="0.5" min="0.1" max="1.0" step="0.1">
                            </div>
                            <div class="form-group">
                                <label>Patience <span class="tooltip-icon">?<span class="tooltip-text">Number of epochs with no improvement after which learning rate will be reduced. Default: 5</span></span></label>
                                <input type="number" id="config-lr-patience" value="5" min="1" max="50">
                            </div>
                            <div class="form-group">
                                <label>Min LR <span class="tooltip-icon">?<span class="tooltip-text">Lower bound on learning rate. LR won't be reduced below this value. Default: 1e-8</span></span></label>
                                <input type="number" id="config-min-lr" value="0.00000001" min="0" max="0.001" step="0.00000001">
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Early Stopping <span class="tooltip-icon">?<span class="tooltip-text">Stops training when validation loss stops improving for patience epochs. Prevents overfitting and saves compute time. Recommended to keep enabled.</span></span></h2>
                        <div class="form-row">
                            <div class="form-group">
                                <label>Enable <span class="tooltip-icon">?<span class="tooltip-text">Turn early stopping on/off. Recommended to leave enabled.</span></span></label>
                                <select id="config-early-stop">
                                    <option value="true" selected>Yes</option>
                                    <option value="false">No</option>
                                </select>
                            </div>
                            <div class="form-group">
                                <label>Patience <span class="tooltip-icon">?<span class="tooltip-text">Number of epochs with no improvement after which training will be stopped. Default: 10</span></span></label>
                                <input type="number" id="config-early-patience" value="10" min="1" max="100">
                            </div>
                            <div class="form-group">
                                <label>Min Delta <span class="tooltip-icon">?<span class="tooltip-text">Minimum change in validation loss to qualify as improvement. Changes smaller than this are ignored. Default: 1e-8</span></span></label>
                                <input type="number" id="config-early-delta" value="0.00000001" min="0" step="0.00000001">
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Online Hard Keypoint Mining <span class="tooltip-icon">?<span class="tooltip-text">OHKM focuses training on difficult keypoints by scaling up losses for hard-to-learn body parts. Can improve accuracy on tricky keypoints but may slow convergence.</span></span></h2>
                        <div class="form-row">
                            <label class="checkbox-group" style="cursor: pointer; display: flex; align-items: center; gap: 8px;">
                                <input type="checkbox" id="config-ohkm-enable">
                                <span>Enable OHKM</span>
                            </label>
                        </div>
                        <div id="ohkm-options" style="display: none; margin-top: 12px;">
                            <div class="form-row">
                                <div class="form-group">
                                    <label>Hard-to-Easy Ratio <span class="tooltip-icon">?<span class="tooltip-text">Minimum ratio of keypoint loss to lowest loss to be considered "hard". Higher = fewer keypoints marked as hard. Default: 2.0</span></span></label>
                                    <input type="number" id="config-ohkm-ratio" value="2.0" min="1.0" max="10.0" step="0.1">
                                </div>
                                <div class="form-group">
                                    <label>Min Hard Keypoints <span class="tooltip-icon">?<span class="tooltip-text">Minimum number of keypoints always considered "hard", even if below the ratio threshold. Default: 2</span></span></label>
                                    <input type="number" id="config-ohkm-min" value="2" min="1" max="20">
                                </div>
                                <div class="form-group">
                                    <label>Max Hard Keypoints <span class="tooltip-icon">?<span class="tooltip-text">Maximum number of hard keypoints to apply scaling to. Leave empty for no limit. Helps prevent over-scaling when many keypoints are difficult.</span></span></label>
                                    <input type="number" id="config-ohkm-max" placeholder="None" min="1" max="50">
                                </div>
                            </div>
                            <div class="form-row">
                                <div class="form-group">
                                    <label>Loss Scale <span class="tooltip-icon">?<span class="tooltip-text">Factor to scale hard keypoint losses by. Higher = more focus on hard keypoints. Default: 5.0</span></span></label>
                                    <input type="number" id="config-ohkm-scale" value="5.0" min="1.0" max="20.0" step="0.5">
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Checkpointing & Logging</h2>
                        <div class="form-row">
                            <div class="form-group">
                                <label>Save Checkpoints <span class="tooltip-icon">?<span class="tooltip-text">Save model weights during training. Required to use the trained model for inference or resume training.</span></span></label>
                                <select id="config-save-ckpt">
                                    <option value="true" selected>Yes</option>
                                    <option value="false">No</option>
                                </select>
                            </div>
                            <div class="form-group">
                                <label>Save Top K <span class="tooltip-icon">?<span class="tooltip-text">Save the K best checkpoints by validation loss. -1 = keep all, 0 = save none, 1 = keep only the best (recommended). Default: 1</span></span></label>
                                <input type="number" id="config-save-top-k" value="1" min="-1" max="10">
                            </div>
                            <div class="form-group">
                                <label>Use WandB <span class="tooltip-icon">?<span class="tooltip-text">Enable Weights & Biases integration for experiment tracking, metric visualization, and run comparison. Requires wandb account.</span></span></label>
                                <select id="config-use-wandb">
                                    <option value="false" selected>No</option>
                                    <option value="true">Yes</option>
                                </select>
                            </div>
                        </div>
                        <div class="form-row" style="margin-top: 12px;">
                            <div class="form-group" style="flex: 2;">
                                <label>Checkpoint Directory <span class="tooltip-icon">?<span class="tooltip-text">Directory path where the run folder is created. Checkpoints saved to &lt;ckpt_dir&gt;/&lt;run_name&gt;/. Default: "models"</span></span></label>
                                <input type="text" id="config-ckpt-dir" value="models" placeholder="models">
                            </div>
                            <div class="form-group" style="flex: 2;">
                                <label>Run Name <span class="tooltip-icon">?<span class="tooltip-text">Name of the current run. Checkpoints saved to &lt;ckpt_dir&gt;/&lt;run_name&gt;/. Auto-generated with timestamp if left blank.</span></span></label>
                                <input type="text" id="config-run-name" placeholder="auto-generated">
                            </div>
                        </div>
                    </div>

                    <div class="card" id="wandb-options-card" style="display: none;">
                        <h2>Weights & Biases Options</h2>
                        <div class="form-row">
                            <div class="form-group">
                                <label>Entity <span class="tooltip-icon">?<span class="tooltip-text">Your WandB username or team name. Required for logging runs to your account.</span></span></label>
                                <input type="text" id="config-wandb-entity" placeholder="your-entity">
                            </div>
                            <div class="form-group">
                                <label>Project <span class="tooltip-icon">?<span class="tooltip-text">WandB project name. Runs will be logged here. Created automatically if it doesn't exist.</span></span></label>
                                <input type="text" id="config-wandb-project" placeholder="sleap-nn">
                            </div>
                            <div class="form-group">
                                <label>Run Name <span class="tooltip-icon">?<span class="tooltip-text">Display name for this run in WandB. Auto-generated with timestamp if left blank.</span></span></label>
                                <input type="text" id="config-wandb-name" placeholder="auto-generated">
                            </div>
                        </div>
                        <div class="form-row">
                            <div class="form-group">
                                <label>Group <span class="tooltip-icon">?<span class="tooltip-text">Optional group name to organize related runs together (e.g., for hyperparameter sweeps or experiment variants).</span></span></label>
                                <input type="text" id="config-wandb-group" placeholder="optional group">
                            </div>
                            <div class="form-group">
                                <label>Save Viz <span class="tooltip-icon">?<span class="tooltip-text">Upload prediction visualizations (keypoints + confidence maps) saved to viz folder to WandB during training.</span></span></label>
                                <select id="config-wandb-save-viz">
                                    <option value="false" selected>No</option>
                                    <option value="true">Yes</option>
                                </select>
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <h2>Memory Estimate <span class="tooltip-icon">?<span class="tooltip-text">Estimates based on model architecture, batch size, and image dimensions. Actual usage may vary.</span></span></h2>

                        <!-- CPU Memory (Caching) -->
                        <h3 style="margin-top: 0;">CPU Memory (Image Cache)</h3>
                        <div class="stats-grid" style="margin-bottom: 12px;">
                            <div class="stat-card">
                                <div class="stat-label">Cache Size</div>
                                <div class="stat-value" id="mem-cache">- GB</div>
                                <div class="stat-detail" id="mem-cache-detail">Load SLP</div>
                            </div>
                        </div>

                        <!-- GPU Memory Breakdown -->
                        <h3>GPU Memory (Training)</h3>
                        <div class="stats-grid" style="margin-bottom: 8px;">
                            <div class="stat-card">
                                <div class="stat-label">Total GPU</div>
                                <div class="stat-value" id="mem-total">~2.1 GB</div>
                            </div>
                            <div class="stat-card">
                                <div class="stat-label">Parameters</div>
                                <div class="stat-value" id="mem-params">~1.2M</div>
                            </div>
                        </div>
                        <details style="margin-bottom: 12px; font-size: 0.85rem;">
                            <summary style="cursor: pointer; color: var(--text-dim);">GPU Memory Breakdown</summary>
                            <div style="padding: 8px 0; display: grid; grid-template-columns: 1fr 1fr; gap: 4px 16px;">
                                <div>Model weights:</div><div id="mem-weights">-</div>
                                <div>Batch images:</div><div id="mem-batch-img">-</div>
                                <div>Batch confmaps:</div><div id="mem-batch-conf">-</div>
                                <div>Activations:</div><div id="mem-activations">-</div>
                                <div>Gradients + Optimizer:</div><div id="mem-gradients">-</div>
                            </div>
                        </details>
                        <div id="mem-status" class="status-box">Adjust batch/crop size if memory is too high.</div>
                    </div>
                </div>

                <!-- ==================== EXPORT TAB ==================== -->
                <div class="tab-panel" id="panel-export">
                    <!-- Single config export (for single_instance and bottomup) -->
                    <div id="export-single" class="card">
                        <h2>Generated Configuration</h2>
                        <div class="yaml-output" id="yaml-output">Loading...</div>
                        <div class="export-buttons">
                            <button class="file-btn" id="copy-yaml-btn">Copy to Clipboard</button>
                            <button class="file-btn secondary" id="download-yaml-btn">Download YAML</button>
                        </div>
                    </div>

                    <!-- Top-Down export with tabs for each model -->
                    <div id="export-topdown" style="display: none;">
                        <div class="sub-tabs" style="margin-bottom: 16px;">
                            <button class="sub-tab active" data-export="centroid" onclick="switchExportTab('centroid')">Centroid Config</button>
                            <button class="sub-tab" data-export="centered-instance" onclick="switchExportTab('centered-instance')">Centered Instance Config</button>
                        </div>

                        <div id="export-centroid-panel" class="card">
                            <h2>Centroid Model Configuration</h2>
                            <p style="color: var(--text-dim); font-size: 0.85rem; margin-bottom: 12px;">Save as: <code>centroid_config.yaml</code></p>
                            <div class="yaml-output" id="yaml-output-centroid">Loading...</div>
                            <div class="export-buttons">
                                <button class="file-btn" onclick="copyYaml('centroid')">Copy to Clipboard</button>
                                <button class="file-btn secondary" onclick="downloadYaml('centroid')">Download YAML</button>
                            </div>
                        </div>

                        <div id="export-ci-panel" class="card" style="display: none;">
                            <h2>Centered Instance Model Configuration</h2>
                            <p style="color: var(--text-dim); font-size: 0.85rem; margin-bottom: 12px;">Save as: <code>centered_instance_config.yaml</code></p>
                            <div class="yaml-output" id="yaml-output-ci">Loading...</div>
                            <div class="export-buttons">
                                <button class="file-btn" onclick="copyYaml('centered-instance')">Copy to Clipboard</button>
                                <button class="file-btn secondary" onclick="downloadYaml('centered-instance')">Download YAML</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Log -->
        <div class="log-section">
            <div class="log-header">
                <h3>Log</h3>
                <button class="log-toggle" id="log-toggle">Hide</button>
            </div>
            <div class="log-content" id="log-content"></div>
        </div>
    </div>

    <script>
        // ============================================
        // State
        // ============================================
        let slpData = null;
        let computedStats = null;
        let videoFrame = null; // Extracted video frame (ImageBitmap)
        let videoWidth = 0;
        let videoHeight = 0;
        let currentFrameIdx = 0;

        let configState = {
            // Data config
            dataPipelineFw: 'torch_dataset_cache_img_memory', userInstancesOnly: true,
            useSameDataForVal: false, // Use same data for train and val (intentional overfitting)
            scale: 1.0, channels: 'auto',
            maxHeight: null, maxWidth: null, // SizeMatcher: limit image size before scaling (null = no limit)
            cropPadding: null, // Padding around instance bbox for crop_size auto-calculation
            pipeline: 'topdown',
            multiClass: false, // Identity tracking (requires tracks in SLP)
            cropSize: 256,
            rotation: 15, scaleAug: 10, brightness: 0, contrast: 0,
            // Shared backbone for single_instance and bottomup
            backbone: 'unet', maxStride: 16, filters: 32, filtersRate: 1.5, modelType: 'default', pretrained: false, inChannels: 1,
            // Single Instance config
            singleInstance: { sigma: 2.5, outputStride: 1 },
            // Top-Down: Centroid model (full config)
            centroid: {
                // Backbone (modelType for ConvNeXt/SwinT, maxStride fixed at 32 for those)
                backbone: 'unet', maxStride: 16, filters: 16, filtersRate: 1.5, modelType: 'default', pretrained: false, inChannels: 1,
                // Head (sigma=5.0 for centroid since it detects instance centers, not precise keypoints)
                sigma: 5.0, outputStride: 1, anchorPart: '',
                // Data
                scale: 1.0, channels: 'auto', maxHeight: null, maxWidth: null,
                dataPipelineFw: 'torch_dataset_cache_img_memory',
                rotation: 15, scaleAug: 10, brightness: 0, contrast: 0,
                // Trainer
                batchSize: 4, numWorkers: 2, epochs: 200,
                optimizer: 'Adam', lr: 0.0001, amsgrad: false,
                lrFactor: 0.5, lrPatience: 5, minLr: 1e-8,
                earlyStop: true, earlyPatience: 10, earlyDelta: 1e-8,
                saveCkpt: true, saveTopK: 1
            },
            // Top-Down: Centered Instance model (full config)
            centeredInstance: {
                // Backbone (modelType for ConvNeXt/SwinT, maxStride fixed at 32 for those)
                backbone: 'unet', maxStride: 16, filters: 32, filtersRate: 1.5, modelType: 'default', pretrained: false, inChannels: 1,
                // Head (sigma=2.5 for precise keypoint localization)
                sigma: 2.5, outputStride: 1, anchorPart: '',
                // Data
                scale: 1.0, channels: 'auto', maxHeight: null, maxWidth: null,
                dataPipelineFw: 'torch_dataset_cache_img_memory',
                rotation: 15, scaleAug: 10, brightness: 0, contrast: 0,
                // Trainer
                batchSize: 4, numWorkers: 2, epochs: 200,
                optimizer: 'Adam', lr: 0.0001, amsgrad: false,
                lrFactor: 0.5, lrPatience: 5, minLr: 1e-8,
                earlyStop: true, earlyPatience: 10, earlyDelta: 1e-8,
                saveCkpt: true, saveTopK: 1
            },
            // Bottom-Up config
            bottomup: {
                confmaps: { sigma: 2.5, outputStride: 1, lossWeight: 1.0 },
                pafs: { sigma: 15.0, outputStride: 1, lossWeight: 1.0 }
            },
            // Trainer config
            batchSize: 4, epochs: 200, numWorkers: 0,
            optimizer: 'Adam', lr: 0.0001, amsgrad: false,
            lrFactor: 0.5, lrPatience: 5, minLr: 1e-8,
            earlyStop: true, earlyPatience: 10, earlyDelta: 1e-8,
            saveCkpt: true, saveTopK: 1, useWandb: false,
            ckptDir: 'models', runName: '',  // Checkpoint directory and run name
            // Online Hard Keypoint Mining
            ohkm: { enabled: false, hardToEasyRatio: 2.0, minHardKeypoints: 2, maxHardKeypoints: null, lossScale: 5.0 },
            // WandB config
            wandb: { entity: '', project: '', name: '', group: '', saveViz: false },
            // Track active Top-Down sub-tab
            activeTopDownTab: 'centroid'
        };

        // ============================================
        // DOM & Logging
        // ============================================
        const logContent = document.getElementById('log-content');
        const loading = document.getElementById('loading');
        const loadingText = document.getElementById('loading-text');

        function log(msg, level = 'info') {
            const entry = document.createElement('div');
            entry.className = `log-entry ${level}`;
            entry.textContent = `${new Date().toLocaleTimeString()} - ${msg}`;
            logContent.appendChild(entry);
            logContent.scrollTop = logContent.scrollHeight;
        }

        function setLoading(msg) { loading.classList.add('visible'); loadingText.textContent = msg; }
        function hideLoading() { loading.classList.remove('visible'); }

        document.getElementById('log-toggle').addEventListener('click', function() {
            logContent.classList.toggle('collapsed');
            this.textContent = logContent.classList.contains('collapsed') ? 'Show' : 'Hide';
        });

        // ============================================
        // Tabs
        // ============================================
        document.querySelectorAll('.tab').forEach(tab => {
            tab.addEventListener('click', () => {
                document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
                document.querySelectorAll('.tab-panel').forEach(p => p.classList.remove('active'));
                tab.classList.add('active');
                document.getElementById(`panel-${tab.dataset.tab}`).classList.add('active');

                // Update visualizations when switching tabs (canvases need refresh when visible)
                if (tab.dataset.tab === 'model') {
                    updateVisualizations();
                    updatePreprocessingPreview();
                    updateAugmentationPreview(true);
                } else if (tab.dataset.tab === 'training') {
                    updateMemoryDisplay();
                } else if (tab.dataset.tab === 'export') {
                    updateYamlOutput();
                }
            });
        });

        // ============================================
        // SLP Worker
        // ============================================
        const slpWorker = new Worker('slp-worker.js');

        slpWorker.onmessage = function(e) {
            const { type, data } = e.data;
            if (type === 'log') log(data.message, data.level);
            else if (type === 'loading') setLoading(data.message);
            else if (type === 'result') {
                hideLoading();
                slpData = data;
                // Use video dimensions from SLP metadata if available
                if (data.videoWidth > 0 && data.videoHeight > 0) {
                    videoWidth = data.videoWidth;
                    videoHeight = data.videoHeight;
                    log(`Video dimensions from SLP: ${videoWidth}x${videoHeight}`, 'info');
                }
                log(`SLP loaded: ${data.frames.length} frames`, 'success');
                processSlpData(data);
            } else if (type === 'error') {
                hideLoading();
                log(`Error: ${data.message}`, 'error');
            }
        };

        // ============================================
        // File Handlers
        // ============================================
        document.getElementById('slp-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;
            document.getElementById('slp-status').textContent = file.name;
            document.getElementById('slp-status').classList.add('loaded');
            log(`Loading: ${file.name}`);
            setLoading('Reading SLP...');
            slpWorker.postMessage({ type: 'loadLocal', file });
        });

        document.getElementById('video-input').addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;
            document.getElementById('video-status').textContent = file.name;
            document.getElementById('video-status').classList.add('loaded');
            log(`Loading video: ${file.name}`);
            setLoading('Extracting video frame...');
            try {
                await extractVideoFrame(file);
                log(`Video frame extracted`, 'success');
            } catch (err) {
                log(`Video error: ${err.message}`, 'error');
            }
            hideLoading();
        });

        document.getElementById('yaml-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;
            const reader = new FileReader();
            reader.onload = (event) => {
                try {
                    const config = jsyaml.load(event.target.result);
                    loadConfigFromYaml(config);
                    document.getElementById('yaml-status').textContent = file.name;
                    document.getElementById('yaml-status').classList.add('loaded');
                    log(`Config loaded: ${file.name}`, 'success');
                } catch (err) {
                    log(`YAML error: ${err.message}`, 'error');
                }
            };
            reader.readAsText(file);
        });

        function loadConfigFromYaml(config) {
            if (config.data_config?.preprocessing) {
                const p = config.data_config.preprocessing;
                if (p.scale) { configState.scale = p.scale; document.getElementById('config-scale').value = String(p.scale); }
                if (p.crop_size) { configState.cropSize = p.crop_size; document.getElementById('config-crop-size').value = p.crop_size; document.getElementById('crop-size-value').textContent = `${p.crop_size} px`; }
            }
            if (config.model_config?.backbone_config?.unet) {
                const u = config.model_config.backbone_config.unet;
                if (u.max_stride) { configState.maxStride = u.max_stride; document.getElementById('config-max-stride').value = String(u.max_stride); }
                if (u.filters) { configState.filters = u.filters; document.getElementById('config-filters').value = u.filters; }
            }
            if (config.trainer_config) {
                const t = config.trainer_config;
                if (t.batch_size) { configState.batchSize = t.batch_size; document.getElementById('config-batch-size').value = t.batch_size; }
                if (t.max_epochs) { configState.epochs = t.max_epochs; document.getElementById('config-epochs').value = t.max_epochs; }
            }
            updateVisualizations();
        }

        // ============================================
        // Instance Statistics
        // ============================================
        function computeInstanceBBox(inst) {
            const pts = inst.points.filter(p => p !== null);
            if (pts.length < 2) return null;
            const xs = pts.map(p => p[0]), ys = pts.map(p => p[1]);
            const minX = Math.min(...xs), maxX = Math.max(...xs), minY = Math.min(...ys), maxY = Math.max(...ys);
            return { minX, maxX, minY, maxY, width: maxX - minX, height: maxY - minY, maxDim: Math.max(maxX - minX, maxY - minY), centerX: (minX + maxX) / 2, centerY: (minY + maxY) / 2 };
        }

        function bboxesOverlap(a, b) {
            return !(a.maxX < b.minX || b.maxX < a.minX || a.maxY < b.minY || b.maxY < a.minY);
        }

        function computeStats(data) {
            const allBboxes = [], instancesPerFrame = [];
            let framesWithOverlap = 0, multiInstanceFrames = 0;

            for (const frame of data.frames) {
                const frameBboxes = [];
                for (const inst of frame.instances) {
                    const bbox = computeInstanceBBox(inst);
                    if (bbox) { allBboxes.push(bbox); frameBboxes.push(bbox); }
                }
                instancesPerFrame.push(frameBboxes.length);
                if (frameBboxes.length >= 2) {
                    multiInstanceFrames++;
                    for (let i = 0; i < frameBboxes.length; i++) {
                        for (let j = i + 1; j < frameBboxes.length; j++) {
                            if (bboxesOverlap(frameBboxes[i], frameBboxes[j])) { framesWithOverlap++; break; }
                        }
                    }
                }
            }

            const sizes = allBboxes.map(b => b.maxDim);
            return {
                numFrames: data.frames.length,
                numInstances: allBboxes.length,
                instancesPerFrame: { avg: instancesPerFrame.reduce((a, b) => a + b, 0) / instancesPerFrame.length || 0, max: Math.max(...instancesPerFrame, 0) },
                instanceSizes: { maxDim: Math.max(...sizes, 0), maxWidth: Math.max(...allBboxes.map(b => b.width), 0), maxHeight: Math.max(...allBboxes.map(b => b.height), 0) },
                overlapFrequency: multiInstanceFrames > 0 ? framesWithOverlap / multiInstanceFrames : 0,
                multiInstanceFrames, framesWithOverlap,
                hasIdentity: data.tracks.length > 0, numTracks: data.tracks.length, trackNames: data.tracks
            };
        }

        function recommendPipeline(stats) {
            const reasons = [];

            // Single instance is clear-cut
            if (stats.instancesPerFrame.max <= 1) {
                return { pipeline: 'Single Instance', reasons: ['Only 1 animal per frame'], confidence: 'high' };
            }

            // Multiple animals per frame - decide between Top-Down and Bottom-Up
            // Top-Down is generally preferred for well-separated animals (most common)
            // Bottom-Up is preferred for heavily overlapping/crowded scenes

            // Use actual video dimensions if available, else estimate from instance positions
            const imgWidth = videoWidth > 0 ? videoWidth : 1920;
            const imgHeight = videoHeight > 0 ? videoHeight : 1080;
            const imageDiag = Math.sqrt(imgWidth * imgWidth + imgHeight * imgHeight);
            const sizeRatio = stats.instanceSizes.maxDim / imageDiag;

            console.log('Pipeline recommendation:', {
                instancesPerFrame: stats.instancesPerFrame,
                maxDim: stats.instanceSizes.maxDim,
                videoDims: `${imgWidth}x${imgHeight}`,
                sizeRatio: sizeRatio.toFixed(3),
                overlapFrequency: stats.overlapFrequency.toFixed(3)
            });

            // Decision logic:
            // - Top-Down is the DEFAULT for multi-animal scenarios
            // - Bottom-Up only when BOTH large instances AND high overlap

            const isVeryLarge = sizeRatio > 0.5;  // Instance > 50% of image diagonal
            const isLarge = sizeRatio > 0.35;     // Instance > 35% of image diagonal
            const isHighOverlap = stats.overlapFrequency > 0.4;  // 40%+ frames have overlap

            // Bottom-Up: only when both large AND high overlap
            if (isVeryLarge && isHighOverlap) {
                reasons.push('Very large instances (> 50% of image)');
                reasons.push(`Frequent overlap (${(stats.overlapFrequency * 100).toFixed(0)}%)`);
                return { pipeline: 'Bottom-Up', reasons, confidence: 'high' };
            }

            if (isLarge && isHighOverlap) {
                reasons.push('Large instances (> 35% of image)');
                reasons.push(`Frequent overlap (${(stats.overlapFrequency * 100).toFixed(0)}%)`);
                return { pipeline: 'Bottom-Up', reasons, confidence: 'medium' };
            }

            // Top-Down: default for everything else
            if (sizeRatio < 0.15) {
                reasons.push('Small instances (< 15% of image)');
            } else if (sizeRatio < 0.35) {
                reasons.push('Medium-sized instances');
            } else {
                reasons.push('Large instances (but low overlap)');
            }

            if (stats.overlapFrequency < 0.1) {
                reasons.push('Well-separated instances');
            } else if (stats.overlapFrequency < 0.3) {
                reasons.push(`Some overlap (${(stats.overlapFrequency * 100).toFixed(0)}%)`);
            } else {
                reasons.push(`Moderate overlap (${(stats.overlapFrequency * 100).toFixed(0)}%)`);
            }

            if (stats.instancesPerFrame.avg > 3) {
                reasons.push(`Multiple animals (${stats.instancesPerFrame.avg.toFixed(1)} avg)`);
            }

            return { pipeline: 'Top-Down', reasons, confidence: stats.overlapFrequency < 0.3 ? 'high' : 'medium' };
        }

        function processSlpData(data) {
            log('Computing statistics...');
            computedStats = computeStats(data);

            // Show cards
            document.getElementById('stats-card').style.display = 'block';
            document.getElementById('rec-card').style.display = 'block';
            document.getElementById('viewer-card').style.display = 'block';

            // Update stats
            document.getElementById('stat-frames').textContent = computedStats.numFrames;
            document.getElementById('stat-keypoints').textContent = data.skeleton.nodes.length;
            document.getElementById('stat-instances').textContent = computedStats.instancesPerFrame.avg.toFixed(1);
            document.getElementById('stat-instances-detail').textContent = `max: ${computedStats.instancesPerFrame.max}`;
            // stat-size and stat-size-detail are updated by updateInstanceSizeDisplays() with scale
            document.getElementById('stat-tracks').textContent = computedStats.numTracks || 'None';
            document.getElementById('stat-overlap').textContent = `${(computedStats.overlapFrequency * 100).toFixed(0)}%`;

            // Set default filters based on number of keypoints
            const numKeypoints = data.skeleton.nodes.length;
            let defaultFilters;
            if (numKeypoints <= 10) {
                defaultFilters = 24;
            } else {
                defaultFilters = 32;
            }

            // Update filter inputs - centroid always uses 16 (simpler detection task)
            document.getElementById('config-filters').value = defaultFilters;
            document.getElementById('config-centroid-filters').value = 16;  // Centroid always 16
            document.getElementById('config-ci-filters').value = defaultFilters;
            configState.filters = defaultFilters;
            configState.centroid.filters = 16;  // Centroid always 16
            configState.centeredInstance.filters = defaultFilters;
            log(`Set default filters: ${defaultFilters} (centroid: 16) based on ${numKeypoints} keypoints`, 'info');

            // Set input channels based on video metadata
            if (data.videoChannels === 1 || data.videoChannels === 3) {
                const channelValue = String(data.videoChannels);
                document.getElementById('config-in-channels').value = channelValue;
                document.getElementById('config-centroid-in-channels').value = channelValue;
                document.getElementById('config-ci-in-channels').value = channelValue;
                configState.inChannels = data.videoChannels;
                configState.centroid.inChannels = data.videoChannels;
                configState.centeredInstance.inChannels = data.videoChannels;
                log(`Set input channels to ${data.videoChannels} (${data.videoChannels === 1 ? 'grayscale' : 'RGB'}) from video metadata`, 'info');
            }

            // Update model params display with new defaults
            updateModelParams();

            // Update multi-class checkbox based on tracks
            const multiClassCheckbox = document.getElementById('config-multi-class');
            const multiClassInfo = document.getElementById('multi-class-tracks-info');
            if (computedStats.hasIdentity && computedStats.numTracks > 0) {
                multiClassCheckbox.disabled = false;
                multiClassInfo.style.color = 'var(--success)';
                multiClassInfo.textContent = `${computedStats.numTracks} tracks detected: ${computedStats.trackNames.slice(0, 5).join(', ')}${computedStats.numTracks > 5 ? '...' : ''}`;
            } else {
                multiClassCheckbox.disabled = true;
                multiClassCheckbox.checked = false;
                configState.multiClass = false;
                multiClassInfo.style.color = 'var(--warning)';
                multiClassInfo.textContent = 'Requires identity tracks in your SLP file.';
            }

            // Disable Single Instance pipeline if multiple instances detected in any frame
            const singleInstanceRadio = document.getElementById('pipeline-single-instance');
            const singleInstanceLabel = document.getElementById('pipeline-single-instance-label');
            const singleInstanceMsg = document.getElementById('single-instance-disabled-msg');
            const hasMultipleInstances = computedStats.instancesPerFrame.max > 1;

            if (hasMultipleInstances) {
                singleInstanceRadio.disabled = true;
                singleInstanceLabel.style.opacity = '0.5';
                singleInstanceLabel.style.cursor = 'not-allowed';
                singleInstanceMsg.style.display = 'block';
                singleInstanceMsg.textContent = `Not available: SLP contains multiple instances (max ${computedStats.instancesPerFrame.max} per frame)`;

                // If Single Instance was selected, switch to recommended pipeline
                if (configState.pipeline === 'single_instance') {
                    const rec = recommendPipeline(computedStats);
                    const newPipeline = rec.pipeline === 'Top-Down' ? 'topdown' : 'bottomup';
                    configState.pipeline = newPipeline;
                    document.querySelector(`input[name="pipeline"][value="${newPipeline}"]`).checked = true;
                    document.querySelectorAll('#pipeline-options .radio-option').forEach(o =>
                        o.classList.toggle('selected', o.querySelector('input').checked));
                    log(`Switched to ${rec.pipeline} (Single Instance not available for multi-instance data)`, 'warn');
                }
            } else {
                singleInstanceRadio.disabled = false;
                singleInstanceLabel.style.opacity = '1';
                singleInstanceLabel.style.cursor = 'pointer';
                singleInstanceMsg.style.display = 'none';
            }

            // Skeleton nodes
            const nodeList = document.getElementById('node-list');
            nodeList.innerHTML = '';
            data.skeleton.nodes.forEach(n => {
                const tag = document.createElement('span');
                tag.className = 'node-tag';
                tag.textContent = n;
                nodeList.appendChild(tag);
            });

            // Skeleton edges
            const edgeList = document.getElementById('edge-list');
            edgeList.innerHTML = '';
            data.skeleton.edges.forEach(([src, dst]) => {
                const tag = document.createElement('span');
                tag.className = 'node-tag';
                tag.textContent = `${data.skeleton.nodes[src]} → ${data.skeleton.nodes[dst]}`;
                edgeList.appendChild(tag);
            });

            // Recommendation
            const rec = recommendPipeline(computedStats);
            document.getElementById('rec-pipeline').textContent = rec.pipeline;
            const detailsList = document.getElementById('rec-details');
            detailsList.innerHTML = '';
            rec.reasons.forEach(r => {
                const li = document.createElement('li');
                li.textContent = r;
                detailsList.appendChild(li);
            });

            // Auto crop size - rounds UP to be divisible by max_stride (not just 16!)
            // Uses the Centered Instance maxStride since crop is for that model
            const ciMaxStride = configState.centeredInstance?.maxStride || 16;
            const autoCrop = Math.ceil(computedStats.instanceSizes.maxDim * 1.2 / ciMaxStride) * ciMaxStride;
            document.getElementById('crop-size-value').textContent = `${autoCrop} px`;
            document.getElementById('config-crop-size').value = autoCrop;
            configState.cropSize = autoCrop;

            // Frame slider
            document.getElementById('frame-slider').max = data.frames.length - 1;
            document.getElementById('frame-info').textContent = `1 / ${data.frames.length}`;

            updateVisualizations();
            updateModelParams();
            updateAnchorPartDropdowns();
            computeAllDistanceStats();
            // Update sigma info with computed suggestions
            updateCentroidSigmaViz();
            updateCISigmaViz();
            // Update preprocessing preview with SLP dimensions
            updatePreprocessingPreview();
            // Update instance size displays (crop card and stats) with scale
            updateInstanceSizeDisplays();
            drawViewerFrame();
            log(`Recommended: ${rec.pipeline}`, 'success');
        }

        // ============================================
        // Frame Viewer
        // ============================================
        const viewerCanvas = document.getElementById('viewer-canvas');
        const viewerCtx = viewerCanvas.getContext('2d');

        function drawViewerFrame() {
            if (!slpData || !slpData.frames.length) return;

            const frame = slpData.frames[currentFrameIdx];
            const w = viewerCanvas.width, h = viewerCanvas.height;

            // Clear canvas
            viewerCtx.fillStyle = '#1a1a2e';
            viewerCtx.fillRect(0, 0, w, h);

            let scale, offsetX, offsetY;

            // If video frame is available, draw it as background
            if (videoFrame) {
                // Scale video to fit canvas while maintaining aspect ratio
                const videoAspect = videoFrame.width / videoFrame.height;
                const canvasAspect = w / h;
                let drawW, drawH, drawX, drawY;

                if (videoAspect > canvasAspect) {
                    drawW = w;
                    drawH = w / videoAspect;
                    drawX = 0;
                    drawY = (h - drawH) / 2;
                } else {
                    drawH = h;
                    drawW = h * videoAspect;
                    drawX = (w - drawW) / 2;
                    drawY = 0;
                }

                viewerCtx.drawImage(videoFrame, drawX, drawY, drawW, drawH);

                // Scale and offset for keypoints (video coordinates -> canvas)
                scale = drawW / videoFrame.width;
                offsetX = drawX;
                offsetY = drawY;
            } else {
                // No video: fit keypoints to canvas
                const allPts = frame.instances.flatMap(inst => inst.points.filter(p => p !== null));
                if (allPts.length === 0) return;

                const xs = allPts.map(p => p[0]), ys = allPts.map(p => p[1]);
                const minX = Math.min(...xs), maxX = Math.max(...xs);
                const minY = Math.min(...ys), maxY = Math.max(...ys);
                const dataW = maxX - minX + 100, dataH = maxY - minY + 100;
                scale = Math.min(w / dataW, h / dataH) * 0.9;
                offsetX = (w - dataW * scale) / 2 - minX * scale + 50 * scale;
                offsetY = (h - dataH * scale) / 2 - minY * scale + 50 * scale;
            }

            // Draw skeleton edges and keypoints for each instance
            const colors = ['#4ade80', '#fbbf24', '#f87171', '#60a5fa', '#c084fc'];
            frame.instances.forEach((inst, instIdx) => {
                const color = colors[instIdx % colors.length];
                const pts = inst.points;

                // Draw edges
                viewerCtx.strokeStyle = color;
                viewerCtx.lineWidth = 2;
                slpData.skeleton.edges.forEach(([src, dst]) => {
                    if (pts[src] && pts[dst]) {
                        viewerCtx.beginPath();
                        viewerCtx.moveTo(pts[src][0] * scale + offsetX, pts[src][1] * scale + offsetY);
                        viewerCtx.lineTo(pts[dst][0] * scale + offsetX, pts[dst][1] * scale + offsetY);
                        viewerCtx.stroke();
                    }
                });

                // Draw keypoints
                viewerCtx.fillStyle = color;
                pts.forEach(p => {
                    if (p) {
                        viewerCtx.beginPath();
                        viewerCtx.arc(p[0] * scale + offsetX, p[1] * scale + offsetY, 4, 0, Math.PI * 2);
                        viewerCtx.fill();
                    }
                });
            });

            document.getElementById('frame-info').textContent = `${currentFrameIdx + 1} / ${slpData.frames.length}`;
        }

        document.getElementById('frame-slider').addEventListener('input', (e) => {
            currentFrameIdx = parseInt(e.target.value);
            drawViewerFrame();
        });

        // ============================================
        // Video Frame Extraction
        // ============================================
        async function extractVideoFrame(file) {
            return new Promise((resolve, reject) => {
                const video = document.createElement('video');
                video.muted = true;
                video.preload = 'metadata';

                const url = URL.createObjectURL(file);
                video.src = url;

                video.onloadedmetadata = () => {
                    videoWidth = video.videoWidth;
                    videoHeight = video.videoHeight;
                    log(`Video: ${videoWidth}x${videoHeight}`, 'info');

                    // Seek to first labeled frame if SLP is loaded, otherwise first frame
                    let seekTime = 0;
                    if (slpData && slpData.frames.length > 0) {
                        const fps = 30; // Default assumption
                        seekTime = slpData.frames[0].frameIdx / fps;
                    }
                    video.currentTime = seekTime;
                };

                video.onseeked = async () => {
                    try {
                        videoFrame = await createImageBitmap(video);
                        URL.revokeObjectURL(url);
                        drawViewerFrame();
                        updateVisualizations();
                        updatePreprocessingPreview();
                        updateAugmentationPreview(true);
                        // Update anchor visualizations with video crop
                        drawAnchorVisualization('centroid-anchor-viz', 'centroid', configState.centroid.anchorPart);
                        drawAnchorVisualization('ci-anchor-viz', 'ci', configState.centeredInstance.anchorPart);
                        resolve();
                    } catch (err) {
                        reject(err);
                    }
                };

                video.onerror = () => {
                    URL.revokeObjectURL(url);
                    reject(new Error('Failed to load video'));
                };
            });
        }

        // ============================================
        // Visualizations (Crop + RF)
        // ============================================
        const vizCanvas = document.getElementById('viz-canvas');
        const vizCtx = vizCanvas.getContext('2d');
        const rfVizCanvas = document.getElementById('rf-viz-canvas');
        const rfVizCtx = rfVizCanvas.getContext('2d');

        // Compute receptive field using SLEAP's formula from receptivefield.py
        // Ref: https://distill.pub/2019/computing-receptive-fields/ (Eq. 2)
        function computeRF(downBlocks, convsPerBlock = 2, kernelSize = 3) {
            // convs have stride 1, pooling has stride 2
            const blockStrides = Array(convsPerBlock).fill(1).concat([2]);
            // convs have kernelSize kernels, pooling has 2x2 kernels
            const blockKernels = Array(convsPerBlock).fill(kernelSize).concat([2]);

            // Repeat block parameters by total number of down blocks
            const strides = [];
            const kernels = [];
            for (let i = 0; i < downBlocks; i++) {
                strides.push(...blockStrides);
                kernels.push(...blockKernels);
            }

            // Compute RF using the product term formula
            let rf = 1;
            for (let l = 0; l < strides.length; l++) {
                const prodTerm = strides.slice(0, l).reduce((a, b) => a * b, 1);
                rf += (kernels[l] - 1) * prodTerm;
            }
            return rf;
        }

        // Pre-compute RF values for common max_stride values
        // down_blocks = log2(max_stride)
        const RF_VALUES = {
            8: computeRF(3),   // log2(8) = 3 down blocks
            16: computeRF(4),  // log2(16) = 4 down blocks
            32: computeRF(5),  // log2(32) = 5 down blocks
            64: computeRF(6),  // log2(64) = 6 down blocks
            128: computeRF(7)  // log2(128) = 7 down blocks
        };

        function updateVisualizations() {
            const w = vizCanvas.width, h = vizCanvas.height;
            vizCtx.clearRect(0, 0, w, h);

            // Use getConfigValue for Top-Down support
            const cropSize = getConfigValue('cropSize') || configState.cropSize;
            const scale = getConfigValue('scale') || configState.scale;
            const backbone = getCurrentBackboneConfig();
            const rfBase = RF_VALUES[backbone.maxStride] || 76;
            // Effective RF in original image coordinates = base RF / scale
            // When scale < 1.0, each processed pixel covers more original pixels
            const rfEffective = rfBase / scale;
            // Instance size in original and processed coordinates
            const instanceSizeOrig = computedStats ? computedStats.instanceSizes.maxDim : 150;
            const instanceSizeAtScale = instanceSizeOrig * scale;  // Size in processed image
            // For visualization comparisons, use effective RF
            const rf = rfEffective;

            // Get instance data for visualization
            let instanceBbox = null;
            let instancePts = [];
            if (slpData && slpData.frames.length > 0) {
                const frame = slpData.frames[currentFrameIdx];
                if (frame.instances.length > 0) {
                    const inst = frame.instances[0];
                    instanceBbox = computeInstanceBBox(inst);
                    instancePts = inst.points.filter(p => p !== null);
                }
            }

            const cx = w / 2, cy = h / 2;

            // If we have video frame and instance data, draw cropped region
            if (videoFrame && instanceBbox && instancePts.length > 0) {
                // Calculate source region (centered on instance)
                const srcCenterX = instanceBbox.centerX;
                const srcCenterY = instanceBbox.centerY;
                const srcHalf = cropSize / 2;

                // Clamp to video bounds
                const srcX = Math.max(0, Math.min(videoFrame.width - cropSize, srcCenterX - srcHalf));
                const srcY = Math.max(0, Math.min(videoFrame.height - cropSize, srcCenterY - srcHalf));
                const srcW = Math.min(cropSize, videoFrame.width - srcX);
                const srcH = Math.min(cropSize, videoFrame.height - srcY);

                // Draw video crop as background
                const displayScale = Math.min((w - 20) / cropSize, (h - 20) / cropSize);
                const dstW = srcW * displayScale;
                const dstH = srcH * displayScale;
                const dstX = (w - dstW) / 2;
                const dstY = (h - dstH) / 2;

                vizCtx.drawImage(videoFrame, srcX, srcY, srcW, srcH, dstX, dstY, dstW, dstH);

                // Transform keypoints to canvas coordinates
                const toCanvasX = (x) => dstX + (x - srcX) * displayScale;
                const toCanvasY = (y) => dstY + (y - srcY) * displayScale;

                // Draw RF box (purple square, centered on instance center)
                // RF is a square region, not a circle
                const rfD = rf * displayScale;
                const instCx = toCanvasX(instanceBbox.centerX);
                const instCy = toCanvasY(instanceBbox.centerY);

                vizCtx.strokeStyle = '#6c63ff';
                vizCtx.fillStyle = 'rgba(108, 99, 255, 0.2)';
                vizCtx.lineWidth = 3;
                vizCtx.fillRect(instCx - rfD / 2, instCy - rfD / 2, rfD, rfD);
                vizCtx.strokeRect(instCx - rfD / 2, instCy - rfD / 2, rfD, rfD);

                // Draw instance bbox (yellow dashed)
                vizCtx.strokeStyle = '#fbbf24';
                vizCtx.lineWidth = 2;
                vizCtx.setLineDash([4, 4]);
                const bboxX = toCanvasX(instanceBbox.minX);
                const bboxY = toCanvasY(instanceBbox.minY);
                const bboxW = instanceBbox.width * displayScale;
                const bboxH = instanceBbox.height * displayScale;
                vizCtx.strokeRect(bboxX, bboxY, bboxW, bboxH);
                vizCtx.setLineDash([]);

                // Draw crop box outline (green)
                vizCtx.strokeStyle = '#4ade80';
                vizCtx.lineWidth = 2;
                vizCtx.strokeRect(dstX, dstY, dstW, dstH);

                // Draw keypoints
                instancePts.forEach(p => {
                    const px = toCanvasX(p[0]);
                    const py = toCanvasY(p[1]);
                    // Color by RF coverage
                    const distFromCenter = Math.sqrt(Math.pow(p[0] - instanceBbox.centerX, 2) + Math.pow(p[1] - instanceBbox.centerY, 2));
                    vizCtx.fillStyle = distFromCenter <= rf / 2 ? '#4ade80' : '#f87171';
                    vizCtx.beginPath();
                    vizCtx.arc(px, py, 4, 0, Math.PI * 2);
                    vizCtx.fill();
                });

                // Center marker
                vizCtx.fillStyle = '#e8e8f0';
                vizCtx.beginPath();
                vizCtx.arc(instCx, instCy, 5, 0, Math.PI * 2);
                vizCtx.fill();
            } else {
                // Fallback: synthetic visualization (no video)
                const padding = 20;
                const maxDisplay = w - padding * 2;
                const displayScale = maxDisplay / Math.max(cropSize, instanceSizeOrig * 1.3, rf * 1.2);

                const cropD = cropSize * displayScale;
                const rfD = rf * displayScale;
                const instD = instanceSizeOrig * displayScale;

                // Draw crop box (green)
                vizCtx.strokeStyle = '#4ade80';
                vizCtx.lineWidth = 2;
                vizCtx.setLineDash([]);
                vizCtx.strokeRect(cx - cropD / 2, cy - cropD / 2, cropD, cropD);

                // Draw RF box (purple square)
                vizCtx.strokeStyle = '#6c63ff';
                vizCtx.fillStyle = 'rgba(108, 99, 255, 0.15)';
                vizCtx.lineWidth = 3;
                vizCtx.fillRect(cx - rfD / 2, cy - rfD / 2, rfD, rfD);
                vizCtx.strokeRect(cx - rfD / 2, cy - rfD / 2, rfD, rfD);

                // Draw instance bbox (yellow dashed)
                const instW = instD, instH = instD * 0.75;
                vizCtx.strokeStyle = '#fbbf24';
                vizCtx.lineWidth = 2;
                vizCtx.setLineDash([4, 4]);
                vizCtx.strokeRect(cx - instW / 2, cy - instH / 2, instW, instH);
                vizCtx.setLineDash([]);

                // Draw synthetic keypoints
                const kps = [[0, -0.35], [0, 0.35], [-0.3, -0.15], [0.3, -0.15], [-0.35, 0.2], [0.35, 0.2]];
                vizCtx.fillStyle = '#fbbf24';
                kps.forEach(([dx, dy]) => {
                    vizCtx.beginPath();
                    vizCtx.arc(cx + dx * instW, cy + dy * instH, 3, 0, Math.PI * 2);
                    vizCtx.fill();
                });

                // Center dot
                vizCtx.fillStyle = '#e8e8f0';
                vizCtx.beginPath();
                vizCtx.arc(cx, cy, 5, 0, Math.PI * 2);
                vizCtx.fill();
            }

            // Update RF display - show base RF like SLEAP GUI does
            // rfBase = RF at model resolution (what SLEAP GUI shows in text)
            // rfEffective = rfBase / scale = RF mapped to original image for visualization
            document.getElementById('rf-value').textContent = `${rfBase} px`;
            document.getElementById('rf-base').textContent = `(${Math.round(rfEffective)} px in original)`;

            // Determine model type for display logic
            const isTopDown = configState.pipeline === 'topdown';
            const isCentroid = isTopDown && configState.activeTopDownTab === 'centroid';
            const isCenteredInstance = isTopDown && configState.activeTopDownTab === 'centeredInstance';
            const isSingleInstance = configState.pipeline === 'single_instance';
            const isBottomUp = configState.pipeline === 'bottomup';

            // Hide instance size and coverage for Single Instance (not relevant)
            const instanceCard = document.getElementById('rf-instance-card');
            const coverageCard = document.getElementById('rf-coverage-card');
            if (isSingleInstance) {
                instanceCard.style.display = 'none';
                coverageCard.style.display = 'none';
            } else {
                instanceCard.style.display = '';
                coverageCard.style.display = '';
            }

            // Show max instance size from labels (at scale to match RF display)
            if (computedStats && !isSingleInstance) {
                const maxInstOrig = Math.round(instanceSizeOrig);
                const maxInstScaled = Math.round(instanceSizeAtScale);
                // Show instance at scale as main value (matches RF which is at model resolution)
                document.getElementById('rf-instance-size').textContent = `${maxInstScaled} px`;
                document.getElementById('rf-instance-scaled').textContent = `(${maxInstOrig} px original)`;
                // Coverage: RF base / instance at scale (both in model/processed coordinates)
                document.getElementById('rf-ratio').textContent = `${((rfBase / instanceSizeAtScale) * 100).toFixed(0)}%`;
            } else if (!isSingleInstance) {
                document.getElementById('rf-instance-size').textContent = '- px';
                document.getElementById('rf-instance-scaled').textContent = '(load SLP)';
                document.getElementById('rf-ratio').textContent = '-';
            }

            // Update RF status with coverage (pipeline-specific guidance)
            const rfStatusEl = document.getElementById('rf-status');
            // RF coverage in model/processed space: RF base / instance at scale
            // Note: rfBase / instanceSizeAtScale == rfEffective / instanceSizeOrig (mathematically equivalent)
            const rfCoverage = instanceSizeAtScale > 0 ? (rfBase / instanceSizeAtScale) * 100 : 0;
            let rfStatus, rfColor;

            if (isCentroid) {
                // Centroid benefits from broader context to identify instances
                if (rfCoverage < 80) {
                    rfStatus = `RF may be small for centroid (${rfCoverage.toFixed(0)}%). Centroid models benefit from larger RF to identify instances.`;
                    rfColor = 'var(--warning)';
                } else if (rfCoverage <= 200) {
                    rfStatus = `Good RF for centroid (${rfCoverage.toFixed(0)}%). Covers enough context to identify instance centers.`;
                    rfColor = 'var(--success)';
                } else {
                    rfStatus = `RF very large (${rfCoverage.toFixed(0)}%). Could use smaller max_stride for efficiency.`;
                    rfColor = 'var(--warning)';
                }
            } else if (isCenteredInstance) {
                // Centered instance needs finer detail for keypoints
                if (rfCoverage < 40) {
                    rfStatus = `RF too small (${rfCoverage.toFixed(0)}%). Increase max_stride or decrease scale.`;
                    rfColor = 'var(--error)';
                } else if (rfCoverage < 60) {
                    rfStatus = `RF adequate (${rfCoverage.toFixed(0)}%). Could increase for better keypoint context.`;
                    rfColor = 'var(--warning)';
                } else if (rfCoverage <= 120) {
                    rfStatus = `Good RF for keypoints (${rfCoverage.toFixed(0)}%). Fine detail preserved for pose estimation.`;
                    rfColor = 'var(--success)';
                } else {
                    rfStatus = `RF large for centered instance (${rfCoverage.toFixed(0)}%). Smaller RF can preserve finer keypoint detail.`;
                    rfColor = 'var(--warning)';
                }
            } else if (isSingleInstance) {
                // Single instance: just show RF info, no coverage comparison
                rfStatus = `Receptive field: ${rfBase} px at model resolution (${Math.round(rfEffective)} px in original image).`;
                rfColor = 'var(--accent)';
            } else {
                // Bottom-up
                if (rfCoverage < 40) {
                    rfStatus = `RF too small (${rfCoverage.toFixed(0)}% of instance). Increase max_stride or decrease scale.`;
                    rfColor = 'var(--error)';
                } else if (rfCoverage < 60) {
                    rfStatus = `RF coverage adequate (${rfCoverage.toFixed(0)}%). Consider increasing for better context.`;
                    rfColor = 'var(--warning)';
                } else if (rfCoverage <= 150) {
                    rfStatus = `Good RF coverage (${rfCoverage.toFixed(0)}% of instance).`;
                    rfColor = 'var(--success)';
                } else {
                    rfStatus = `RF very large (${rfCoverage.toFixed(0)}%). Could use smaller max_stride.`;
                    rfColor = 'var(--warning)';
                }
            }
            rfStatusEl.textContent = rfStatus;
            rfStatusEl.style.borderLeftColor = rfColor;

            // Crop status
            updateCropStatus(cropSize, instanceSizeOrig);
            updateMemoryDisplay();

            // Draw RF visualization (uses original coordinates for display)
            drawRFVisualization(rfBase, rfEffective, instanceSizeOrig);
        }

        function drawRFVisualization(rfBase, rfEffective, instanceSize) {
            const w = rfVizCanvas.width, h = rfVizCanvas.height;
            rfVizCtx.clearRect(0, 0, w, h);

            const cx = w / 2, cy = h / 2;

            // If we have a video frame, draw it as background (like marimo tutorial)
            if (videoFrame) {
                // Draw the full image, scaled to fit the canvas
                const imgAspect = videoFrame.width / videoFrame.height;
                const canvasAspect = w / h;
                let drawW, drawH, drawX, drawY;

                if (imgAspect > canvasAspect) {
                    drawW = w;
                    drawH = w / imgAspect;
                    drawX = 0;
                    drawY = (h - drawH) / 2;
                } else {
                    drawH = h;
                    drawW = h * imgAspect;
                    drawX = (w - drawW) / 2;
                    drawY = 0;
                }

                rfVizCtx.drawImage(videoFrame, drawX, drawY, drawW, drawH);

                // Calculate RF box size in canvas coordinates
                // RF is in original image coordinates, so we need to scale to canvas
                const scaleToCanvas = drawW / videoFrame.width;
                const rfBoxSize = rfEffective * scaleToCanvas;

                // Find instance center to position RF box
                let rfCenterX = cx, rfCenterY = cy;
                let instanceBbox = null;

                if (slpData && slpData.frames.length > 0) {
                    const frame = slpData.frames[currentFrameIdx];
                    if (frame.instances.length > 0) {
                        const inst = frame.instances[0];
                        instanceBbox = computeInstanceBBox(inst);
                        if (instanceBbox) {
                            // Center RF on instance center (in canvas coordinates)
                            rfCenterX = drawX + instanceBbox.centerX * scaleToCanvas;
                            rfCenterY = drawY + instanceBbox.centerY * scaleToCanvas;
                        }
                    }
                }

                // Draw RF box centered on instance (red)
                rfVizCtx.strokeStyle = '#ff0000';
                rfVizCtx.lineWidth = 3;
                rfVizCtx.strokeRect(rfCenterX - rfBoxSize / 2, rfCenterY - rfBoxSize / 2, rfBoxSize, rfBoxSize);

                // Draw instance bbox if available (yellow dashed)
                if (instanceBbox) {
                    const bx = drawX + instanceBbox.minX * scaleToCanvas;
                    const by = drawY + instanceBbox.minY * scaleToCanvas;
                    const bw = instanceBbox.width * scaleToCanvas;
                    const bh = instanceBbox.height * scaleToCanvas;

                    rfVizCtx.strokeStyle = '#fbbf24';
                    rfVizCtx.lineWidth = 2;
                    rfVizCtx.setLineDash([4, 4]);
                    rfVizCtx.strokeRect(bx, by, bw, bh);
                    rfVizCtx.setLineDash([]);

                    // Draw keypoints
                    const inst = slpData.frames[currentFrameIdx].instances[0];
                    inst.points.forEach(p => {
                        if (p) {
                            const px = drawX + p[0] * scaleToCanvas;
                            const py = drawY + p[1] * scaleToCanvas;
                            rfVizCtx.fillStyle = '#4ade80';
                            rfVizCtx.beginPath();
                            rfVizCtx.arc(px, py, 3, 0, Math.PI * 2);
                            rfVizCtx.fill();
                        }
                    });

                    // Draw instance center marker
                    rfVizCtx.fillStyle = '#ffffff';
                    rfVizCtx.beginPath();
                    rfVizCtx.arc(rfCenterX, rfCenterY, 4, 0, Math.PI * 2);
                    rfVizCtx.fill();
                }
            } else {
                // No image - draw synthetic visualization
                const padding = 15;
                const maxDisplay = w - padding * 2;
                const maxSize = Math.max(rfEffective, instanceSize * 1.2);
                const displayScale = maxDisplay / maxSize;

                const rfD = rfEffective * displayScale;
                const instD = instanceSize * displayScale;

                // Draw background placeholder
                rfVizCtx.fillStyle = 'rgba(30, 30, 50, 0.5)';
                rfVizCtx.fillRect(0, 0, w, h);
                rfVizCtx.fillStyle = 'var(--text-dim)';
                rfVizCtx.font = '10px system-ui';
                rfVizCtx.textAlign = 'center';
                rfVizCtx.fillText('Load SLP to see image', cx, 15);

                // Draw RF box (red)
                rfVizCtx.strokeStyle = '#ff0000';
                rfVizCtx.lineWidth = 3;
                rfVizCtx.strokeRect(cx - rfD / 2, cy - rfD / 2, rfD, rfD);

                // Draw instance bbox (yellow dashed)
                const instW = instD, instH = instD * 0.75;
                rfVizCtx.strokeStyle = '#fbbf24';
                rfVizCtx.lineWidth = 2;
                rfVizCtx.setLineDash([4, 4]);
                rfVizCtx.strokeRect(cx - instW / 2, cy - instH / 2, instW, instH);
                rfVizCtx.setLineDash([]);
            }
        }

        function updateCropStatus(cropSize, instanceSize) {
            const statusEl = document.getElementById('crop-status');
            const ratio = cropSize / instanceSize;
            let status, color;

            if (ratio < 1.0) { status = `Too small! Crop < Instance.`; color = 'var(--error)'; }
            else if (ratio < 1.1) { status = `Tight fit. Add more padding.`; color = 'var(--warning)'; }
            else if (ratio < 1.5) { status = `Good! ${Math.round((ratio - 1) * 100)}% padding.`; color = 'var(--success)'; }
            else { status = `Large crop. Consider reducing.`; color = 'var(--warning)'; }

            statusEl.textContent = status;
            statusEl.style.borderLeftColor = color;
        }

        // ============================================
        // Memory Estimation
        // ============================================
        function formatBytes(bytes) {
            if (bytes < 1024) return `${bytes} B`;
            if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB`;
            if (bytes < 1024 * 1024 * 1024) return `${(bytes / (1024 * 1024)).toFixed(1)} MB`;
            return `${(bytes / (1024 * 1024 * 1024)).toFixed(2)} GB`;
        }

        function estimateMemory() {
            const bs = configState.batchSize;
            const backbone = getCurrentBackboneConfig();
            const filters = backbone.filters || configState.filters;
            const rate = backbone.filtersRate || configState.filtersRate;
            const stride = backbone.maxStride || configState.maxStride;
            const kps = slpData ? slpData.skeleton.nodes.length : 13;
            const scale = configState.scale || 1.0;

            // Get image dimensions based on pipeline
            let imgH, imgW;
            if (configState.pipeline === 'topdown' && configState.activeTopDownTab === 'centeredInstance') {
                // Centered Instance: uses crop
                const crop = configState.cropSize || 256;
                imgH = imgW = Math.round(crop * scale);
            } else {
                // Other pipelines: uses full image
                const origH = videoHeight || 512;
                const origW = videoWidth || 512;
                imgH = Math.round(origH * scale);
                imgW = Math.round(origW * scale);
            }

            // Calculate model parameters (same as updateModelParams for consistency)
            const downBlocks = Math.log2(stride);
            const outputStride = getActiveOutputStride();
            const upBlocks = Math.log2(stride / outputStride);
            const inputCh = backbone.inChannels || 1;
            let params = 0;

            // Build encoder channel progression
            let encoderChannels = [];
            for (let block = 0; block < downBlocks; block++) {
                encoderChannels.push(Math.floor(filters * Math.pow(rate, block)));
            }
            const bottleneckCh = Math.floor(filters * Math.pow(rate, downBlocks));

            // Encoder
            let prevCh = inputCh;
            for (let block = 0; block < downBlocks; block++) {
                const encCh = encoderChannels[block];
                params += prevCh * encCh * 9 + encCh;
                params += encCh * encCh * 9 + encCh;
                prevCh = encCh;
            }

            // Middle block
            const lastEncCh = encoderChannels[downBlocks - 1];
            params += lastEncCh * bottleneckCh * 9 + bottleneckCh;
            params += bottleneckCh * bottleneckCh * 9 + bottleneckCh;

            // Decoder with skip connections
            let xInCh = bottleneckCh;
            for (let block = 0; block < upBlocks; block++) {
                const decOutCh = Math.floor(filters * Math.pow(rate, Math.max(0, downBlocks - 1 - block)));
                const skipCh = decOutCh;
                params += (xInCh + skipCh) * decOutCh * 9 + decOutCh;
                params += decOutCh * decOutCh * 9 + decOutCh;
                xInCh = decOutCh;
            }

            // Head (1x1 conv)
            params += xInCh * kps * 1 + kps;

            // Memory breakdown (in bytes)
            const weightsBytes = params * 4;  // float32

            // Batch images: B × C × H × W × 4 bytes
            const batchImgBytes = bs * (backbone.inChannels || 1) * imgH * imgW * 4;

            // Batch confmaps: B × K × (H/output_stride) × (W/output_stride) × 4 bytes
            const confH = Math.ceil(imgH / outputStride);
            const confW = Math.ceil(imgW / outputStride);
            const batchConfBytes = bs * kps * confH * confW * 4;

            // Activations: sum of feature maps at each level
            let actBytes = 0, res = Math.max(imgH, imgW);
            let actFilt = filters;
            for (let i = 0; i <= downBlocks; i++) {
                actBytes += res * res * actFilt * 4 * 2;  // forward + backward
                res = Math.floor(res / 2); actFilt = Math.floor(actFilt * rate);
            }
            actBytes *= bs;

            // Gradients + Optimizer states (Adam uses 2 momentum buffers)
            const gradientBytes = weightsBytes * 3;  // gradients + m + v

            // Total GPU memory with overhead
            const totalGpu = (weightsBytes + batchImgBytes + batchConfBytes + actBytes + gradientBytes) * 1.15;

            // CPU cache memory estimation
            // Note: Images are cached at ORIGINAL resolution as uint8 (1 byte per pixel)
            let cacheBytes = 0;
            if (slpData && computedStats) {
                const numFrames = computedStats.numFrames || 1000;
                const channels = backbone.inChannels || 1;
                // Use original video dimensions (not scaled) and uint8 format
                const origH = videoHeight || 512;
                const origW = videoWidth || 512;
                cacheBytes = numFrames * channels * origH * origW * 1;  // uint8 cached images
            }

            return {
                totalGB: totalGpu / (1024 ** 3),
                paramsM: params / 1e6,
                weightsBytes,
                batchImgBytes,
                batchConfBytes,
                actBytes,
                gradientBytes,
                cacheBytes
            };
        }

        function updateMemoryDisplay() {
            const mem = estimateMemory();
            document.getElementById('mem-total').textContent = `~${mem.totalGB.toFixed(1)} GB`;
            document.getElementById('mem-params').textContent = `~${mem.paramsM.toFixed(1)}M`;

            // GPU breakdown
            document.getElementById('mem-weights').textContent = formatBytes(mem.weightsBytes);
            document.getElementById('mem-batch-img').textContent = formatBytes(mem.batchImgBytes);
            document.getElementById('mem-batch-conf').textContent = formatBytes(mem.batchConfBytes);
            document.getElementById('mem-activations').textContent = formatBytes(mem.actBytes);
            document.getElementById('mem-gradients').textContent = formatBytes(mem.gradientBytes);

            // CPU cache
            if (mem.cacheBytes > 0) {
                document.getElementById('mem-cache').textContent = formatBytes(mem.cacheBytes);
                const numFrames = computedStats?.numFrames || 0;
                document.getElementById('mem-cache-detail').textContent = `${numFrames} frames`;
            } else {
                document.getElementById('mem-cache').textContent = '- GB';
                document.getElementById('mem-cache-detail').textContent = 'Load SLP';
            }

            const statusEl = document.getElementById('mem-status');
            let status, color;
            if (mem.totalGB < 4) { status = 'Fits most GPUs.'; color = 'var(--success)'; }
            else if (mem.totalGB < 8) { status = 'Needs 8GB+ GPU.'; color = 'var(--success)'; }
            else if (mem.totalGB < 12) { status = 'High usage. Reduce batch/crop.'; color = 'var(--warning)'; }
            else { status = 'Very high! Reduce settings.'; color = 'var(--error)'; }
            statusEl.textContent = status;
            statusEl.style.borderLeftColor = color;

            [4, 8, 12, 24].forEach(gpuMem => {
                const el = document.getElementById(`gpu-${gpuMem}`);
                if (mem.totalGB <= gpuMem * 0.85) { el.textContent = 'OK'; el.style.color = 'var(--success)'; }
                else if (mem.totalGB <= gpuMem) { el.textContent = 'Tight'; el.style.color = 'var(--warning)'; }
                else { el.textContent = 'No'; el.style.color = 'var(--error)'; }
            });
        }

        // Helper to get current backbone config based on pipeline and active tab
        // For ConvNeXt/SwinT, maxStride is always 32
        function getCurrentBackboneConfig() {
            const c = configState;
            let cfg;
            if (c.pipeline === 'topdown') {
                cfg = c.activeTopDownTab === 'centroid' ? c.centroid : c.centeredInstance;
            } else {
                cfg = c;
            }
            // ConvNeXt and SwinT have fixed max_stride of 32
            const effectiveMaxStride = (cfg.backbone === 'convnext' || cfg.backbone === 'swint') ? 32 : cfg.maxStride;
            return {
                backbone: cfg.backbone,
                filters: cfg.filters,
                filtersRate: cfg.filtersRate,
                maxStride: effectiveMaxStride,
                modelType: cfg.modelType
            };
        }

        // Helper to get the active model config for Top-Down pipeline
        function getActiveTopDownConfig() {
            return configState.activeTopDownTab === 'centroid' ? configState.centroid : configState.centeredInstance;
        }

        // Update Data and Trainer tab forms from the active Top-Down model config
        function updateFormsFromActiveConfig() {
            if (configState.pipeline !== 'topdown') return;

            const cfg = getActiveTopDownConfig();

            // Data tab - Preprocessing
            document.getElementById('config-scale').value = cfg.scale;
            document.getElementById('config-channels').value = cfg.channels;
            document.getElementById('config-data-pipeline').value = cfg.dataPipelineFw;

            // RF section - sync max stride and scale
            document.getElementById('rf-max-stride').value = cfg.maxStride;
            document.getElementById('rf-scale-select').value = cfg.scale;

            // Data tab - Augmentations
            document.getElementById('config-rotation').value = cfg.rotation;
            document.getElementById('rotation-value').textContent = `±${cfg.rotation}°`;
            document.getElementById('config-scale-aug').value = cfg.scaleAug;
            document.getElementById('scale-aug-value').textContent = `${(1 - cfg.scaleAug / 100).toFixed(2)} - ${(1 + cfg.scaleAug / 100).toFixed(2)}`;
            document.getElementById('config-brightness').value = cfg.brightness;
            document.getElementById('brightness-value').textContent = `${cfg.brightness}%`;
            document.getElementById('config-contrast').value = cfg.contrast;
            document.getElementById('contrast-value').textContent = `${cfg.contrast}%`;

            // Trainer tab
            document.getElementById('config-batch-size').value = cfg.batchSize;
            document.getElementById('config-num-workers').value = cfg.numWorkers;
            document.getElementById('config-epochs').value = cfg.epochs;
            document.getElementById('config-optimizer').value = cfg.optimizer;
            document.getElementById('config-lr').value = cfg.lr;
            document.getElementById('config-amsgrad').value = cfg.amsgrad ? 'true' : 'false';
            document.getElementById('config-lr-factor').value = cfg.lrFactor;
            document.getElementById('config-lr-patience').value = cfg.lrPatience;
            document.getElementById('config-min-lr').value = cfg.minLr;
            document.getElementById('config-early-stop').value = cfg.earlyStop ? 'true' : 'false';
            document.getElementById('config-early-patience').value = cfg.earlyPatience;
            document.getElementById('config-early-delta').value = cfg.earlyDelta;
            document.getElementById('config-save-ckpt').value = cfg.saveCkpt ? 'true' : 'false';
            document.getElementById('config-save-top-k').value = cfg.saveTopK;

            // Update previews
            updatePreprocessingPreview();
            updateAugmentationPreview();
            updateMemoryDisplay();
        }

        // Helper to update a config value - routes to active Top-Down model or shared config
        function updateConfigValue(key, value) {
            if (configState.pipeline === 'topdown') {
                const cfg = getActiveTopDownConfig();
                cfg[key] = value;
            } else {
                configState[key] = value;
            }
        }

        // Helper to get a config value - reads from active Top-Down model or shared config
        function getConfigValue(key) {
            if (configState.pipeline === 'topdown') {
                return getActiveTopDownConfig()[key];
            } else {
                return configState[key];
            }
        }

        // Switch between Centroid and Centered Instance models (called from all model selectors)
        function switchTopDownModel(model) {
            const isCI = model === 'centered-instance';
            configState.activeTopDownTab = isCI ? 'centeredInstance' : 'centroid';

            // Update all model selector sub-tabs across all tabs
            document.querySelectorAll('[data-model]').forEach(btn => {
                btn.classList.toggle('active', btn.dataset.model === model);
            });

            // Update Model tab sub-tabs and panels
            document.querySelectorAll('.sub-tab[data-subtab]').forEach(t => {
                t.classList.toggle('active', t.dataset.subtab === model);
            });
            document.querySelectorAll('.sub-panel').forEach(p => p.classList.remove('active'));
            document.getElementById(`subtab-${model}`).classList.add('active');

            // Update forms and visualizations
            updateFormsFromActiveConfig();
            updateModelParams();
            updateVisualizations();
            updateMemoryDisplay();

            // Update crop size card visibility (only for centered instance)
            const isCenteredInstance = model === 'centered-instance';
            document.getElementById('crop-size-card').style.display = isCenteredInstance ? 'block' : 'none';
        }

        // Update model selector visibility based on pipeline
        function updateModelSelectorVisibility() {
            const isTopDown = configState.pipeline === 'topdown';
            const trainingSelector = document.getElementById('training-model-selector');
            if (trainingSelector) trainingSelector.style.display = isTopDown ? 'block' : 'none';

            // Update export tab visibility
            document.getElementById('export-single').style.display = isTopDown ? 'none' : 'block';
            document.getElementById('export-topdown').style.display = isTopDown ? 'block' : 'none';
        }

        // Switch between export tabs for Top-Down
        function switchExportTab(model) {
            // Update tab active states
            document.querySelectorAll('[data-export]').forEach(btn => {
                btn.classList.toggle('active', btn.dataset.export === model);
            });

            // Show/hide panels
            document.getElementById('export-centroid-panel').style.display = model === 'centroid' ? 'block' : 'none';
            document.getElementById('export-ci-panel').style.display = model === 'centered-instance' ? 'block' : 'none';
        }

        // Store generated YAML for copy/download
        let generatedYaml = { single: '', centroid: '', centeredInstance: '' };

        // Copy YAML to clipboard
        function copyYaml(model) {
            let yaml;
            if (model === 'centroid') yaml = generatedYaml.centroid;
            else if (model === 'centered-instance') yaml = generatedYaml.centeredInstance;
            else yaml = generatedYaml.single;

            navigator.clipboard.writeText(yaml).then(() => {
                log('Copied to clipboard!', 'success');
            }).catch(() => {
                // Fallback
                const ta = document.createElement('textarea');
                ta.value = yaml;
                document.body.appendChild(ta);
                ta.select();
                document.execCommand('copy');
                document.body.removeChild(ta);
                log('Copied to clipboard!', 'success');
            });
        }

        // Download YAML file
        function downloadYaml(model) {
            let yaml, filename;
            if (model === 'centroid') {
                yaml = generatedYaml.centroid;
                filename = 'centroid_config.yaml';
            } else if (model === 'centered-instance') {
                yaml = generatedYaml.centeredInstance;
                filename = 'centered_instance_config.yaml';
            } else {
                yaml = generatedYaml.single;
                filename = `${configState.pipeline}_config.yaml`;
            }

            const blob = new Blob([yaml], { type: 'text/yaml' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            a.click();
            URL.revokeObjectURL(url);
            log(`Downloaded ${filename}`, 'success');
        }

        function updateModelParams() {
            const backbone = getCurrentBackboneConfig();
            const filters = backbone.filters;
            const rate = backbone.filtersRate;
            const maxStride = backbone.maxStride;
            const kps = slpData ? slpData.skeleton.nodes.length : 13;
            const inputCh = getInputChannels(); // Use actual input channels (1 or 3)
            const outputStride = getActiveOutputStride();
            const convsPerBlock = 2; // SLEAP-NN default
            const middleBlock = true; // SLEAP-NN default

            const downBlocks = Math.log2(maxStride);
            const upBlocks = Math.log2(maxStride / outputStride);

            // Build encoder channel progression: filters * rate^block
            let encoderChannels = [];
            for (let block = 0; block < downBlocks; block++) {
                encoderChannels.push(Math.floor(filters * Math.pow(rate, block)));
            }

            // Bottleneck (middle block) channels
            const bottleneckCh = Math.floor(filters * Math.pow(rate, downBlocks));

            // Calculate parameters for SLEAP-NN UNet architecture
            let params = 0;

            // Encoder: Each block has convs_per_block (2) convolutions
            // First block: in_ch → enc_ch, then enc_ch → enc_ch
            // Other blocks: prev_enc_ch → enc_ch, then enc_ch → enc_ch
            let prevCh = inputCh;
            for (let block = 0; block < downBlocks; block++) {
                const encCh = encoderChannels[block];
                // Conv 0: prev_ch → enc_ch
                params += prevCh * encCh * 9 + encCh;
                // Conv 1: enc_ch → enc_ch
                params += encCh * encCh * 9 + encCh;
                prevCh = encCh;
            }

            // Middle block (if enabled): expand + contract
            if (middleBlock) {
                const lastEncCh = encoderChannels[downBlocks - 1];
                // Middle expand: (convs_per_block - 1) = 1 conv
                // last_enc_ch → bottleneck_ch
                params += lastEncCh * bottleneckCh * 9 + bottleneckCh;
                // Middle contract: 1 conv
                // bottleneck_ch → bottleneck_ch (no block_contraction)
                params += bottleneckCh * bottleneckCh * 9 + bottleneckCh;
            }

            // Decoder: Each block has convs_per_block (2) refine convolutions
            // Uses bilinear interpolation (no learnable params for upsampling)
            // First conv: (x_in + skip_ch) → dec_out_ch
            // Second conv: dec_out_ch → dec_out_ch
            let xInCh = bottleneckCh;
            for (let block = 0; block < upBlocks; block++) {
                // Decoder output channels: filters * rate^(down_blocks - 1 - block)
                const decOutCh = Math.floor(filters * Math.pow(rate, Math.max(0, downBlocks - 1 - block)));
                // Skip connection from encoder has same channels as decoder output
                const skipCh = decOutCh;
                // First refine conv: (x_in + skip) → dec_out
                params += (xInCh + skipCh) * decOutCh * 9 + decOutCh;
                // Second refine conv: dec_out → dec_out
                params += decOutCh * decOutCh * 9 + decOutCh;
                xInCh = decOutCh;
            }

            // Head: final decoder channels → keypoints (1x1 conv)
            params += xInCh * kps * 1 + kps;

            // Update display
            const paramsM = params / 1e6;
            document.getElementById('model-params').textContent = paramsM >= 1 ? `~${paramsM.toFixed(1)}M` : `~${(params / 1000).toFixed(0)}K`;

            // Head output: last decoder channels → keypoints at output stride
            // Last decoder channels = filters * rate^(log2(output_stride))
            // e.g., output_stride=1 → filters*rate^0 = filters
            //       output_stride=2 → filters*rate^1
            //       output_stride=4 → filters*rate^2
            const lastDecoderCh = Math.floor(filters * Math.pow(rate, Math.log2(outputStride)));
            document.getElementById('model-head-output').textContent = `${lastDecoderCh} → ${kps}`;
            document.getElementById('model-head-stride').textContent = `at stride ${outputStride}`;

            // Update UNet architecture diagram (only for shared config when UNet is selected)
            if (backbone.backbone === 'unet') {
                const inputCh = getInputChannels();
                // Get input dimensions (full image for single instance / bottom-up)
                const inputDims = (videoWidth > 0 && videoHeight > 0) ? {
                    width: videoWidth,
                    height: videoHeight,
                    scale: parseFloat(document.getElementById('config-scale')?.value || 1.0),
                    isCrop: false
                } : null;
                updateUNetDiagram('shared-unet-arch', filters, rate, maxStride, kps, inputCh, inputDims, outputStride);
            }
        }

        // Render UNet architecture diagram
        // inputDims: { width, height, scale, isCrop } for showing processed dimensions
        function updateUNetDiagram(elementId, filters, rate, maxStride, outputs, inputChannels = 1, inputDims = null, outputStride = 1) {
            const el = document.getElementById(elementId);
            if (!el) return;

            // Calculate blocks based on SLEAP-NN UNet formulas
            const downBlocks = Math.log2(maxStride);  // Number of encoder blocks
            const upBlocks = Math.log2(maxStride / outputStride);  // Number of decoder blocks

            let html = '<div style="text-align: center; color: var(--text-dim); margin-bottom: 8px;">UNet Encoder-Decoder Architecture</div>';

            // Show input dimensions if provided
            if (inputDims) {
                const scale = inputDims.scale || 1.0;
                const processedW = Math.round(inputDims.width * scale);
                const processedH = Math.round(inputDims.height * scale);
                const sourceLabel = inputDims.isCrop ? 'Crop' : 'Image';

                html += '<div style="background: #2d3748; padding: 8px; border-radius: 6px; margin-bottom: 8px; text-align: center;">';
                html += `<div style="font-size: 0.7rem; color: var(--text-dim);">${sourceLabel}: ${inputDims.width}×${inputDims.height}`;
                if (scale !== 1.0) {
                    html += ` → Scale(${scale}) → <strong>${processedW}×${processedH}</strong>`;
                }
                html += `</div>`;
                html += '</div>';
            }

            // Build encoder layers: channels = filters * rate^block
            let encoderLayers = [];
            let prevCh = inputChannels;
            for (let i = 0; i < downBlocks; i++) {
                const outCh = Math.floor(filters * Math.pow(rate, i));
                const stride = Math.pow(2, i + 1);
                encoderLayers.push({ inCh: prevCh, outCh, stride });
                prevCh = outCh;
            }

            // Bottleneck channels: last_enc * rate
            const lastEncCh = encoderLayers[encoderLayers.length - 1].outCh;
            const bottleneckCh = Math.floor(lastEncCh * rate);

            // Build decoder layers (only upBlocks, not all levels)
            // Decoder output channels: filters * rate^(down_blocks - 1 - block)
            let decoderLayers = [];
            let xInCh = bottleneckCh;
            for (let i = 0; i < upBlocks; i++) {
                const decOutCh = Math.floor(filters * Math.pow(rate, downBlocks - 1 - i));
                const skipCh = decOutCh;  // Skip from corresponding encoder level
                const fromStride = Math.pow(2, downBlocks - i);
                const toStride = Math.pow(2, downBlocks - i - 1);
                decoderLayers.push({ inCh: xInCh, skipCh, outCh: decOutCh, fromStride, toStride });
                xInCh = decOutCh;
            }

            // Create visual diagram
            html += '<div style="display: flex; flex-direction: column; gap: 2px; align-items: center;">';

            // Input
            html += `<div style="padding: 4px 12px; background: #4a5568; border-radius: 4px; color: white;">Input: ${inputChannels} ch</div>`;
            html += '<div style="color: var(--text-dim);">↓</div>';

            // Encoder (downsampling)
            html += '<div style="color: #60a5fa; font-weight: bold; margin: 4px 0;">ENCODER</div>';
            encoderLayers.forEach((layer, i) => {
                html += `<div style="padding: 4px 12px; background: #3b82f6; border-radius: 4px; color: white; opacity: ${0.6 + i * 0.06};">`;
                html += `${layer.inCh} → Conv → ${layer.outCh} → Pool ↓${layer.stride}`;
                html += '</div>';
                if (i < encoderLayers.length - 1) html += '<div style="color: var(--text-dim);">↓</div>';
            });

            // Bottleneck
            html += '<div style="color: var(--text-dim);">↓</div>';
            html += `<div style="padding: 6px 16px; background: #8b5cf6; border-radius: 4px; color: white; font-weight: bold;">`;
            html += `Bottleneck: ${lastEncCh} → ${bottleneckCh}`;
            html += '</div>';
            html += '<div style="color: var(--text-dim);">↓</div>';

            // Decoder (upsampling) - only show upBlocks
            html += '<div style="color: #34d399; font-weight: bold; margin: 4px 0;">DECODER</div>';
            decoderLayers.forEach((layer, i) => {
                html += `<div style="padding: 4px 12px; background: #10b981; border-radius: 4px; color: white; opacity: ${0.9 - i * 0.08};">`;
                html += `${layer.inCh} → Up s${layer.fromStride}→s${layer.toStride} + Skip(${layer.skipCh}) → ${layer.outCh}`;
                html += '</div>';
                if (i < decoderLayers.length - 1) html += '<div style="color: var(--text-dim);">↓</div>';
            });

            // Output head - uses last decoder output channels
            const headInputCh = decoderLayers.length > 0 ? decoderLayers[decoderLayers.length - 1].outCh : bottleneckCh;
            html += '<div style="color: var(--text-dim);">↓</div>';
            html += `<div style="padding: 4px 12px; background: #f59e0b; border-radius: 4px; color: white;">Head: ${headInputCh} → ${outputs} @ stride ${outputStride}</div>`;

            html += '</div>';

            el.innerHTML = html;
        }

        // Draw sigma visualization showing Gaussian blob
        function drawSigmaVisualization(canvasId, sigma, outputStride = 1) {
            const canvas = document.getElementById(canvasId);
            if (!canvas) return;

            const ctx = canvas.getContext('2d');
            const width = canvas.width;
            const height = canvas.height;
            const centerX = width / 2;
            const centerY = height / 2;

            // Clear canvas
            ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--bg').trim() || '#1a1a2e';
            ctx.fillRect(0, 0, width, height);

            // Effective sigma in pixels (scaled for visualization)
            // The canvas is 80x80, show the Gaussian relative to a ~40px reference area
            const effectiveSigma = sigma * outputStride;
            const scaleFactor = 2; // Scale up for visibility
            const vizSigma = effectiveSigma * scaleFactor;

            // Draw Gaussian as radial gradient
            const gradient = ctx.createRadialGradient(centerX, centerY, 0, centerX, centerY, vizSigma * 2);
            gradient.addColorStop(0, 'rgba(96, 165, 250, 0.9)');     // Center: bright blue
            gradient.addColorStop(0.5, 'rgba(96, 165, 250, 0.4)');   // At 1σ: ~40% opacity
            gradient.addColorStop(1, 'rgba(96, 165, 250, 0.05)');    // At 2σ: nearly transparent

            ctx.beginPath();
            ctx.arc(centerX, centerY, vizSigma * 2, 0, Math.PI * 2);
            ctx.fillStyle = gradient;
            ctx.fill();

            // Draw circle at 2σ (95% coverage)
            ctx.beginPath();
            ctx.arc(centerX, centerY, vizSigma * 2, 0, Math.PI * 2);
            ctx.strokeStyle = 'rgba(96, 165, 250, 0.5)';
            ctx.lineWidth = 1;
            ctx.setLineDash([3, 3]);
            ctx.stroke();
            ctx.setLineDash([]);

            // Draw crosshair
            ctx.beginPath();
            ctx.moveTo(centerX - 5, centerY);
            ctx.lineTo(centerX + 5, centerY);
            ctx.moveTo(centerX, centerY - 5);
            ctx.lineTo(centerX, centerY + 5);
            ctx.strokeStyle = 'rgba(255, 255, 255, 0.6)';
            ctx.lineWidth = 1;
            ctx.stroke();

            // Label
            ctx.fillStyle = 'rgba(255, 255, 255, 0.8)';
            ctx.font = '10px system-ui, sans-serif';
            ctx.textAlign = 'center';
            ctx.fillText(`${effectiveSigma.toFixed(1)}px`, centerX, height - 4);
        }

        // Computed distance stats from loaded data
        let distanceStats = {
            minKeypointDist: null,    // Min distance between adjacent keypoints (skeleton edges)
            avgKeypointDist: null,    // Avg distance between adjacent keypoints
            minCentroidDist: null,    // Min distance between centroids in same frame
            avgCentroidDist: null     // Avg distance between centroids
        };

        // Compute inter-keypoint distances from skeleton edges
        function computeKeypointDistances() {
            if (!slpData) return;

            const edges = slpData.skeleton.edges;
            const allEdgeDists = [];

            // Sample from multiple instances for better statistics
            for (const frame of slpData.frames) {
                for (const inst of frame.instances) {
                    const pts = inst.points;
                    for (const [src, dst] of edges) {
                        if (pts[src] && pts[dst]) {
                            const dx = pts[src][0] - pts[dst][0];
                            const dy = pts[src][1] - pts[dst][1];
                            const dist = Math.sqrt(dx * dx + dy * dy);
                            if (dist > 0) allEdgeDists.push(dist);
                        }
                    }
                }
            }

            if (allEdgeDists.length > 0) {
                distanceStats.minKeypointDist = Math.min(...allEdgeDists);
                distanceStats.avgKeypointDist = allEdgeDists.reduce((a, b) => a + b, 0) / allEdgeDists.length;
            }
        }

        // Compute inter-centroid distances (between instances in same frame)
        function computeCentroidDistances() {
            if (!slpData) return;

            const allCentroidDists = [];

            for (const frame of slpData.frames) {
                if (frame.instances.length < 2) continue;

                // Compute centroids for all instances in this frame
                const centroids = [];
                for (const inst of frame.instances) {
                    const validPts = inst.points.filter(p => p !== null);
                    if (validPts.length > 0) {
                        const cx = validPts.reduce((s, p) => s + p[0], 0) / validPts.length;
                        const cy = validPts.reduce((s, p) => s + p[1], 0) / validPts.length;
                        centroids.push([cx, cy]);
                    }
                }

                // Compute pairwise distances
                for (let i = 0; i < centroids.length; i++) {
                    for (let j = i + 1; j < centroids.length; j++) {
                        const dx = centroids[i][0] - centroids[j][0];
                        const dy = centroids[i][1] - centroids[j][1];
                        const dist = Math.sqrt(dx * dx + dy * dy);
                        if (dist > 0) allCentroidDists.push(dist);
                    }
                }
            }

            if (allCentroidDists.length > 0) {
                distanceStats.minCentroidDist = Math.min(...allCentroidDists);
                distanceStats.avgCentroidDist = allCentroidDists.reduce((a, b) => a + b, 0) / allCentroidDists.length;
            }
        }

        // Compute all distance statistics when SLP is loaded
        function computeAllDistanceStats() {
            computeKeypointDistances();
            computeCentroidDistances();
            log(`Distance stats: keypoint min=${distanceStats.minKeypointDist?.toFixed(1) || 'N/A'}px, centroid min=${distanceStats.minCentroidDist?.toFixed(1) || 'N/A'}px`);
        }

        // Update sigma info display with computed suggestions
        function updateSigmaInfo(prefix, sigma, outputStride, isCentroid = false) {
            const radiusSpan = document.getElementById(`${prefix}-sigma-radius`);
            const suggestSpan = document.getElementById(`${prefix}-sigma-suggest`);

            // Get current input scale
            const inputScale = parseFloat(document.getElementById('config-scale')?.value || 1.0);

            if (radiusSpan) {
                const effectiveSigma = sigma * outputStride;
                const radius = Math.round(effectiveSigma * 2); // 2σ covers 95%
                radiusSpan.textContent = radius;
            }

            if (suggestSpan) {
                // Only show distance-based suggestions for Centroid (where overlap matters)
                // For keypoint models (SI, CI, BU), each keypoint has its own channel - no overlap
                if (isCentroid && distanceStats.minCentroidDist) {
                    const origDist = Math.round(distanceStats.minCentroidDist);
                    const scaledDist = Math.round(distanceStats.minCentroidDist * inputScale);
                    if (inputScale === 1.0) {
                        suggestSpan.innerHTML = `Min instance dist: <strong>${origDist}px</strong> (keep σ < ${Math.round(origDist/4)}px to avoid overlap)`;
                    } else {
                        suggestSpan.innerHTML = `Min instance dist: <strong>${scaledDist}px</strong> at scale (keep σ < ${Math.round(scaledDist/4)}px)`;
                    }
                } else if (isCentroid) {
                    suggestSpan.textContent = 'Load SLP to compute instance distances';
                } else {
                    // For keypoint models: each keypoint has its own channel, no overlap concern
                    suggestSpan.innerHTML = 'Default: <strong>2.5</strong> (each keypoint has its own channel)';
                }
            }
        }

        // Store node positions for click detection
        let anchorVizNodePositions = { centroid: [], ci: [] };

        // Draw skeleton crop for anchor selection
        function drawAnchorVisualization(canvasId, prefix, selectedAnchor = '') {
            const canvas = document.getElementById(canvasId);
            if (!canvas) return;

            const ctx = canvas.getContext('2d');
            const width = canvas.width;
            const height = canvas.height;
            const padding = 8;

            // Clear canvas with dark background
            ctx.fillStyle = '#1a1a2e';
            ctx.fillRect(0, 0, width, height);

            // If no data loaded, show placeholder
            if (!slpData) {
                ctx.fillStyle = 'rgba(255, 255, 255, 0.3)';
                ctx.font = '10px system-ui, sans-serif';
                ctx.textAlign = 'center';
                ctx.fillText('Load SLP', width / 2, height / 2);
                return;
            }

            const nodes = slpData.skeleton.nodes;
            const edges = slpData.skeleton.edges;

            // Find best instance from first frame (to match video frame)
            let bestInstance = null;
            let bestScore = 0;
            const firstFrame = slpData.frames[0];
            if (firstFrame) {
                for (const inst of firstFrame.instances) {
                    const validPts = inst.points.filter(p => p !== null);
                    if (validPts.length > bestScore) {
                        bestScore = validPts.length;
                        bestInstance = inst;
                    }
                }
            }

            if (!bestInstance || bestScore < 2) {
                ctx.fillStyle = 'rgba(255, 255, 255, 0.3)';
                ctx.font = '10px system-ui, sans-serif';
                ctx.textAlign = 'center';
                ctx.fillText('No instances', width / 2, height / 2);
                return;
            }

            const nodePositions = bestInstance.points;
            const validPts = nodePositions.filter(p => p !== null);

            // Compute bounding box with margin for crop
            const xs = validPts.map(p => p[0]);
            const ys = validPts.map(p => p[1]);
            const minX = Math.min(...xs), maxX = Math.max(...xs);
            const minY = Math.min(...ys), maxY = Math.max(...ys);
            const bboxCenterX = (minX + maxX) / 2;
            const bboxCenterY = (minY + maxY) / 2;
            const bboxW = maxX - minX || 1;
            const bboxH = maxY - minY || 1;

            // Add 20% margin around bbox for crop
            const margin = Math.max(bboxW, bboxH) * 0.2;
            const cropMinX = Math.max(0, minX - margin);
            const cropMinY = Math.max(0, minY - margin);
            const cropMaxX = videoFrame ? Math.min(videoWidth, maxX + margin) : maxX + margin;
            const cropMaxY = videoFrame ? Math.min(videoHeight, maxY + margin) : maxY + margin;
            const cropW = cropMaxX - cropMinX;
            const cropH = cropMaxY - cropMinY;

            // Scale to fit canvas
            const scale = Math.min(width / cropW, height / cropH);
            const offsetX = (width - cropW * scale) / 2 - cropMinX * scale;
            const offsetY = (height - cropH * scale) / 2 - cropMinY * scale;

            const transform = (pt) => pt ? [pt[0] * scale + offsetX, pt[1] * scale + offsetY] : null;

            // Draw video frame crop as background if available
            if (videoFrame && videoWidth > 0 && videoHeight > 0) {
                ctx.drawImage(
                    videoFrame,
                    cropMinX, cropMinY, cropW, cropH,  // Source rect
                    (width - cropW * scale) / 2, (height - cropH * scale) / 2, cropW * scale, cropH * scale  // Dest rect
                );
                // Slight darkening overlay for better skeleton visibility
                ctx.fillStyle = 'rgba(0, 0, 0, 0.2)';
                ctx.fillRect(0, 0, width, height);
            }

            // Store transformed positions for click detection
            anchorVizNodePositions[prefix] = nodePositions.map((pt, i) => {
                const tpt = transform(pt);
                return tpt ? { x: tpt[0], y: tpt[1], name: nodes[i] } : null;
            });

            // Draw edges (skeleton bones)
            ctx.strokeStyle = videoFrame ? 'rgba(255, 200, 50, 0.9)' : 'rgba(100, 180, 255, 0.6)';
            ctx.lineWidth = 2;
            for (const [src, dst] of edges) {
                const p1 = transform(nodePositions[src]);
                const p2 = transform(nodePositions[dst]);
                if (p1 && p2) {
                    ctx.beginPath();
                    ctx.moveTo(p1[0], p1[1]);
                    ctx.lineTo(p2[0], p2[1]);
                    ctx.stroke();
                }
            }

            // Find selected node index
            const selectedIdx = selectedAnchor ? nodes.indexOf(selectedAnchor) : -1;

            // Draw all nodes (small) - skip the selected one
            nodePositions.forEach((pt, i) => {
                if (i === selectedIdx) return; // Skip selected, draw it separately
                const tpt = transform(pt);
                if (!tpt) return;
                ctx.beginPath();
                ctx.arc(tpt[0], tpt[1], 3, 0, Math.PI * 2);
                ctx.fillStyle = videoFrame ? 'rgba(255, 200, 50, 0.8)' : 'rgba(100, 180, 255, 0.8)';
                ctx.fill();
            });

            // Highlight selected anchor or bbox center
            if (selectedAnchor && selectedIdx >= 0 && nodePositions[selectedIdx]) {
                const tpt = transform(nodePositions[selectedIdx]);
                if (tpt) {
                    // Draw outer glow ring
                    ctx.beginPath();
                    ctx.arc(tpt[0], tpt[1], 12, 0, Math.PI * 2);
                    ctx.strokeStyle = '#ff3366';
                    ctx.lineWidth = 2;
                    ctx.stroke();
                    // Draw filled center - bright magenta/pink
                    ctx.beginPath();
                    ctx.arc(tpt[0], tpt[1], 6, 0, Math.PI * 2);
                    ctx.fillStyle = '#ff3366';
                    ctx.fill();
                    // White inner dot for contrast
                    ctx.beginPath();
                    ctx.arc(tpt[0], tpt[1], 2, 0, Math.PI * 2);
                    ctx.fillStyle = '#ffffff';
                    ctx.fill();
                }
            } else if (!selectedAnchor) {
                // No anchor - highlight bbox center with crosshair
                const bboxCenterTpt = transform([bboxCenterX, bboxCenterY]);
                if (bboxCenterTpt) {
                    // Draw crosshair at bbox center - bright magenta
                    ctx.strokeStyle = '#ff3366';
                    ctx.lineWidth = 2;
                    ctx.beginPath();
                    ctx.moveTo(bboxCenterTpt[0] - 10, bboxCenterTpt[1]);
                    ctx.lineTo(bboxCenterTpt[0] + 10, bboxCenterTpt[1]);
                    ctx.moveTo(bboxCenterTpt[0], bboxCenterTpt[1] - 10);
                    ctx.lineTo(bboxCenterTpt[0], bboxCenterTpt[1] + 10);
                    ctx.stroke();
                    // Center dot
                    ctx.beginPath();
                    ctx.arc(bboxCenterTpt[0], bboxCenterTpt[1], 4, 0, Math.PI * 2);
                    ctx.fillStyle = '#ff3366';
                    ctx.fill();
                }
            }

            // Label
            ctx.fillStyle = 'rgba(255, 255, 255, 0.6)';
            ctx.font = '9px system-ui, sans-serif';
            ctx.textAlign = 'center';
            ctx.fillText(selectedAnchor || 'bbox center', width / 2, height - 3);
        }

        // Handle anchor canvas click
        function handleAnchorCanvasClick(e, canvasId, prefix, selectId) {
            const canvas = document.getElementById(canvasId);
            if (!canvas) return;

            const rect = canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const y = e.clientY - rect.top;

            const nodePositions = anchorVizNodePositions[prefix] || [];
            const clickRadius = 10;

            // Find closest node
            let closestNode = null;
            let closestDist = clickRadius;

            for (const node of nodePositions) {
                if (!node) continue;
                const dist = Math.sqrt((x - node.x) ** 2 + (y - node.y) ** 2);
                if (dist < closestDist) {
                    closestDist = dist;
                    closestNode = node.name;
                }
            }

            // Update selection
            const select = document.getElementById(selectId);
            if (closestNode) {
                select.value = closestNode;
            } else {
                select.value = ''; // Clicked empty area, reset to "None"
            }

            // Trigger change event
            select.dispatchEvent(new Event('change'));
        }

        // ============================================
        // UI Event Handlers
        // ============================================
        document.querySelectorAll('input[name="pipeline"]').forEach(r => {
            r.addEventListener('change', (e) => {
                document.querySelectorAll('#pipeline-options .radio-option').forEach(o => o.classList.toggle('selected', o.querySelector('input').checked));
                configState.pipeline = e.target.value;
                updatePipelineUI();
                updateVisualizations();
            });
        });

        // Multi-Class checkbox event listener
        document.getElementById('config-multi-class').addEventListener('change', (e) => {
            configState.multiClass = e.target.checked;
            log(`Multi-class ${e.target.checked ? 'enabled' : 'disabled'}`, 'info');
        });

        function updatePipelineUI() {
            const pipeline = configState.pipeline;
            const isTopDown = pipeline === 'topdown';
            const isSingleInstance = pipeline === 'single_instance';
            const isBottomUp = pipeline === 'bottomup';

            // Show/hide crop size card (only for centered instance model)
            const isCenteredInstance = isTopDown && configState.activeTopDownTab === 'centeredInstance';
            document.getElementById('crop-size-card').style.display = isCenteredInstance ? 'block' : 'none';

            // Show/hide config sections based on pipeline
            // Top-Down has its own card with sub-tabs
            document.getElementById('config-topdown').style.display = isTopDown ? 'block' : 'none';
            // Single Instance and Bottom-Up share the config-shared section
            document.getElementById('config-shared').style.display = (isSingleInstance || isBottomUp) ? 'block' : 'none';

            // Show/hide head configs within config-shared based on pipeline
            document.getElementById('head-single-instance').style.display = isSingleInstance ? 'block' : 'none';
            document.getElementById('head-bottomup').style.display = isBottomUp ? 'block' : 'none';

            // Maintain Single Instance disabled state based on multi-instance data
            const singleInstanceRadio = document.getElementById('pipeline-single-instance');
            const singleInstanceLabel = document.getElementById('pipeline-single-instance-label');
            const singleInstanceMsg = document.getElementById('single-instance-disabled-msg');
            const hasMultipleInstances = computedStats && computedStats.instancesPerFrame.max > 1;

            if (hasMultipleInstances) {
                singleInstanceRadio.disabled = true;
                singleInstanceLabel.style.opacity = '0.5';
                singleInstanceLabel.style.cursor = 'not-allowed';
                singleInstanceMsg.style.display = 'block';
                singleInstanceMsg.textContent = `Not available: SLP contains multiple instances (max ${computedStats.instancesPerFrame.max} per frame)`;
            } else if (computedStats) {
                // SLP is loaded but only single instances
                singleInstanceRadio.disabled = false;
                singleInstanceLabel.style.opacity = '1';
                singleInstanceLabel.style.cursor = 'pointer';
                singleInstanceMsg.style.display = 'none';
            }

            // Multi-class is NOT available for Single Instance (only Top-Down and Bottom-Up)
            const multiClassCheckbox = document.getElementById('config-multi-class');
            const multiClassOption = document.getElementById('multi-class-option');
            if (isSingleInstance) {
                multiClassCheckbox.disabled = true;
                multiClassCheckbox.checked = false;
                configState.multiClass = false;
                multiClassOption.style.opacity = '0.5';
                document.getElementById('multi-class-tracks-info').textContent = 'Not available for Single Instance pipeline.';
            } else {
                multiClassOption.style.opacity = '1';
                // Re-enable based on tracks (will be updated by processSlpData if SLP is loaded)
                if (computedStats && computedStats.hasIdentity && computedStats.numTracks > 0) {
                    multiClassCheckbox.disabled = false;
                    document.getElementById('multi-class-tracks-info').textContent =
                        `${computedStats.numTracks} tracks detected: ${computedStats.trackNames.slice(0, 5).join(', ')}${computedStats.numTracks > 5 ? '...' : ''}`;
                    document.getElementById('multi-class-tracks-info').style.color = 'var(--success)';
                }
            }

            // Show/hide model selectors in Data and Trainer tabs
            updateModelSelectorVisibility();

            // If switching to Top-Down, also update forms from active config
            if (isTopDown) {
                updateFormsFromActiveConfig();
            }
        }

        // Initialize pipeline UI
        updatePipelineUI();

        // Store NaN counts per node
        let nodeNanCounts = {};

        // Compute NaN counts for each skeleton node
        function computeNodeNanCounts() {
            if (!slpData) return;
            const nodes = slpData.skeleton.nodes;
            nodeNanCounts = {};

            // Debug: check for duplicate node names
            const uniqueNodes = new Set(nodes);
            console.log(`Nodes: ${nodes.length} total, ${uniqueNodes.size} unique`);
            if (nodes.length !== uniqueNodes.size) {
                console.warn('DUPLICATE NODE NAMES DETECTED!', nodes);
            }

            // Initialize counts
            nodes.forEach((n, i) => {
                nodeNanCounts[n] = { nan: 0, total: 0 };
            });

            // Count user instances and NaNs
            let userInstanceCount = 0;
            let firstInstancePointsLen = null;
            for (const frame of slpData.frames) {
                for (const inst of frame.instances) {
                    // Skip predicted instances - only count user-labeled instances
                    if (inst.type !== 'user') continue;
                    userInstanceCount++;

                    // Debug: check points array length
                    if (firstInstancePointsLen === null) {
                        firstInstancePointsLen = inst.points.length;
                        console.log(`First instance has ${inst.points.length} points, skeleton has ${nodes.length} nodes`);
                    }

                    // Only iterate up to number of nodes to avoid double-counting
                    const numPoints = Math.min(inst.points.length, nodes.length);
                    for (let i = 0; i < numPoints; i++) {
                        const pt = inst.points[i];
                        const nodeName = nodes[i];
                        if (nodeNanCounts[nodeName]) {
                            nodeNanCounts[nodeName].total++;
                            if (pt === null) {
                                nodeNanCounts[nodeName].nan++;
                            }
                        }
                    }
                }
            }
            console.log(`NaN computation: ${userInstanceCount} user instances, ${nodes.length} nodes`);
            console.log('NaN counts:', nodeNanCounts);
        }

        // Populate anchor part dropdowns when SLP is loaded
        function updateAnchorPartDropdowns() {
            if (!slpData) return;
            const nodes = slpData.skeleton.nodes;

            // Compute NaN counts first
            computeNodeNanCounts();

            ['config-centroid-anchor', 'config-ci-anchor'].forEach(id => {
                const select = document.getElementById(id);
                select.innerHTML = '<option value="">None (use bbox center)</option>';
                nodes.forEach(n => {
                    const opt = document.createElement('option');
                    opt.value = n;
                    const stats = nodeNanCounts[n];
                    const nanCount = stats ? stats.nan : 0;
                    const total = stats ? stats.total : 0;
                    // Show NaN count or checkmark for complete nodes
                    if (nanCount > 0) {
                        opt.textContent = `${n} (${nanCount}/${total} missing)`;
                    } else if (total > 0) {
                        opt.textContent = `${n} ✓`;  // Complete - no missing values
                    } else {
                        opt.textContent = n;
                    }
                    select.appendChild(opt);
                });
            });
            // Draw anchor visualizations
            drawAnchorVisualization('centroid-anchor-viz', 'centroid', configState.centroid.anchorPart);
            drawAnchorVisualization('ci-anchor-viz', 'ci', configState.centeredInstance.anchorPart);
            // Update NaN info displays
            updateAnchorNanInfo('centroid', configState.centroid.anchorPart);
            updateAnchorNanInfo('ci', configState.centeredInstance.anchorPart);
        }

        // Update NaN info display for anchor
        function updateAnchorNanInfo(prefix, anchorPart) {
            const infoEl = document.getElementById(`${prefix}-anchor-nan-info`);
            if (!infoEl) return;

            if (!anchorPart || !nodeNanCounts[anchorPart]) {
                infoEl.textContent = '';
                return;
            }

            const stats = nodeNanCounts[anchorPart];
            if (stats.nan > 0) {
                infoEl.innerHTML = `<span style="color: #f59e0b;">⚠ ${stats.nan}/${stats.total} missing</span>`;
            } else {
                infoEl.innerHTML = `<span style="color: #10b981;">✓ No missing values</span>`;
            }
        }

        document.getElementById('config-crop-size').addEventListener('input', (e) => {
            configState.cropSize = parseInt(e.target.value);
            document.getElementById('crop-size-value').textContent = `${e.target.value} px`;
            updateVisualizations();
            updatePreprocessingPreview(); // Update processed size for Centered Instance
        });

        // Shared backbone event listeners (single instance / bottom-up)
        document.getElementById('config-backbone').addEventListener('change', (e) => {
            configState.backbone = e.target.value;
            updateBackboneUI('shared', e.target.value);
            updateModelParams();
            updateVisualizations();
        });
        document.getElementById('config-max-stride').addEventListener('change', (e) => {
            configState.maxStride = parseInt(e.target.value);
            // Sync with RF section
            document.getElementById('rf-max-stride').value = e.target.value;
            updateVisualizations();
            updateModelParams();
        });
        document.getElementById('config-model-type').addEventListener('change', (e) => {
            configState.modelType = e.target.value;
            updateModelParams();
        });
        document.getElementById('config-pretrained').addEventListener('change', (e) => {
            configState.pretrained = e.target.checked;
        });
        document.getElementById('config-filters').addEventListener('input', (e) => {
            configState.filters = parseInt(e.target.value) || 24;
            updateModelParams();
        });
        document.getElementById('config-filters-rate').addEventListener('input', (e) => {
            configState.filtersRate = parseFloat(e.target.value) || 2.0;
            updateModelParams();
        });

        document.getElementById('config-rotation').addEventListener('input', (e) => {
            updateConfigValue('rotation', parseInt(e.target.value));
            document.getElementById('rotation-value').textContent = `±${e.target.value}°`;
            updateAugmentationPreview();
        });

        document.getElementById('config-scale-aug').addEventListener('input', (e) => {
            const v = parseInt(e.target.value);
            updateConfigValue('scaleAug', v);
            document.getElementById('scale-aug-value').textContent = `${(1 - v / 100).toFixed(2)} - ${(1 + v / 100).toFixed(2)}`;
            updateAugmentationPreview();
        });

        document.getElementById('config-brightness').addEventListener('input', (e) => {
            updateConfigValue('brightness', parseInt(e.target.value));
            document.getElementById('brightness-value').textContent = `${e.target.value}%`;
            updateAugmentationPreview();
        });

        document.getElementById('config-contrast').addEventListener('input', (e) => {
            updateConfigValue('contrast', parseInt(e.target.value));
            document.getElementById('contrast-value').textContent = `${e.target.value}%`;
            updateAugmentationPreview();
        });

        // Scale change updates preprocessing preview and RF calculations
        document.getElementById('config-scale').addEventListener('change', (e) => {
            updateConfigValue('scale', parseFloat(e.target.value));
            // Sync with RF section scale selector
            document.getElementById('rf-scale-select').value = e.target.value;
            updatePreprocessingPreview();
            updateVisualizations(); // RF changes with scale
            // Update sigma info to reflect new scaled distances
            if (typeof updateCentroidSigmaViz === 'function') {
                updateCentroidSigmaViz();
            }
            if (typeof updateCISigmaViz === 'function') {
                updateCISigmaViz();
            }
            // Update instance size displays to reflect new scale
            if (typeof updateInstanceSizeDisplays === 'function') {
                updateInstanceSizeDisplays();
            }
        });

        // RF section controls - sync with Model and Data tabs
        document.getElementById('rf-max-stride').addEventListener('change', (e) => {
            const newStride = parseInt(e.target.value);
            // Update the appropriate backbone max stride based on pipeline
            if (configState.pipeline === 'topdown') {
                if (configState.activeTopDownTab === 'centroid') {
                    configState.centroid.maxStride = newStride;
                    document.getElementById('config-centroid-max-stride').value = newStride;
                } else {
                    configState.centeredInstance.maxStride = newStride;
                    document.getElementById('config-ci-max-stride').value = newStride;
                }
            } else {
                configState.maxStride = newStride;
                document.getElementById('config-max-stride').value = newStride;
            }
            updateModelParams();
            updateVisualizations();
        });

        document.getElementById('rf-scale-select').addEventListener('change', (e) => {
            const newScale = parseFloat(e.target.value);
            updateConfigValue('scale', newScale);
            // Sync with Data tab scale selector
            document.getElementById('config-scale').value = newScale;
            updatePreprocessingPreview();
            updateVisualizations();
            // Update sigma info to reflect new scaled distances
            if (typeof updateCentroidSigmaViz === 'function') {
                updateCentroidSigmaViz();
            }
            if (typeof updateCISigmaViz === 'function') {
                updateCISigmaViz();
            }
            // Update instance size displays to reflect new scale
            if (typeof updateInstanceSizeDisplays === 'function') {
                updateInstanceSizeDisplays();
            }
        });

        // Channels setting - sync with model input channels
        document.getElementById('config-channels').addEventListener('change', (e) => {
            updateConfigValue('channels', e.target.value);
            // Sync input channels in model config based on channels setting
            const inCh = e.target.value === 'rgb' ? 3 : 1;
            configState.inChannels = inCh;
            configState.centroid.inChannels = inCh;
            configState.centeredInstance.inChannels = inCh;
            // Update UI selects
            document.getElementById('config-in-channels').value = inCh;
            document.getElementById('config-centroid-in-channels').value = inCh;
            document.getElementById('config-ci-in-channels').value = inCh;
            // Update UNet diagrams
            updateModelParams();
            updateTopDownUNetDiagram('centroid');
            updateTopDownUNetDiagram('ci');
        });

        // Max height/width - limit image size before scaling
        document.getElementById('config-max-height').addEventListener('input', (e) => {
            const val = e.target.value ? parseInt(e.target.value) : null;
            updateConfigValue('maxHeight', val);
            configState.maxHeight = val;
            configState.centroid.maxHeight = val;
            configState.centeredInstance.maxHeight = val;
            updatePreprocessingPreview();
        });
        document.getElementById('config-max-width').addEventListener('input', (e) => {
            const val = e.target.value ? parseInt(e.target.value) : null;
            updateConfigValue('maxWidth', val);
            configState.maxWidth = val;
            configState.centroid.maxWidth = val;
            configState.centeredInstance.maxWidth = val;
            updatePreprocessingPreview();
        });

        // Input channels event listeners (UNet backbone)
        document.getElementById('config-in-channels').addEventListener('change', (e) => {
            configState.inChannels = parseInt(e.target.value);
            updateModelParams();
        });
        document.getElementById('config-centroid-in-channels').addEventListener('change', (e) => {
            configState.centroid.inChannels = parseInt(e.target.value);
            updateTopDownUNetDiagram('centroid');
        });
        document.getElementById('config-ci-in-channels').addEventListener('change', (e) => {
            configState.centeredInstance.inChannels = parseInt(e.target.value);
            updateTopDownUNetDiagram('ci');
        });

        // Data pipeline settings
        document.getElementById('config-data-pipeline').addEventListener('change', (e) => {
            updateConfigValue('dataPipelineFw', e.target.value);
        });
        document.getElementById('config-user-instances').addEventListener('change', (e) => {
            configState.userInstancesOnly = e.target.value === 'true';
        });

        // WandB toggle - show/hide options
        document.getElementById('config-use-wandb').addEventListener('change', (e) => {
            configState.useWandb = e.target.value === 'true';
            document.getElementById('wandb-options-card').style.display = configState.useWandb ? 'block' : 'none';
        });

        // WandB options
        document.getElementById('config-wandb-entity').addEventListener('input', (e) => {
            configState.wandb.entity = e.target.value;
        });
        document.getElementById('config-wandb-project').addEventListener('input', (e) => {
            configState.wandb.project = e.target.value;
        });
        document.getElementById('config-wandb-name').addEventListener('input', (e) => {
            configState.wandb.name = e.target.value;
        });
        document.getElementById('config-wandb-group').addEventListener('input', (e) => {
            configState.wandb.group = e.target.value;
        });
        document.getElementById('config-wandb-save-viz').addEventListener('change', (e) => {
            configState.wandb.saveViz = e.target.value === 'true';
        });

        // Use same data for train & validation toggle
        document.getElementById('config-same-data-val').addEventListener('change', (e) => {
            configState.useSameDataForVal = e.target.checked;
        });

        // Online Hard Keypoint Mining toggle and options
        document.getElementById('config-ohkm-enable').addEventListener('change', (e) => {
            configState.ohkm.enabled = e.target.checked;
            document.getElementById('ohkm-options').style.display = e.target.checked ? 'block' : 'none';
        });
        document.getElementById('config-ohkm-ratio').addEventListener('input', (e) => {
            configState.ohkm.hardToEasyRatio = parseFloat(e.target.value) || 2.0;
        });
        document.getElementById('config-ohkm-min').addEventListener('input', (e) => {
            configState.ohkm.minHardKeypoints = parseInt(e.target.value) || 2;
        });
        document.getElementById('config-ohkm-max').addEventListener('input', (e) => {
            const val = e.target.value ? parseInt(e.target.value) : null;
            configState.ohkm.maxHardKeypoints = val;
        });
        document.getElementById('config-ohkm-scale').addEventListener('input', (e) => {
            configState.ohkm.lossScale = parseFloat(e.target.value) || 5.0;
        });

        // Checkpoint directory and run name
        document.getElementById('config-ckpt-dir').addEventListener('input', (e) => {
            configState.ckptDir = e.target.value || 'models';
        });
        document.getElementById('config-run-name').addEventListener('input', (e) => {
            configState.runName = e.target.value || '';
        });

        // Randomize augmentation button
        document.getElementById('randomize-aug-btn').addEventListener('click', () => {
            updateAugmentationPreview(true);
        });

        // Batch size routes to active model for Top-Down
        document.getElementById('config-batch-size').addEventListener('input', () => {
            updateConfigValue('batchSize', parseInt(document.getElementById('config-batch-size').value) || 4);
            updateMemoryDisplay();
        });

        // Filters/FiltersRate are for shared backbone only (single_instance/bottomup)
        ['config-filters', 'config-filters-rate'].forEach(id => {
            document.getElementById(id).addEventListener('input', () => {
                configState.filters = parseInt(document.getElementById('config-filters').value) || 24;
                configState.filtersRate = parseFloat(document.getElementById('config-filters-rate').value) || 2.0;
                updateMemoryDisplay();
                updateModelParams();
            });
        });

        // Head config event listeners - Single Instance
        document.getElementById('config-si-sigma').addEventListener('input', (e) => {
            configState.singleInstance.sigma = parseFloat(e.target.value);
        });
        document.getElementById('config-si-stride').addEventListener('change', (e) => {
            configState.singleInstance.outputStride = parseInt(e.target.value);
            updateModelParams();
        });

        // Head config event listeners - Centroid
        document.getElementById('config-centroid-sigma').addEventListener('input', (e) => {
            configState.centroid.sigma = parseFloat(e.target.value);
            updateCentroidSigmaViz();
        });
        document.getElementById('config-centroid-stride').addEventListener('change', (e) => {
            configState.centroid.outputStride = parseInt(e.target.value);
            updateCentroidSigmaViz();
            updateModelParams();
        });
        document.getElementById('config-centroid-anchor').addEventListener('change', (e) => {
            configState.centroid.anchorPart = e.target.value;
            drawAnchorVisualization('centroid-anchor-viz', 'centroid', e.target.value);
            updateAnchorNanInfo('centroid', e.target.value);
        });

        // Click handler for centroid anchor canvas
        document.getElementById('centroid-anchor-viz').addEventListener('click', (e) => {
            handleAnchorCanvasClick(e, 'centroid-anchor-viz', 'centroid', 'config-centroid-anchor');
        });

        function updateCentroidSigmaViz() {
            const sigma = configState.centroid.sigma;
            const stride = configState.centroid.outputStride;
            drawSigmaVisualization('centroid-sigma-viz', sigma, stride);
            updateSigmaInfo('centroid', sigma, stride, true);
        }

        // Head config event listeners - Centered Instance
        document.getElementById('config-ci-sigma').addEventListener('input', (e) => {
            configState.centeredInstance.sigma = parseFloat(e.target.value);
            updateCISigmaViz();
        });
        document.getElementById('config-ci-stride').addEventListener('change', (e) => {
            configState.centeredInstance.outputStride = parseInt(e.target.value);
            updateCISigmaViz();
            updateModelParams();
        });
        document.getElementById('config-ci-anchor').addEventListener('change', (e) => {
            configState.centeredInstance.anchorPart = e.target.value;
            drawAnchorVisualization('ci-anchor-viz', 'ci', e.target.value);
            updateAnchorNanInfo('ci', e.target.value);
        });

        // Click handler for CI anchor canvas
        document.getElementById('ci-anchor-viz').addEventListener('click', (e) => {
            handleAnchorCanvasClick(e, 'ci-anchor-viz', 'ci', 'config-ci-anchor');
        });

        function updateCISigmaViz() {
            const sigma = configState.centeredInstance.sigma;
            const stride = configState.centeredInstance.outputStride;
            drawSigmaVisualization('ci-sigma-viz', sigma, stride);
            updateSigmaInfo('ci', sigma, stride, false);
        }

        // Update instance size displays based on current scale
        function updateInstanceSizeDisplays() {
            if (!computedStats || !computedStats.instanceSizes) return;

            const scale = getConfigValue('scale') || configState.scale || 1.0;
            const maxDim = computedStats.instanceSizes.maxDim;
            const maxW = computedStats.instanceSizes.maxWidth;
            const maxH = computedStats.instanceSizes.maxHeight;

            // Scaled values
            const scaledDim = Math.round(maxDim * scale);
            const scaledW = Math.round(maxW * scale);
            const scaledH = Math.round(maxH * scale);

            // Original values (at scale 1.0)
            const origDim = Math.round(maxDim);
            const origW = Math.round(maxW);
            const origH = Math.round(maxH);

            // Update stats card
            const statSizeEl = document.getElementById('stat-size');
            const statDetailEl = document.getElementById('stat-size-detail');
            if (statSizeEl && statDetailEl) {
                if (scale !== 1.0) {
                    statSizeEl.innerHTML = `<strong>${scaledDim}</strong> <span style="font-size: 0.7rem; opacity: 0.7;">px @ scale ${scale}</span>`;
                    statDetailEl.textContent = `${origDim} px @ scale 1.0`;
                } else {
                    statSizeEl.textContent = `${origDim} px`;
                    statDetailEl.textContent = `${origW}×${origH}`;
                }
            }

            // Update crop size card
            const cropMaxEl = document.getElementById('crop-max-instance');
            if (cropMaxEl) {
                if (scale !== 1.0) {
                    cropMaxEl.innerHTML = `<strong>${scaledDim} px</strong> <span style="font-size: 0.75rem; opacity: 0.7;">@ scale ${scale}</span><br><span style="font-size: 0.7rem; opacity: 0.6;">(${origDim} px @ scale 1.0)</span>`;
                } else {
                    cropMaxEl.innerHTML = `<strong>${origDim} px</strong> <span style="font-size: 0.75rem;">(${origW}×${origH})</span>`;
                }
            }
        }

        // Head config event listeners - Bottom-Up Confmaps
        document.getElementById('config-bu-sigma').addEventListener('input', (e) => {
            configState.bottomup.confmaps.sigma = parseFloat(e.target.value);
        });
        document.getElementById('config-bu-stride').addEventListener('change', (e) => {
            configState.bottomup.confmaps.outputStride = parseInt(e.target.value);
        });
        document.getElementById('config-bu-confmap-weight').addEventListener('input', (e) => {
            configState.bottomup.confmaps.lossWeight = parseFloat(e.target.value);
        });

        // Head config event listeners - Bottom-Up PAFs
        document.getElementById('config-paf-sigma').addEventListener('input', (e) => {
            configState.bottomup.pafs.sigma = parseFloat(e.target.value);
        });
        document.getElementById('config-paf-stride').addEventListener('change', (e) => {
            configState.bottomup.pafs.outputStride = parseInt(e.target.value);
        });
        document.getElementById('config-paf-weight').addEventListener('input', (e) => {
            configState.bottomup.pafs.lossWeight = parseFloat(e.target.value);
        });

        // Sub-tab click handlers for Top-Down config (Model tab)
        document.querySelectorAll('.sub-tab[data-subtab]').forEach(tab => {
            tab.addEventListener('click', () => {
                switchTopDownModel(tab.dataset.subtab);
            });
        });

        // Helper to update backbone UI based on architecture type
        function updateBackboneUI(prefix, backbone) {
            const isUnet = backbone === 'unet';
            const isSwinT = backbone === 'swint';
            // Show/hide max stride vs model type
            document.getElementById(`${prefix}-max-stride-group`).style.display = isUnet ? 'block' : 'none';
            document.getElementById(`${prefix}-model-type-group`).style.display = isUnet ? 'none' : 'block';
            document.getElementById(`${prefix}-unet-params`).style.display = isUnet ? 'flex' : 'none';
            // Show/hide UNet architecture diagram
            const unetDiagram = document.getElementById(`${prefix}-unet-diagram`);
            if (unetDiagram) {
                unetDiagram.style.display = isUnet ? 'block' : 'none';
                if (isUnet) {
                    updateTopDownUNetDiagram(prefix);
                }
            }
            // For SwinT, hide 'large' option (only tiny/small/base)
            const modelTypeSelect = document.getElementById(`config-${prefix === 'shared' ? '' : prefix + '-'}model-type`);
            if (modelTypeSelect) {
                const largeOption = modelTypeSelect.querySelector('option[value="large"]');
                if (largeOption) largeOption.style.display = isSwinT ? 'none' : 'block';
                // If currently large and switching to SwinT, default to base
                if (isSwinT && modelTypeSelect.value === 'large') {
                    modelTypeSelect.value = 'base';
                }
            }
            // Update RF section max stride visibility and value
            updateRFMaxStrideUI();
        }

        // Get active output stride based on current pipeline
        function getActiveOutputStride() {
            const pipeline = configState.pipeline;
            if (pipeline === 'single_instance') {
                return configState.singleInstance.outputStride || 1;
            } else if (pipeline === 'topdown') {
                // For top-down, show the active sub-tab's stride
                if (configState.activeTopDownTab === 'centroid') {
                    return configState.centroid.outputStride || 1;
                } else {
                    return configState.centeredInstance.outputStride || 1;
                }
            } else if (pipeline === 'bottomup') {
                return configState.bottomup.confmaps.outputStride || 1;
            }
            return 1;
        }

        // Get input channels based on current config
        function getInputChannels(modelConfig = null) {
            const c = modelConfig || configState;
            // Use explicit inChannels if set, otherwise derive from channels setting
            if (c.inChannels !== undefined) return c.inChannels;

            const channels = c.channels || configState.channels;
            const usesPretrained = (c.backbone !== 'unet') && c.pretrained;

            if (channels === 'rgb') return 3;
            if (channels === 'grayscale') return 1;
            // 'auto': if using pretrained weights, default to 3 (RGB), otherwise 1
            return usesPretrained ? 3 : 1;
        }

        // Update UNet diagram for Top-Down models
        function updateTopDownUNetDiagram(prefix) {
            if (prefix === 'shared') {
                // For Single Instance / Bottom-Up, use the shared config
                const filters = parseInt(document.getElementById('config-filters').value) || 24;
                const rate = parseFloat(document.getElementById('config-filters-rate').value) || 2.0;
                const maxStride = parseInt(document.getElementById('config-max-stride').value) || 16;
                const outputStride = parseInt(document.getElementById('config-stride').value) || 1;
                const kps = slpData?.skeleton?.nodes?.length || 13;
                const inputCh = parseInt(document.getElementById('config-in-channels').value) || 1;
                const scale = parseFloat(document.getElementById('config-scale')?.value || 1.0);
                const inputDims = (videoWidth > 0 && videoHeight > 0) ? {
                    width: videoWidth,
                    height: videoHeight,
                    scale: scale,
                    isCrop: false
                } : null;
                updateUNetDiagram('shared-unet-arch', filters, rate, maxStride, kps, inputCh, inputDims, outputStride);
            } else if (prefix === 'centroid') {
                const filters = parseInt(document.getElementById('config-centroid-filters').value) || 24;
                const rate = parseFloat(document.getElementById('config-centroid-filters-rate').value) || 2.0;
                const maxStride = parseInt(document.getElementById('config-centroid-max-stride').value) || 16;
                const outputStride = parseInt(document.getElementById('config-centroid-stride').value) || 1;
                const inputCh = getInputChannels(configState.centroid);
                // Centroid model uses full image (with scale)
                const centroidScale = parseFloat(document.getElementById('config-centroid-scale')?.value || 1.0);
                const inputDims = (videoWidth > 0 && videoHeight > 0) ? {
                    width: videoWidth,
                    height: videoHeight,
                    scale: centroidScale,
                    isCrop: false
                } : null;
                updateUNetDiagram('centroid-unet-arch', filters, rate, maxStride, 1, inputCh, inputDims, outputStride); // 1 output for centroid
            } else if (prefix === 'ci') {
                const filters = parseInt(document.getElementById('config-ci-filters').value) || 24;
                const rate = parseFloat(document.getElementById('config-ci-filters-rate').value) || 2.0;
                const maxStride = parseInt(document.getElementById('config-ci-max-stride').value) || 16;
                const outputStride = parseInt(document.getElementById('config-ci-stride').value) || 1;
                const kps = slpData?.skeleton?.nodes?.length || 13;
                const inputCh = getInputChannels(configState.centeredInstance);
                // Centered instance model uses CROP as input (not full image!)
                const cropSize = parseInt(document.getElementById('config-crop-size')?.value || 256);
                const ciScale = parseFloat(document.getElementById('config-ci-scale')?.value || 1.0);
                const inputDims = {
                    width: cropSize,
                    height: cropSize,
                    scale: ciScale,
                    isCrop: true  // This is a crop, not the full image
                };
                updateUNetDiagram('ci-unet-arch', filters, rate, maxStride, kps, inputCh, inputDims, outputStride);
            }
        }

        // Update RF section max stride based on current backbone
        function updateRFMaxStrideUI() {
            const backbone = getCurrentBackboneConfig();
            const isUnet = backbone.backbone === 'unet';
            const rfMaxStrideGroup = document.getElementById('rf-max-stride-group');
            const rfMaxStrideSelect = document.getElementById('rf-max-stride');

            if (isUnet) {
                rfMaxStrideGroup.style.opacity = '1';
                rfMaxStrideSelect.disabled = false;
                rfMaxStrideSelect.value = backbone.maxStride;
            } else {
                // ConvNeXt/SwinT - max stride is fixed at 32
                rfMaxStrideGroup.style.opacity = '0.6';
                rfMaxStrideSelect.disabled = true;
                rfMaxStrideSelect.value = '32';
            }
        }

        // Centroid backbone event listeners
        document.getElementById('config-centroid-backbone').addEventListener('change', (e) => {
            configState.centroid.backbone = e.target.value;
            updateBackboneUI('centroid', e.target.value);
            updateModelParams();
            updateVisualizations();
        });
        document.getElementById('config-centroid-max-stride').addEventListener('change', (e) => {
            configState.centroid.maxStride = parseInt(e.target.value);
            // Sync with RF section if this is the active model
            if (configState.activeTopDownTab === 'centroid') {
                document.getElementById('rf-max-stride').value = e.target.value;
            }
            updateVisualizations();
            updateModelParams();
            updateTopDownUNetDiagram('centroid');
        });
        document.getElementById('config-centroid-model-type').addEventListener('change', (e) => {
            configState.centroid.modelType = e.target.value;
            updateModelParams();
        });
        document.getElementById('config-centroid-pretrained').addEventListener('change', (e) => {
            configState.centroid.pretrained = e.target.checked;
        });
        document.getElementById('config-centroid-filters').addEventListener('input', (e) => {
            configState.centroid.filters = parseInt(e.target.value) || 24;
            updateModelParams();
            updateTopDownUNetDiagram('centroid');
        });
        document.getElementById('config-centroid-filters-rate').addEventListener('input', (e) => {
            configState.centroid.filtersRate = parseFloat(e.target.value) || 2.0;
            updateModelParams();
            updateTopDownUNetDiagram('centroid');
        });

        // Centered Instance backbone event listeners
        document.getElementById('config-ci-backbone').addEventListener('change', (e) => {
            configState.centeredInstance.backbone = e.target.value;
            updateBackboneUI('ci', e.target.value);
            updateModelParams();
            updateVisualizations();
        });
        document.getElementById('config-ci-max-stride').addEventListener('change', (e) => {
            configState.centeredInstance.maxStride = parseInt(e.target.value);
            // Sync with RF section if this is the active model
            if (configState.activeTopDownTab === 'centeredInstance') {
                document.getElementById('rf-max-stride').value = e.target.value;
            }
            updateVisualizations();
            updateModelParams();
            updateTopDownUNetDiagram('ci');
        });
        document.getElementById('config-ci-model-type').addEventListener('change', (e) => {
            configState.centeredInstance.modelType = e.target.value;
            updateModelParams();
        });
        document.getElementById('config-ci-pretrained').addEventListener('change', (e) => {
            configState.centeredInstance.pretrained = e.target.checked;
        });
        document.getElementById('config-ci-filters').addEventListener('input', (e) => {
            configState.centeredInstance.filters = parseInt(e.target.value) || 24;
            updateModelParams();
            updateTopDownUNetDiagram('ci');
        });
        document.getElementById('config-ci-filters-rate').addEventListener('input', (e) => {
            configState.centeredInstance.filtersRate = parseFloat(e.target.value) || 2.0;
            updateModelParams();
            updateTopDownUNetDiagram('ci');
        });

        // Trainer config event listeners (route to active model for Top-Down)
        document.getElementById('config-epochs').addEventListener('input', (e) => {
            updateConfigValue('epochs', parseInt(e.target.value) || 200);
        });
        document.getElementById('config-num-workers').addEventListener('input', (e) => {
            updateConfigValue('numWorkers', parseInt(e.target.value) || 0);
        });
        document.getElementById('config-optimizer').addEventListener('change', (e) => {
            updateConfigValue('optimizer', e.target.value);
        });
        document.getElementById('config-lr').addEventListener('input', (e) => {
            updateConfigValue('lr', parseFloat(e.target.value) || 0.0001);
        });
        document.getElementById('config-amsgrad').addEventListener('change', (e) => {
            updateConfigValue('amsgrad', e.target.value === 'true');
        });
        document.getElementById('config-lr-factor').addEventListener('input', (e) => {
            updateConfigValue('lrFactor', parseFloat(e.target.value) || 0.5);
        });
        document.getElementById('config-lr-patience').addEventListener('input', (e) => {
            updateConfigValue('lrPatience', parseInt(e.target.value) || 5);
        });
        document.getElementById('config-min-lr').addEventListener('input', (e) => {
            updateConfigValue('minLr', parseFloat(e.target.value) || 1e-8);
        });
        document.getElementById('config-early-stop').addEventListener('change', (e) => {
            updateConfigValue('earlyStop', e.target.value === 'true');
        });
        document.getElementById('config-early-patience').addEventListener('input', (e) => {
            updateConfigValue('earlyPatience', parseInt(e.target.value) || 10);
        });
        document.getElementById('config-early-delta').addEventListener('input', (e) => {
            updateConfigValue('earlyDelta', parseFloat(e.target.value) || 1e-8);
        });
        document.getElementById('config-save-ckpt').addEventListener('change', (e) => {
            updateConfigValue('saveCkpt', e.target.value === 'true');
        });
        document.getElementById('config-save-top-k').addEventListener('input', (e) => {
            updateConfigValue('saveTopK', parseInt(e.target.value) || 1);
        });

        // ============================================
        // ============================================
        // Preprocessing & Augmentation Previews
        // ============================================
        const preprocCanvas = document.getElementById('preproc-canvas');
        const preprocCtx = preprocCanvas.getContext('2d');
        const augOrigCanvas = document.getElementById('aug-original');
        const augOrigCtx = augOrigCanvas.getContext('2d');
        const augPrevCanvas = document.getElementById('aug-preview');
        const augPrevCtx = augPrevCanvas.getContext('2d');

        // Helper to compute padded size (pad to be divisible by max_stride)
        function padToStride(size, maxStride) {
            return Math.ceil(size / maxStride) * maxStride;
        }

        function updatePreprocessingPreview() {
            const paddedSizeEl = document.getElementById('padded-size');

            // Use video frame dimensions, or fall back to SLP video dimensions
            let origW, origH;
            if (videoFrame) {
                origW = videoFrame.width;
                origH = videoFrame.height;
            } else if (videoWidth && videoHeight) {
                // Use dimensions from SLP metadata
                origW = videoWidth;
                origH = videoHeight;
            } else {
                document.getElementById('orig-size').textContent = '-';
                document.getElementById('proc-size').textContent = '-';
                if (paddedSizeEl) paddedSizeEl.textContent = '-';
                return;
            }
            const scale = getConfigValue('scale') || configState.scale;
            const maxHeight = getConfigValue('maxHeight') || configState.maxHeight;
            const maxWidth = getConfigValue('maxWidth') || configState.maxWidth;

            // Get max stride from current backbone config
            const backbone = getCurrentBackboneConfig();
            const maxStride = backbone.maxStride || 16;

            // Scale applies differently per pipeline:
            // - Centered Instance: scale applies to CROP (crop_size × scale)
            // - Single Instance, Centroid, Bottom-Up: scale applies to FULL IMAGE (video_dims × scale)
            const isTopDown = configState.pipeline === 'topdown';
            const isCenteredInstance = isTopDown && configState.activeTopDownTab === 'centeredInstance';

            let procW, procH, procLabel;
            let paddedW, paddedH;

            if (isCenteredInstance) {
                // For Centered Instance, scale applies to crop, not full image
                const cropSize = configState.cropSize || 256;
                const ciScale = configState.centeredInstance?.scale || scale;
                const scaledCrop = Math.round(cropSize * ciScale);
                procW = scaledCrop;
                procH = scaledCrop;
                procLabel = `${scaledCrop}×${scaledCrop} (crop)`;
                // Pad crop to stride
                paddedW = padToStride(scaledCrop, maxStride);
                paddedH = padToStride(scaledCrop, maxStride);
            } else {
                // Apply SizeMatcher first (max_height/max_width limits)
                let sizedW = origW;
                let sizedH = origH;
                if (maxHeight && origH > maxHeight) {
                    const ratio = maxHeight / origH;
                    sizedH = maxHeight;
                    sizedW = Math.round(origW * ratio);
                }
                if (maxWidth && sizedW > maxWidth) {
                    const ratio = maxWidth / sizedW;
                    sizedW = maxWidth;
                    sizedH = Math.round(sizedH * ratio);
                }
                // Then apply scale
                procW = Math.round(sizedW * scale);
                procH = Math.round(sizedH * scale);
                procLabel = `${procW}×${procH}`;
                // Pad to stride
                paddedW = padToStride(procW, maxStride);
                paddedH = padToStride(procH, maxStride);
            }

            document.getElementById('orig-size').textContent = `${origW}×${origH}`;
            document.getElementById('proc-size').textContent = procLabel;
            if (paddedSizeEl) {
                if (paddedW === procW && paddedH === procH) {
                    paddedSizeEl.textContent = `${paddedW}×${paddedH}`;
                } else {
                    paddedSizeEl.innerHTML = `${paddedW}×${paddedH} <span style="font-size: 0.7rem; color: var(--text-dim);">(+${paddedW - procW}, +${paddedH - procH})</span>`;
                }
            }

            // Draw scaled preview (only if video frame is available)
            const cw = preprocCanvas.width, ch = preprocCanvas.height;
            preprocCtx.clearRect(0, 0, cw, ch);

            const aspect = origW / origH;
            let dw, dh;
            if (aspect > cw / ch) {
                dw = cw - 10;
                dh = dw / aspect;
            } else {
                dh = ch - 10;
                dw = dh * aspect;
            }

            if (videoFrame) {
                // Simulate scaled appearance (scale the drawn size)
                const scaledW = dw * scale;
                const scaledH = dh * scale;
                const dx = (cw - scaledW) / 2;
                const dy = (ch - scaledH) / 2;

                preprocCtx.drawImage(videoFrame, dx, dy, scaledW, scaledH);

                // Draw border showing original size
                preprocCtx.strokeStyle = 'var(--text-dim)';
                preprocCtx.setLineDash([3, 3]);
                preprocCtx.strokeRect((cw - dw) / 2, (ch - dh) / 2, dw, dh);
                preprocCtx.setLineDash([]);
            } else {
                // Show placeholder with dimensions from SLP
                preprocCtx.fillStyle = '#1a1a2e';
                preprocCtx.fillRect(0, 0, cw, ch);
                preprocCtx.strokeStyle = 'var(--primary)';
                preprocCtx.setLineDash([5, 5]);
                preprocCtx.strokeRect((cw - dw) / 2, (ch - dh) / 2, dw, dh);
                preprocCtx.setLineDash([]);
                preprocCtx.fillStyle = 'var(--text-dim)';
                preprocCtx.font = '10px system-ui';
                preprocCtx.textAlign = 'center';
                preprocCtx.fillText(`${origW}×${origH}`, cw / 2, ch / 2);
                preprocCtx.fillText('(from SLP)', cw / 2, ch / 2 + 12);
            }
        }

        let currentAugParams = { rotation: 0, scale: 1, brightness: 0, contrast: 0 };

        function updateAugmentationPreview(randomize = false) {
            if (!videoFrame) return;

            const cw = augOrigCanvas.width, ch = augOrigCanvas.height;

            // Get crop around first instance if available
            let srcX = 0, srcY = 0, srcS = Math.min(videoFrame.width, videoFrame.height);
            if (slpData && slpData.frames.length > 0 && slpData.frames[currentFrameIdx].instances.length > 0) {
                const inst = slpData.frames[currentFrameIdx].instances[0];
                const bbox = computeInstanceBBox(inst);
                if (bbox) {
                    srcS = Math.max(bbox.width, bbox.height) * 1.5;
                    srcX = bbox.centerX - srcS / 2;
                    srcY = bbox.centerY - srcS / 2;
                    srcX = Math.max(0, Math.min(videoFrame.width - srcS, srcX));
                    srcY = Math.max(0, Math.min(videoFrame.height - srcS, srcY));
                }
            }

            // Draw original (cropped region)
            augOrigCtx.clearRect(0, 0, cw, ch);
            augOrigCtx.drawImage(videoFrame, srcX, srcY, srcS, srcS, 0, 0, cw, ch);

            // Generate random augmentation within bounds (use getConfigValue for Top-Down support)
            if (randomize) {
                const rotRange = getConfigValue('rotation') || 0;
                const scaleRange = (getConfigValue('scaleAug') || 0) / 100;
                const brightRange = (getConfigValue('brightness') || 0) / 100;
                const contrastRange = (getConfigValue('contrast') || 0) / 100;

                currentAugParams = {
                    rotation: rotRange > 0 ? (Math.random() * 2 - 1) * rotRange : 0,
                    scale: scaleRange > 0 ? 1 + (Math.random() * 2 - 1) * scaleRange : 1,
                    brightness: brightRange > 0 ? (Math.random() * 2 - 1) * brightRange : 0,
                    contrast: contrastRange > 0 ? 1 + (Math.random() * 2 - 1) * contrastRange : 1
                };
            }

            // Apply augmentations to preview canvas
            augPrevCtx.clearRect(0, 0, cw, ch);
            augPrevCtx.save();

            // Apply transformations
            augPrevCtx.translate(cw / 2, ch / 2);
            augPrevCtx.rotate(currentAugParams.rotation * Math.PI / 180);
            augPrevCtx.scale(currentAugParams.scale, currentAugParams.scale);
            augPrevCtx.translate(-cw / 2, -ch / 2);

            // Draw image
            augPrevCtx.filter = `brightness(${1 + currentAugParams.brightness}) contrast(${currentAugParams.contrast})`;
            augPrevCtx.drawImage(videoFrame, srcX, srcY, srcS, srcS, 0, 0, cw, ch);
            augPrevCtx.filter = 'none';

            augPrevCtx.restore();
        }

        // ============================================
        // YAML Generation
        // ============================================
        function generateYaml() {
            const c = configState;

            // Determine input channels - use explicit setting if available
            // Otherwise derive from channels setting and pretrained weights
            const usesPretrained = (c.backbone !== 'unet') && c.pretrained;
            let inChannels;
            if (c.inChannels !== undefined) {
                inChannels = c.inChannels;
            } else if (c.channels === 'rgb') {
                inChannels = 3;
            } else if (c.channels === 'grayscale') {
                inChannels = 1;
            } else {
                // 'auto': if using pretrained weights, default to 3 (RGB), otherwise 1
                inChannels = usesPretrained ? 3 : 1;
            }

            // Complete preprocessing config
            // When using pretrained weights with 'auto', set ensure_rgb=true since pretrained models expect RGB
            const preprocessingConfig = {
                ensure_rgb: c.channels === 'rgb' || (c.channels === 'auto' && usesPretrained),
                ensure_grayscale: c.channels === 'grayscale',
                max_height: c.maxHeight || null,
                max_width: c.maxWidth || null,
                scale: c.scale,
                min_crop_size: 100,
                crop_padding: c.cropPadding || null
            };

            // Complete intensity augmentation config
            const intensityConfig = {
                uniform_noise_min: 0.0,
                uniform_noise_max: 0.04,
                uniform_noise_p: 0.0,
                gaussian_noise_mean: 0.0,
                gaussian_noise_std: 0.04,
                gaussian_noise_p: 0.0,
                contrast_min: 1.0 - c.contrast / 100,
                contrast_max: 1.0 + c.contrast / 100,
                contrast_p: c.contrast > 0 ? 0.5 : 0.0,
                brightness_min: 1.0 - c.brightness / 100,
                brightness_max: 1.0 + c.brightness / 100,
                brightness_p: c.brightness > 0 ? 0.5 : 0.0
            };

            // Complete geometric augmentation config
            // Use separate _p params for each transform type (new sleap-nn format)
            const geometricConfig = {
                rotation_min: -c.rotation,
                rotation_max: c.rotation,
                rotation_p: c.rotation > 0 ? 0.5 : null,
                scale_min: 1.0 - c.scaleAug / 100,
                scale_max: 1.0 + c.scaleAug / 100,
                scale_p: c.scaleAug > 0 ? 0.5 : null,
                translate_width: 0.0,
                translate_height: 0.0,
                translate_p: null,
                affine_p: 0.0,
                erase_scale_min: 0.0001,
                erase_scale_max: 0.01,
                erase_ratio_min: 1.0,
                erase_ratio_max: 1.0,
                erase_p: 0.0,
                mixup_lambda_min: 0.01,
                mixup_lambda_max: 0.05,
                mixup_p: 0.0
            };

            // Base data config shared by all models
            const baseDataConfig = {
                train_labels_path: 'path/to/train.slp',
                val_labels_path: null,
                validation_fraction: 0.1,
                use_same_data_for_val: c.useSameDataForVal,
                test_file_path: null,
                provider: 'LabelsReader',
                user_instances_only: c.userInstancesOnly,
                data_pipeline_fw: c.dataPipelineFw,
                cache_img_path: null,
                use_existing_imgs: false,
                delete_cache_imgs_after_training: true,
                preprocessing: preprocessingConfig,
                use_augmentations_train: true,
                augmentation_config: {
                    intensity: intensityConfig,
                    geometric: geometricConfig
                },
                skeletons: null
            };

            // Build backbone config with all types (unused set to null)
            let backboneConfig = {
                unet: null,
                convnext: null,
                swint: null
            };
            if (c.backbone === 'unet') {
                backboneConfig.unet = {
                    in_channels: inChannels,
                    kernel_size: 3,
                    filters: c.filters,
                    filters_rate: c.filtersRate,
                    max_stride: c.maxStride,
                    stem_stride: null,
                    middle_block: true,
                    up_interpolate: true,
                    stacks: 1,
                    convs_per_block: 2,
                    output_stride: 1
                };
            } else if (c.backbone === 'convnext') {
                // ConvNeXt pretrained weights: ConvNeXt_Tiny_Weights, ConvNeXt_Small_Weights, ConvNeXt_Base_Weights, ConvNeXt_Large_Weights
                const convnextWeights = { tiny: 'ConvNeXt_Tiny_Weights', small: 'ConvNeXt_Small_Weights', base: 'ConvNeXt_Base_Weights', large: 'ConvNeXt_Large_Weights' };
                backboneConfig.convnext = {
                    pre_trained_weights: c.pretrained ? convnextWeights[c.modelType || 'tiny'] : null,
                    model_type: c.modelType || 'tiny',
                    arch: null,
                    stem_patch_kernel: 4,
                    stem_patch_stride: 2,
                    in_channels: inChannels,
                    kernel_size: 3,
                    filters_rate: 2,
                    convs_per_block: 2,
                    up_interpolate: true,
                    output_stride: 1,
                    max_stride: 32
                };
            } else {
                // SwinT pretrained weights: Swin_T_Weights, Swin_S_Weights, Swin_B_Weights (no large)
                const swintWeights = { tiny: 'Swin_T_Weights', small: 'Swin_S_Weights', base: 'Swin_B_Weights' };
                const swintModelType = c.modelType === 'large' ? 'base' : (c.modelType || 'tiny');
                backboneConfig.swint = {
                    pre_trained_weights: c.pretrained ? swintWeights[swintModelType] : null,
                    model_type: swintModelType,
                    arch: null,
                    patch_size: 4,
                    stem_patch_stride: 2,
                    window_size: 7,
                    in_channels: inChannels,
                    kernel_size: 3,
                    filters_rate: 2,
                    convs_per_block: 2,
                    up_interpolate: true,
                    output_stride: 1,
                    max_stride: 32
                };
            }

            // Base model config
            const baseModelConfig = {
                init_weights: 'default',
                pretrained_backbone_weights: null,
                pretrained_head_weights: null,
                backbone_config: backboneConfig
            };

            // Complete trainer config
            const baseTrainerConfig = {
                train_data_loader: { batch_size: c.batchSize, shuffle: true, num_workers: c.numWorkers },
                val_data_loader: { batch_size: c.batchSize, shuffle: false, num_workers: c.numWorkers },
                model_ckpt: { save_top_k: c.saveTopK, save_last: false },
                trainer_devices: null,
                trainer_device_indices: null,
                trainer_accelerator: 'auto',
                profiler: null,
                trainer_strategy: 'auto',
                enable_progress_bar: true,
                min_train_steps_per_epoch: 200,
                train_steps_per_epoch: null,
                visualize_preds_during_training: false,
                keep_viz: false,
                max_epochs: c.epochs,
                seed: null,
                use_wandb: c.useWandb,
                save_ckpt: c.saveCkpt,
                ckpt_dir: c.ckptDir || 'models',
                run_name: c.runName || null,
                resume_ckpt_path: null,
                wandb: {
                    entity: c.wandb.entity || null,
                    project: c.wandb.project || null,
                    name: c.wandb.name || null,
                    save_viz_imgs_wandb: c.wandb.saveViz,
                    api_key: null,
                    wandb_mode: null,
                    prv_runid: null,
                    group: c.wandb.group || null,
                    current_run_id: null
                },
                optimizer_name: c.optimizer,
                optimizer: { lr: c.lr, amsgrad: c.amsgrad },
                lr_scheduler: {
                    step_lr: null,
                    reduce_lr_on_plateau: {
                        threshold: 1e-8,
                        threshold_mode: 'abs',
                        cooldown: 3,
                        patience: c.lrPatience,
                        factor: c.lrFactor,
                        min_lr: c.minLr
                    }
                },
                early_stopping: {
                    min_delta: c.earlyDelta,
                    patience: c.earlyPatience,
                    stop_training_on_plateau: c.earlyStop
                },
                online_hard_keypoint_mining: {
                    online_mining: c.ohkm.enabled,
                    hard_to_easy_ratio: c.ohkm.hardToEasyRatio,
                    min_hard_keypoints: c.ohkm.minHardKeypoints,
                    max_hard_keypoints: c.ohkm.maxHardKeypoints,
                    loss_scale: c.ohkm.lossScale
                },
                zmq: {
                    controller_port: 9000,
                    controller_polling_timeout: 10,
                    publish_port: 9001
                }
            };

            // Top-level config metadata
            const configMetadata = {
                name: '',
                description: '',
                sleap_nn_version: '0.0.5',
                filename: ''
            };

            // All head types template (unused ones are null)
            const allHeadsNull = {
                single_instance: null,
                centroid: null,
                centered_instance: null,
                bottomup: null,
                multi_class_bottomup: null,
                multi_class_topdown: null
            };

            if (c.pipeline === 'topdown') {
                // TOP-DOWN: Generate TWO configs with SEPARATE data, backbone, and trainer configs

                // Helper to build model-specific data config
                function buildModelDataConfig(modelCfg, cropSize = null) {
                    // Check if using pretrained weights (ConvNeXt/SwinT with pretrained=true needs RGB)
                    const usesPretrained = (modelCfg.backbone !== 'unet') && modelCfg.pretrained;
                    const forceRgb = modelCfg.channels === 'auto' && usesPretrained;

                    const modelPreprocessingConfig = {
                        ensure_rgb: modelCfg.channels === 'rgb' || forceRgb,
                        ensure_grayscale: modelCfg.channels === 'grayscale',
                        max_height: modelCfg.maxHeight || null,
                        max_width: modelCfg.maxWidth || null,
                        scale: modelCfg.scale,
                        min_crop_size: 100,
                        crop_padding: c.cropPadding || null
                    };
                    if (cropSize) modelPreprocessingConfig.crop_size = cropSize;

                    const modelIntensityConfig = {
                        uniform_noise_min: 0.0,
                        uniform_noise_max: 0.04,
                        uniform_noise_p: 0.0,
                        gaussian_noise_mean: 0.0,
                        gaussian_noise_std: 0.04,
                        gaussian_noise_p: 0.0,
                        contrast_min: 1.0 - modelCfg.contrast / 100,
                        contrast_max: 1.0 + modelCfg.contrast / 100,
                        contrast_p: modelCfg.contrast > 0 ? 0.5 : 0.0,
                        brightness_min: 1.0 - modelCfg.brightness / 100,
                        brightness_max: 1.0 + modelCfg.brightness / 100,
                        brightness_p: modelCfg.brightness > 0 ? 0.5 : 0.0
                    };

                    // Use separate _p params for each transform type (new sleap-nn format)
                    const modelGeometricConfig = {
                        rotation_min: -modelCfg.rotation,
                        rotation_max: modelCfg.rotation,
                        rotation_p: modelCfg.rotation > 0 ? 0.5 : null,
                        scale_min: 1.0 - modelCfg.scaleAug / 100,
                        scale_max: 1.0 + modelCfg.scaleAug / 100,
                        scale_p: modelCfg.scaleAug > 0 ? 0.5 : null,
                        translate_width: 0.0,
                        translate_height: 0.0,
                        translate_p: null,
                        affine_p: 0.0,
                        erase_scale_min: 0.0001,
                        erase_scale_max: 0.01,
                        erase_ratio_min: 1.0,
                        erase_ratio_max: 1.0,
                        erase_p: 0.0,
                        mixup_lambda_min: 0.01,
                        mixup_lambda_max: 0.05,
                        mixup_p: 0.0
                    };

                    return {
                        train_labels_path: 'path/to/train.slp',
                        val_labels_path: null,
                        validation_fraction: 0.1,
                        use_same_data_for_val: c.useSameDataForVal,
                        test_file_path: null,
                        provider: 'LabelsReader',
                        user_instances_only: c.userInstancesOnly,
                        data_pipeline_fw: modelCfg.dataPipelineFw,
                        cache_img_path: null,
                        use_existing_imgs: false,
                        delete_cache_imgs_after_training: true,
                        preprocessing: modelPreprocessingConfig,
                        use_augmentations_train: true,
                        augmentation_config: {
                            intensity: modelIntensityConfig,
                            geometric: modelGeometricConfig
                        },
                        skeletons: null
                    };
                }

                // Helper to build model-specific trainer config
                function buildModelTrainerConfig(modelCfg) {
                    return {
                        ...baseTrainerConfig,
                        train_data_loader: { batch_size: modelCfg.batchSize, shuffle: true, num_workers: modelCfg.numWorkers },
                        val_data_loader: { batch_size: modelCfg.batchSize, shuffle: false, num_workers: modelCfg.numWorkers },
                        max_epochs: modelCfg.epochs,
                        optimizer_name: modelCfg.optimizer,
                        optimizer: { lr: modelCfg.lr, amsgrad: modelCfg.amsgrad },
                        lr_scheduler: {
                            step_lr: null,
                            reduce_lr_on_plateau: {
                                threshold: 1e-8,
                                threshold_mode: 'abs',
                                cooldown: 3,
                                patience: modelCfg.lrPatience,
                                factor: modelCfg.lrFactor,
                                min_lr: modelCfg.minLr
                            }
                        },
                        early_stopping: {
                            min_delta: modelCfg.earlyDelta,
                            patience: modelCfg.earlyPatience,
                            stop_training_on_plateau: modelCfg.earlyStop
                        },
                        save_ckpt: modelCfg.saveCkpt,
                        model_ckpt: { save_top_k: modelCfg.saveTopK, save_last: false }
                    };
                }

                // Build CENTROID backbone config
                // Determine channels: use explicit inChannels or derive from channels setting
                const centroidUsesPretrained = (c.centroid.backbone !== 'unet') && c.centroid.pretrained;
                let centroidInChannels;
                if (c.centroid.inChannels !== undefined) {
                    centroidInChannels = c.centroid.inChannels;
                } else if (c.centroid.channels === 'rgb') {
                    centroidInChannels = 3;
                } else if (c.centroid.channels === 'grayscale') {
                    centroidInChannels = 1;
                } else {
                    centroidInChannels = centroidUsesPretrained ? 3 : 1;
                }
                const centroidBackboneConfig = { unet: null, convnext: null, swint: null };
                if (c.centroid.backbone === 'unet') {
                    centroidBackboneConfig.unet = {
                        in_channels: centroidInChannels, kernel_size: 3,
                        filters: c.centroid.filters, filters_rate: c.centroid.filtersRate,
                        max_stride: c.centroid.maxStride, stem_stride: null,
                        middle_block: true, up_interpolate: true,
                        stacks: 1, convs_per_block: 2, output_stride: 1
                    };
                } else if (c.centroid.backbone === 'convnext') {
                    const convnextWeights = { tiny: 'ConvNeXt_Tiny_Weights', small: 'ConvNeXt_Small_Weights', base: 'ConvNeXt_Base_Weights', large: 'ConvNeXt_Large_Weights' };
                    centroidBackboneConfig.convnext = {
                        pre_trained_weights: c.centroid.pretrained ? convnextWeights[c.centroid.modelType || 'tiny'] : null,
                        model_type: c.centroid.modelType || 'tiny',
                        arch: null,
                        stem_patch_kernel: 4, stem_patch_stride: 2,
                        in_channels: centroidInChannels,
                        kernel_size: 3, filters_rate: 2, convs_per_block: 2,
                        up_interpolate: true, output_stride: 1, max_stride: 32
                    };
                } else {
                    const swintWeights = { tiny: 'Swin_T_Weights', small: 'Swin_S_Weights', base: 'Swin_B_Weights' };
                    const swintModelType = c.centroid.modelType === 'large' ? 'base' : (c.centroid.modelType || 'tiny');
                    centroidBackboneConfig.swint = {
                        pre_trained_weights: c.centroid.pretrained ? swintWeights[swintModelType] : null,
                        model_type: swintModelType,
                        arch: null,
                        patch_size: 4, stem_patch_stride: 2, window_size: 7,
                        in_channels: centroidInChannels,
                        kernel_size: 3, filters_rate: 2, convs_per_block: 2,
                        up_interpolate: true, output_stride: 1, max_stride: 32
                    };
                }

                const centroidHeadConfig = {
                    confmaps: {
                        part_names: null,
                        sigma: c.centroid.sigma,
                        output_stride: c.centroid.outputStride,
                        loss_weight: 1.0,
                        anchor_part: c.centroid.anchorPart || null
                    }
                };

                const centroidConfig = {
                    data_config: buildModelDataConfig(c.centroid),
                    model_config: {
                        init_weights: 'default',
                        pretrained_backbone_weights: null,
                        pretrained_head_weights: null,
                        backbone_config: centroidBackboneConfig,
                        head_configs: {
                            ...allHeadsNull,
                            centroid: centroidHeadConfig
                        },
                        total_params: null
                    },
                    trainer_config: buildModelTrainerConfig(c.centroid),
                    ...configMetadata
                };

                // Build CENTERED INSTANCE backbone config
                // Determine channels: use explicit inChannels or derive from channels setting
                const ciUsesPretrained = (c.centeredInstance.backbone !== 'unet') && c.centeredInstance.pretrained;
                let ciInChannels;
                if (c.centeredInstance.inChannels !== undefined) {
                    ciInChannels = c.centeredInstance.inChannels;
                } else if (c.centeredInstance.channels === 'rgb') {
                    ciInChannels = 3;
                } else if (c.centeredInstance.channels === 'grayscale') {
                    ciInChannels = 1;
                } else {
                    ciInChannels = ciUsesPretrained ? 3 : 1;
                }
                const ciBackboneConfig = { unet: null, convnext: null, swint: null };
                if (c.centeredInstance.backbone === 'unet') {
                    ciBackboneConfig.unet = {
                        in_channels: ciInChannels, kernel_size: 3,
                        filters: c.centeredInstance.filters, filters_rate: c.centeredInstance.filtersRate,
                        max_stride: c.centeredInstance.maxStride, stem_stride: null,
                        middle_block: true, up_interpolate: true,
                        stacks: 1, convs_per_block: 2, output_stride: 1
                    };
                } else if (c.centeredInstance.backbone === 'convnext') {
                    const convnextWeights = { tiny: 'ConvNeXt_Tiny_Weights', small: 'ConvNeXt_Small_Weights', base: 'ConvNeXt_Base_Weights', large: 'ConvNeXt_Large_Weights' };
                    ciBackboneConfig.convnext = {
                        pre_trained_weights: c.centeredInstance.pretrained ? convnextWeights[c.centeredInstance.modelType || 'tiny'] : null,
                        model_type: c.centeredInstance.modelType || 'tiny',
                        arch: null,
                        stem_patch_kernel: 4, stem_patch_stride: 2,
                        in_channels: ciInChannels,
                        kernel_size: 3, filters_rate: 2, convs_per_block: 2,
                        up_interpolate: true, output_stride: 1, max_stride: 32
                    };
                } else {
                    const swintWeights = { tiny: 'Swin_T_Weights', small: 'Swin_S_Weights', base: 'Swin_B_Weights' };
                    const ciSwintModelType = c.centeredInstance.modelType === 'large' ? 'base' : (c.centeredInstance.modelType || 'tiny');
                    ciBackboneConfig.swint = {
                        pre_trained_weights: c.centeredInstance.pretrained ? swintWeights[ciSwintModelType] : null,
                        model_type: ciSwintModelType,
                        arch: null,
                        patch_size: 4, stem_patch_stride: 2, window_size: 7,
                        in_channels: ciInChannels,
                        kernel_size: 3, filters_rate: 2, convs_per_block: 2,
                        up_interpolate: true, output_stride: 1, max_stride: 32
                    };
                }

                // Use multi_class_topdown head if multiClass is enabled
                const ciHeadKey = c.multiClass ? 'multi_class_topdown' : 'centered_instance';
                const ciHeadConfig = {
                    confmaps: {
                        part_names: null,
                        sigma: c.centeredInstance.sigma,
                        output_stride: c.centeredInstance.outputStride,
                        loss_weight: 1.0,
                        anchor_part: c.centeredInstance.anchorPart || null
                    }
                };
                // Add class_vectors head for multi-class top-down
                if (c.multiClass) {
                    ciHeadConfig.class_vectors = {
                        classes: null, // Will be auto-populated from tracks
                        num_fc_layers: 2,
                        num_fc_units: 256,
                        loss_weight: 1.0
                    };
                }

                const centeredInstanceConfig = {
                    data_config: buildModelDataConfig(c.centeredInstance, c.cropSize),
                    model_config: {
                        init_weights: 'default',
                        pretrained_backbone_weights: null,
                        pretrained_head_weights: null,
                        backbone_config: ciBackboneConfig,
                        head_configs: {
                            ...allHeadsNull,
                            [ciHeadKey]: ciHeadConfig
                        },
                        total_params: null
                    },
                    trainer_config: buildModelTrainerConfig(c.centeredInstance),
                    ...configMetadata
                };

                // Return object with separate configs for Top-Down
                return {
                    isTopDown: true,
                    centroid: jsyaml.dump(centroidConfig, { indent: 2, lineWidth: -1 }),
                    centeredInstance: jsyaml.dump(centeredInstanceConfig, { indent: 2, lineWidth: -1 })
                };

            } else if (c.pipeline === 'single_instance') {
                const config = {
                    data_config: { ...baseDataConfig },
                    model_config: {
                        ...baseModelConfig,
                        head_configs: {
                            ...allHeadsNull,
                            single_instance: {
                                confmaps: {
                                    part_names: null,
                                    sigma: c.singleInstance.sigma,
                                    output_stride: c.singleInstance.outputStride,
                                    loss_weight: 1.0
                                }
                            }
                        },
                        total_params: null
                    },
                    trainer_config: { ...baseTrainerConfig },
                    ...configMetadata
                };
                return jsyaml.dump(config, { indent: 2, lineWidth: -1 });

            } else {
                // Bottom-up (or Multi-Class Bottom-up if multiClass enabled)
                const headKey = c.multiClass ? 'multi_class_bottomup' : 'bottomup';
                const headConfig = {
                    confmaps: {
                        part_names: null,
                        sigma: c.bottomup.confmaps.sigma,
                        output_stride: c.bottomup.confmaps.outputStride,
                        loss_weight: c.bottomup.confmaps.lossWeight
                    },
                    pafs: {
                        edges: null,
                        sigma: c.bottomup.pafs.sigma,
                        output_stride: c.bottomup.pafs.outputStride,
                        loss_weight: c.bottomup.pafs.lossWeight
                    }
                };
                // Add class_maps head for multi-class
                if (c.multiClass) {
                    headConfig.class_maps = {
                        classes: null, // Will be auto-populated from tracks
                        sigma: c.bottomup.confmaps.sigma,
                        output_stride: c.bottomup.confmaps.outputStride,
                        loss_weight: 1.0
                    };
                }

                const config = {
                    data_config: { ...baseDataConfig },
                    model_config: {
                        ...baseModelConfig,
                        head_configs: {
                            ...allHeadsNull,
                            [headKey]: headConfig
                        },
                        total_params: null
                    },
                    trainer_config: { ...baseTrainerConfig },
                    ...configMetadata
                };
                return jsyaml.dump(config, { indent: 2, lineWidth: -1 });
            }
        }

        function updateYamlOutput() {
            const result = generateYaml();

            if (result && result.isTopDown) {
                // Top-Down: Update separate outputs
                generatedYaml.centroid = result.centroid;
                generatedYaml.centeredInstance = result.centeredInstance;
                document.getElementById('yaml-output-centroid').textContent = result.centroid;
                document.getElementById('yaml-output-ci').textContent = result.centeredInstance;
            } else {
                // Single config
                generatedYaml.single = result;
                document.getElementById('yaml-output').textContent = result;
            }
        }

        document.getElementById('copy-yaml-btn').addEventListener('click', () => {
            copyYaml('single');
        });

        document.getElementById('download-yaml-btn').addEventListener('click', () => {
            downloadYaml('single');
        });

        // ============================================
        // Init
        // ============================================
        log('SLEAP-NN Config Helper ready');
        updateVisualizations();
        updateModelParams();
        updateYamlOutput();
        // Initialize UNet diagrams for Top-Down models
        updateTopDownUNetDiagram('centroid');
        updateTopDownUNetDiagram('ci');
        // Initialize sigma visualizations
        updateCentroidSigmaViz();
        updateCISigmaViz();
    </script>
</body>
</html>
